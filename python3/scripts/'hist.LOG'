 4/1: from iconfuv.misc import get_br
 5/1: from iconfuv.misc import get_br
 6/1: from iconfuv.misc import get_br
 7/1: from iconfuv.misc import get_br
 8/1: from iconfuv.misc import get_br
 9/1: from iconfuv.misc import get_br
 9/2: from iconfuv.misc import get_br_noght
 9/3: from iconfuv.misc import get_br_nights
 9/4: plt.plot(np.arange(5))
 9/5: plt.show()
10/1: plt.plot(np.arange(4))
10/2: plt.show()
11/1: plt.plot(np.arange(4))
11/2: plt.show()
11/3: import matplotlib
11/4: matplotlib.use('tkagg')
13/1: import matplotlib.pyplot as plt
14/1: import matplotlib.pyplot as plt
14/2: import matplotlib
14/3: matplotlib.pyplot
14/4: from matplotlib import pyplot as plt
15/1: import matplotlib
16/1: import matplotlib
16/2: matplotlib.use('Agg')
16/3: plt.plot(np.arange(4))
16/4: from matplotlib import pyplot as plt
16/5: plt.plot(range(4))
17/1: import matplotlib
17/2: from matplotlib import pyplot as plt
17/3: plt.plot(range(4))
17/4: plt.show()
17/5: matplotlib.get_backend()
18/1: plt.imshow(np.random.rand(7,7))
18/2: plt.imshow(np.random.rand(7,7))
18/3: ls
18/4: cd pres/pres31_2021_05_15_Daynight_Determination_SZA/
18/5: %run sza_testbed.py
18/6: %run sza_testbed.py
19/1: cd pres/pres31_2021_05_15_Daynight_Determination_SZA/
19/2: %run sza_testbed.py
19/3: a = np.random.rand(1000,1000)
19/4: a=np.linalg.inv(a)
19/5: a = np.random.rand(10000,10000)
19/6: a=np.linalg.inv(a)
19/7: del a
19/8: a=2
19/9: file = '/home/kamo/resources/icon-fuv/ncfiles/l0/ICON_L0P_FUV_Ancillary_2020-07-09_v03r001.NC'
19/10: anc = netCDF4.Dataset(file, mode='r')
19/11: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-07-09_v03r001.NC'
19/12: l1 = netCDF4.Dataset(file, mode='r')
19/13: file = '/home/kamo/resources/icon-fuv/ncfiles/l0/ICON_L0P_FUV_Ancillary_2020-01-01_v03r002.NC'
19/14: anc = netCDF4.Dataset(file, mode='r')
19/15: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-01_v03r004.NC'
19/16: l1 = netCDF4.Dataset(file, mode='r')
19/17: anc.variables.keys()
19/18: sza = anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_SZA'][:]
19/19: sza.shape
19/20: alt = anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_LATLONALT'][:]
19/21: alt.shape
19/22: alt = alt[:,:,:,-1]
19/23: alt.shape
19/24: mode = l1.variables['ICON_L1_FUV_Mode'][:]
19/25: mode.shape
19/26: stat = anc.variables['ICON_ANCILLARY_FUV_STATUS'][:]
19/27: anc.variables['ICON_ANCILLARY_FUV_STATUS']
19/28: plt.plot(status); plt.plot(mode)
19/29: plt.plot(stat); plt.plot(mode)
19/30: qual = l1.variables['ICON_L1_FUVA_SWP_Quality_Flag'][:]
19/31: l1.variables['ICON_L1_FUVA_SWP_Quality_Flag']
19/32: plt.figure(); plt.plot(qual)
19/33: plt.plot(mode)
19/34: np.where(alt>300).shape
19/35: len(np.where(alt>300))
19/36: np.where(alt>300)[0].shape
19/37: np.where(alt>300)[1].shape
19/38: np.where(alt>300)[2].shape
19/39: ind = alt>300
19/40: ind.shape
19/41: np.diff(ind,axis=1)
19/42: ind=np.diff(ind,axis=1)
19/43: ind.shape
19/44: a = np.array([0,0,0,0,1,1,1,1])
19/45: np.diff(a,prepend=0)
19/46: ind = alt>300
19/47: ind=np.diff(ind,axis=1,prepend=0)
19/48: ind.shape
19/49: np.sum(ind,axis=1)
19/50: np.sum(ind,axis=1).max()
19/51: np.sum(ind,axis=1).min()
19/52: inn = np.where(ind==1)
19/53: len(inn)
19/54: inn[0].shape
19/55: 6*5812
19/56: a = np.array([0,0,0,0,1,1,1,1])
19/57: ind = alt<300
19/58: ind = np.sum(ind, axis=1)
19/59: ind.shape
19/60: ind = alt>300]
19/61: ind = alt>300
19/62: ind=np.diff(ind,axis=1,prepend=0)
19/63: alt0 = alt[ind]
19/64: alt0.shape
19/65: alt0 = alt[np.where(ind==1)]
19/66: alt0.shape
19/67: alt0=np.reshape(alt0, 5812,6)
19/68: alt0=np.reshape(alt0, (5812,6))
19/69: alt0[3,5]
19/70: np.max(alt0)
19/71: np.min(alt0)
19/72: ind = np.sum(alt<300, axis=1)
19/73: ind.shape
19/74: sza.shape
19/75: ii = np.ones((25,30))
19/76: x=sza[ii]
19/77: sza.shape
19/78: sza[1,3,2]
19/79: sza[ii,ii,ii]
19/80: ii[2]
19/81: ii.astype(np.int)
19/82: ii=ii.astype(np.int)
19/83: sza[ii,ii,ii].shape
19/84: ind.shape
19/85: xx, yy = np.meshgrid(5812,6)
19/86: xx.shape
19/87: yy.shape
19/88: xx, yy = np.meshgrid(np.arange(5812),np.arange(6))
19/89: xx.shape
19/90: yy.shape
19/91: xx, yy = np.meshgrid(np.arange(6),np.arange(5812))
19/92: xx.shape
19/93: xx[:6,:6]
19/94: xx, yy = np.meshgrid(np.arange(5812),np.arange(6), indexing='ij')
19/95: xx.shape
19/96: xx[:6,:6]
19/97: sza300 = alt[xx,ind,yy]
19/98: sza300.shape
19/99: plt.plot(sza300[:,3])
19/100: alt300 = sza300[:]
19/101: sza300 = sza[xx,ind,yy]
19/102: plt.figure(); plt.plot(sza300[:,3])
19/103: plt.figure(); plt.plot(mode)
19/104: plt.figure(); plt.plot(sza300[mode==2,3])
19/105: plt.figure(); plt.plot(sza300[:,3])
19/106: plt.figure(); plt.plot(sza300[:,:])
19/107: plt.figure(); plt.plot(sza300[mode==2,:])
19/108: %run sza_testbed.py
19/109: %run sza_testbed.py
19/110: %run sza_testbed.py
19/111: %run sza_testbed.py
19/112: %run sza_testbed.py
19/113: [i[:,3].min() for i in sza300l]
19/114: plt.plot(sza300l[-1][:,3])
19/115: plt.plot(sza300l[-1][:,:])
19/116: plt.plot(sza300l[-2][:,:])
19/117: plt.plot(sza300l[-3][:,:])
19/118: plt.plot(sza300l[-4][:,:])
19/119: plt.plot(sza300l[-5][:,:])
19/120: plt.plot(sza300l[-6][:,:])
19/121: plt.plot(sza300l[-7][:,:])
19/122: plt.plot(sza300l[-8][:,:])
19/123: plt.plot(sza300l[-9][:,:])
19/124: plt.plot(sza300l[-10][:,:])
20/1: %run sza_testbed.py
20/2: ind.shape
21/1: %run sza_testbed.py
21/2: ind.shape
21/3: ind[:6,:]
21/4: 12*1
21/5: %run sza_testbed.py
21/6: plt.plot(sza300l[-10][:,:])
21/7: plt.plot(sza300l[-1][:,:])
21/8: %run sza_testbed.py
21/9: plt.plot(sza300l[-1][:,:])
21/10: plt.plot(pix1l[-1][:,:])
21/11: %run sza_testbed.py
21/12: plt.plot(pix1l[-1][:,:])
21/13: plt.plot(pix1l[-4][:,:])
21/14: plt.plot(sza300l[-4][:,:])
21/15: plt.plot(pix1l[-6][:,:])
21/16: plt.plot(sza300l[-6][:,:])
21/17: plt.plot(sza300l[-3][:,:])
21/18: plt.plot(sza300l[-2][:,:])
21/19: plt.plot(pix1l[-2][:,:])
21/20: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-03-15_v03r003.NC'
21/21: l1 = netCDF4.Dataset(file, mode='r')
21/22: file = '/home/kamo/resources/icon-fuv/ncfiles/l0/ICON_L0P_FUV_Ancillary_2020-03-15_v03r003.NC'
21/23: anc = netCDF4.Dataset(file, mode='r')
21/24: mode = l1.variables['ICON_L1_FUV_Mode'][:]
21/25: stat = anc.variables['ICON_ANCILLARY_FUV_STATUS'][:]
21/26: qual = l1.variables['ICON_L1_FUVA_SWP_Quality_Flag'][:]
21/27: plt.plot(qual[mode==2])
21/28: qual = l1.variables['ICON_L1_FUVA_SWP_Quality_Flag']
21/29: qual
21/30: plt.plot(qual[mode==2])
21/31: plt.plot(stat[mode==2])
21/32: plt.plot(pix1l[-2][:,:])
21/33: plt.figure(); plt.plot(qual[mode==2])
21/34: plt.plot(pix1l[-2][qual[mode==2]==0,:])
21/35: %run sza_testbed.py
21/36: %run sza_testbed.py
21/37: %run sza_testbed.py
21/38: plt.plot(pix1l[-2][:,:])
21/39: plt.plot(pix1l[-1][:,:])
21/40: plt.plot(pix1l[-1][:,:])
21/41: plt.plot(pix1l[-3][:,:])
21/42: plt.plot(pix1l[-5][:,:])
21/43: plt.plot(sza300l[-5][:,:])
21/44: plt.plot(pix1l[-5][:,:])
21/45: plt.plot(pix1l[-5][:,-1])
21/46: %run sza_testbed.py
21/47: plt.plot(pix1l[-5][:,-1])
21/48: plt.plot(sza300l[-5][:,:])
21/49: %run sza_testbed.py
21/50: plt.plot(sza300l[-5][:,:])
21/51: %run sza_testbed.py
21/52: plt.plot(sza300l[-5][:,:])
21/53: %run sza_testbed.py
21/54: plt.plot(sza300l[-5][:,:])
21/55: plt.plot(sltl[-5][:,:])
21/56: plt.plot(sza300l[-5][:,:])
21/57: plt.plot(sza300l[-6][:,:])
21/58: plt.plot(sza300l[-7][:,:])
21/59: plt.plot(sza300l[-8][:,:])
21/60: plt.plot(sza300l[-9][:,:])
21/61: anc.variables['ICON_ANCILLARY_FUV_SC_SZA']
21/62: anc = netCDF4.Dataset(file, mode='r')
21/63: anc.variables['ICON_ANCILLARY_FUV_SC_SZA']
21/64: file = '/home/kamo/resources/icon-fuv/ncfiles/l0/ICON_L0P_FUV_Ancillary_2020-03-15_v03r003.NC'
21/65: mode = l1.variables['ICON_L1_FUV_Mode'][:]
21/66: l1 = netCDF4.Dataset(file, mode='r')
21/67: mode = l1.variables['ICON_L1_FUV_Mode'][:]
21/68: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-03-15_v03r003.NC'
21/69: mode = l1.variables['ICON_L1_FUV_Mode'][:]
21/70: %run sza_testbed.py
21/71: plt.plot(sza300l[-8][:,:])
21/72: plt.plot(szail[-8][:,:])
21/73: plt.plot(szail[-8])
21/74: %run sza_testbed.py
21/75: plt.plot(pix1l[-8][:,:])
22/1: import glob
22/2: glob.glob
22/3: glob.glob('*')
22/4: glob.glob('/home/kamo/resources/icon-fuv/ncfiles/l1')
22/5: glob.glob('/home/kamo/resources/icon-fuv/ncfiles/l1/')
22/6: glob.glob('/home/kamo/resources/icon-fuv/ncfiles/l1/*')
22/7: y=glob.glob('/home/kamo/resources/icon-fuv/ncfiles/l1/*')
22/8: y.sort()
22/9: y
22/10: a = np.arange(3)
22/11: b = a+3
22/12:
for x,y in a,b:
    print(x,y)
22/13:
for x,y in zip(a,b):
    print(x,y)
22/14: %run sza_testbed.py
22/15: lt.shape
22/16: alt.shape
22/17: %run sza_testbed.py
22/18: ipdb.pm()
22/19: %run sza_testbed.py
22/20: ipdb.pm()
22/21: %run sza_testbed.py
22/22: len(sza300l)
22/23: plt.plot(np.min([i for i in sza300l]))
22/24: plt.plot([np.min(i) for i in sza300l])
22/25: plt.plot(sza300l[18][:,:])
22/26: mins=[np.min(i) for i in sza300l]
22/27: plt.plot(mins, '-o')
24/1: import glob
24/2: y=glob.glob('/home/kamo/resources/icon-fuv/ncfiles/l1/*')
24/3: len(y)
24/4: z = [k +' {}'.format(i) for i,k in enumerate(y)]
24/5: z
24/6: %run sza_testbed.py
24/7: z
24/8: mins=[np.min(i) for i in sza300l]
24/9: plt.plot(mins, '-o')
24/10: plt.grid(which='both',axis='both')
24/11: y = y.sort()
24/12: z = [k +' {}'.format(i) for i,k in enumerate(y)]
24/13: y=glob.glob('/home/kamo/resources/icon-fuv/ncfiles/l1/*')
24/14: y.sort()
24/15: z = [k +' {}'.format(i) for i,k in enumerate(y)]
24/16: z
25/1: %run sza_testbed.py
25/2: %run sza_testbed.py
25/3: %run sza_testbed.py
25/4: %run sza_testbed.py
25/5: diffs
25/6: y=glob.glob('/home/kamo/resources/icon-fuv/ncfiles/l1/*')
25/7: y.sort()
25/8: z = [k +' {}'.format(i) for i,k in enumerate(y)]
25/9: z
25/10: mins=[np.min(i) for i in sza300l]
25/11: plt.plot(mins, '-o')
25/12: plt.plot(sza300l[-1][:,:])
25/13: plt.plot(sza300l[-2][:,:])
26/1: %run sza_testbed.py
26/2: plt.plot(sza300l[-2][:,:])
26/3: mins=[np.min(i) for i in sza300l]
26/4: plt.plot(mins, '-o')
26/5: plt.plot(sza300l[-5][:,:])
26/6: %run ../pres28_2021_04_26_Artifact_Removal/artifact_removal_testbed.py
26/7: %run ../pres28_2021_04_26_Artifact_Removal/artifact_removal_testbed.py
26/8: %run ../pres28_2021_04_26_Artifact_Removal/artifact_removal_testbed.py
26/9: cd ../pres28_2021_04_26_Artifact_Removal/
26/10: from artifact_removal_testbed import *
26/11: plotday(brs_l[0])
26/12: diffs
26/13: plt.plot(mins, '-o')
26/14: %run ../pres28_2021_04_26_Artifact_Removal/artifact_removal_testbed.py
26/15: %run ../pres28_2021_04_26_Artifact_Removal/artifact_removal_testbed.py
26/16: plotday(brs_l[0])
26/17: plotmeans(brs_l[0])
26/18: plotorb(brs_l[0][4])
26/19: plotorb(brs_l[0][7])
28/1: from iconfuv.misc import get_br_nights, lastfile
28/2: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-03-15_v03r003.NC'
28/3: l1 = netCDF4.Dataset(file, mode='r')
28/4: brs, brsc, _, _, _, _ = get_br_nights(l1)
28/5: brs[3].shape
28/6: %run sza_testbed.py
28/7: %run sza_testbed.py
28/8: %run sza_testbed.py
28/9: %run sza_testbed.py
28/10: sza300l[4].shape
28/11: plt.plot(np.min(sza300l[-5], axis=1))
28/12: x=1
28/13: a=3 if x==1 else pass
28/14: a=3 if x==1
28/15: mins=[np.min(i) for i in sza300l]
28/16: plt.plot(mins, '-o')
28/17: %run sza_testbed.py
28/18: mins=[np.min(i) for i in sza300l]
28/19: plt.plot(mins, '-o')
28/20: a = np.where(np.arange(3)<-3)[0]
28/21: a
28/22: b=np.sort(a)
28/23: b
28/24: len(b)
28/25: np.sort(np.arange(4))
28/26: %run sza_testbed.py
28/27: %run sza_testbed.py
28/28: plotday(brs_l[0], szas[0])
28/29: %run sza_testbed.py
28/30: plotday(brs_l[-2], szas_l[-2])
28/31: from ../pres28_2021_04_26_Artifact_Removal/artifact_removal_testbed import detectday
28/32: plotday(brs_l[-2], szas_l[-2])
28/33: from sza_testbed import plotday
28/34: plotday(brs_l[-2], szas_l[-2])
28/35: mins=[np.min(i) for i in sza300l]
28/36: plt.plot(mins, '-o')
28/37: plotday(brs_l[18], szas_l[18])
28/38: plt.plot(mins, '-o')
28/39: plotday(brs_l[22], szas_l[22])
28/40: plotday(brs_l[22], szas_l[22], stripe=5)
28/41: plotday(brs_l[22], szas_l[22], stripe=0)
28/42: detectday
28/43: from sza_testbed import *
28/44: detectday(brs_l[22],30)
28/45: szas_l[22].shape
28/46: szas_l[22][3].shape
28/47: plt.plot(szas_l[22][3])
28/48: plt.plot(np.flatten(np.array(szas_l[22])))
28/49: plt.plot(szas_l[22][6])
28/50: file = '/home/kamo/resources/icon-fuv/ncfiles/l0/ICON_L0P_FUV_Ancillary_2020-07-06_v03r001.NC'
28/51: anc = netCDF4.Dataset(file, mode='r')
28/52: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-07-06_v03r001.NC'
28/53: l1 = netCDF4.Dataset(file, mode='r')
28/54:
        mode = l1.variables['ICON_L1_FUV_Mode'][:]
        qual = l1.variables['ICON_L1_FUVA_SWP_Quality_Flag'][:]
        nind = (mode==2) & ((qual==0) | (qual==1))
        # nind = mode==2
        alt = anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_LATLONALT'][:,:,:,2]
        alt = alt[nind]
        ind = np.sum(alt<300, axis=1) - 1
        xx, yy = np.meshgrid(np.arange(alt.shape[0]), np.arange(6), indexing='ij')
        sza = anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_SZA'][:]
        sza = sza[nind]
        # szai = anc.variables['ICON_ANCILLARY_FUV_SC_SZA'][nind]
        # slt = anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_LST'][:]
        sza300 = sza[xx,ind,yy]
28/55: sza300.shape
28/56: plt.plot(np.min(sza300, axis=1))
28/57: plt.plot(szas_l[22][-1])
28/58: plotday(brs_l[22], szas_l[22], stripe=3)
28/59: len(brs_l[22])
28/60: plotday(brs_l[22], szas_l[22], stripe=3)
28/61: plotday(brs_l[22], szas_l[22], stripe=3)
28/62: plt.plot(szas_l[22][-1])
28/63: plotday(brs_l[22], szas_l[22], stripe=3)
28/64: plotday(brs_l[22], szas_l[22], stripe=3)
28/65: plt.plot(szas_l[22][5])
28/66: plt.plot(np.min(sza300, axis=1))
28/67:
        mode = l1.variables['ICON_L1_FUV_Mode'][:]
        qual = l1.variables['ICON_L1_FUVA_SWP_Quality_Flag'][:]
        nind = (mode==2) & ((qual==0) | (qual==1))
        nind = mode==2
        alt = anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_LATLONALT'][:,:,:,2]
        alt = alt[nind]
        ind = np.sum(alt<300, axis=1) - 1
        xx, yy = np.meshgrid(np.arange(alt.shape[0]), np.arange(6), indexing='ij')
        sza = anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_SZA'][:]
        sza = sza[nind]
        # szai = anc.variables['ICON_ANCILLARY_FUV_SC_SZA'][nind]
        # slt = anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_LST'][:]
        sza300 = sza[xx,ind,yy]
28/68: plt.plot(np.min(sza300, axis=1))
28/69: plt.plot(qual[mode==2])
28/70: plt.plot(qual[mode==2])
28/71: l1.variables['ICON_L1_FUVA_SWP_Quality_Flag']
28/72: plotday(brs_l[22], szas_l[22], stripe=3)
28/73: plotday(brs_l[23], szas_l[23], stripe=3)
28/74: plotday(brs_l[23], szas_l[23], stripe=3, vmax=200)
28/75: plotday(brs_l[24], szas_l[24], stripe=3, vmax=200)
28/76: plotday(brs_l[25], szas_l[25], stripe=3, vmax=200)
28/77: plotday(brs_l[25], szas_l[25], stripe=5, vmax=200)
28/78: plotday(brs_l[26], szas_l[26], stripe=5, vmax=200)
28/79: plotday(brs_l[26], szas_l[26], stripe=0, vmax=200)
28/80: plotday(brs_l[27], szas_l[27], stripe=0, vmax=200)
28/81: plotday(brs_l[27], szas_l[27], stripe=5, vmax=200)
28/82: plotday(brs_l[28], szas_l[28], stripe=5, vmax=200)
28/83: plotday(brs_l[29], szas_l[29], stripe=5, vmax=200)
28/84: plt.plot(mins, '-o')
29/1: max(3,5)
29/2: np.arange(5)[-1]
29/3: max(0,-1)
29/4: a = None; b=True
29/5:
if a or b>3:
    c=3
29/6: c
29/7:
if b or a>3:
    c=3
29/8: c
29/9:
if None>3:
    print('Yarrak')
29/10: None>3
30/1: %run runner.py 2020 241
30/2: ipdb.pm()
31/1: file = '/home/kamo/resources/icon-fuv/ncfiles/l2/ICON_L2-5_FUV_Night_2020-01-01_v03r000.NC'
31/2: l21 = netCDF4.Dataset(file, mode='r')
31/3: file = '/home/kamo/resources/icon-fuv/ncfiles/l2/ICON_L2-5_FUV_Night_2020-01-01_v04r000.NC'
31/4: l22 = netCDF4.Dataset(file, mode='r')
31/5: l21.History
31/6: type(l21.History)
31/7: type(l22.History)
31/8: l21.History
31/9: l22.History
31/10: l21.MODS
31/11: l22.MODS
31/12: type(l22.MODS)
32/1: %run runner.py 2020 241
33/1: %run runner.py 2020 241
33/2: %run plotter.py toh 2020-08-28
34/1: file = '/home/kamo/resources/icon-fuv/ncfiles/l2/ICON_L2-5_FUV_Night_2020-01-01_v03r000.NC'
34/2: l2 = netCDF4.Dataset(file, mode='r')
34/3: flag = l2.variables['ICON_L25_Quality_Flags']
34/4: flag
34/5: flag = flag[:]
34/6: plt.plot(flag)
34/7: qual = l2.variables['ICON_L25_Quality'][:]
34/8: plt.plot(qual)
34/9: qual.shape
34/10: plt.plot(flag[:,3])
34/11: (False or False) or None<95
34/12: None<95
34/13: None>95
34/14: None<95
34/15: True or False or False
34/16: True or (False or False)
34/17: (True or False )or False
38/1: %run forward.py
40/1: %run forward.py
40/2: w=signal.gaussian(51,std=7)
40/3: w.shape
40/4: plt.plot(w)
40/5: w[0]
40/6: w=signal.gaussian(51,std=20)
40/7: w[0]
40/8: plt.plot(w)
40/9: plt.plot(w, '-o')
41/1: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-01-08_v04r000.NC'
41/2: l1 = netCDF4.Dataset(file, mode='r')
41/3: tur = l1.variables['ICON_L1_FUV_Turret'][:]
41/4: plt.plot(ture)
41/5: plt.plot(tur)
41/6: l1.variables['ICON_L1_FUV_Turret']
41/7: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-02-07_v04r000.NC'
41/8: l1 = netCDF4.Dataset(file, mode='r')
41/9: tur = l1.variables['ICON_L1_FUV_Turret'][:]
41/10: plt.plot(tur)
41/11: np.max(tur)
41/12: np.min(tur)
42/1: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-01-18_v04r000.NC'
42/2: l1 = netCDF4.Dataset(file, mode='r')
42/3: tur = l1.variables['ICON_L1_FUV_Turret'][:]
42/4: np.min(tur)
42/5: np.max(tur)
42/6: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-01-28_v04r000.NC'
42/7: l1 = netCDF4.Dataset(file, mode='r')
42/8: tur = l1.variables['ICON_L1_FUV_Turret'][:]
42/9: np.min(tur)
42/10: np.max(tur)
42/11: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-02-17_v04r000.NC'
42/12: l1 = netCDF4.Dataset(file, mode='r')
42/13: tur = l1.variables['ICON_L1_FUV_Turret'][:]
42/14: np.max(tur)
42/15: np.min(tur)
42/16: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-02-27_v04r000.NC'
42/17: l1 = netCDF4.Dataset(file, mode='r')
42/18: tur = l1.variables['ICON_L1_FUV_Turret'][:]
42/19: np.min(tur)
42/20: np.max(tur)
42/21: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-03-09_v04r000.NC'
42/22: l1 = netCDF4.Dataset(file, mode='r')
42/23: tur = l1.variables['ICON_L1_FUV_Turret'][:]
42/24: np.max(tur)
42/25: np.min(tur)
43/1: ls
43/2:
def tur(file):
    l1 = netCDF4.Dataset(file, mode='r')
    tur = l1.variables['ICON_L1_FUV_Turret'][:]
    return np.min(tur), np.max(tur)
43/3: import glob
43/4: files = glob.glob('/home/kamo/resources/icon-fuv/ncfiles/l1/**2021**')
43/5: len(files)
43/6: mins, maxs = [], []
43/7:
for file in files:
    minn, maxx = tur(file)
    mins.append(minn)
    maxs.append(maxx)
43/8: mins
43/9: maxs
43/10:
for i,j in enumerate(mins):
    print(i, j)
43/11:
for i,j in enumerate(maxs):
    print(i, j)
43/12: files[31]
43/13: files[38]
43/14: file = files[38]
43/15: l1 = netCDF4.Dataset(file, mode='r')
43/16: tur = l1.variables['ICON_L1_FUV_Turret'][:]
43/17: plt.plot(tur)
43/18: file = files[31]
43/19: l1 = netCDF4.Dataset(file, mode='r')
43/20: tur = l1.variables['ICON_L1_FUV_Turret'][:]
43/21: np.hist(tur)
43/22: np.histogram(tur)
43/23: plt.plot(tur)
44/1:
def tur(file):
    l1 = netCDF4.Dataset(file, mode='r')
    tur = l1.variables['ICON_L1_FUV_Turret'][:]
    return np.min(tur), np.max(tur)
44/2: files = glob.glob('/home/kamo/resources/icon-fuv/ncfiles/l1/**2021**')
44/3: import glob
44/4: files = glob.glob('/home/kamo/resources/icon-fuv/ncfiles/l1/**2021**')
44/5: files.sort()
44/6: files
44/7:
for file in files:
    minn, maxx = tur(file)
    mins.append(minn)
    maxs.append(maxx)
44/8: import netCDF4
45/1: files = glob.glob('/home/kamo/resources/icon-fuv/ncfiles/l1/**2021**')
45/2: import glob
45/3: files = glob.glob('/home/kamo/resources/icon-fuv/ncfiles/l1/**2021**')
45/4: files.sort()
45/5:
def tur(file):
    l1 = netCDF4.Dataset(file, mode='r')
    tur = l1.variables['ICON_L1_FUV_Turret'][:]
    return np.min(tur), np.max(tur)
45/6:
for file in files:
    minn, maxx = tur(file)
    mins.append(minn)
    maxs.append(maxx)
45/7: files = glob.glob('/home/kamo/resources/icon-fuv/ncfiles/l1/**2021**')
45/8: files.sort()
45/9:
for file in files:
    minn, maxx = tur(file)
    mins.append(minn)
    maxs.append(maxx)
45/10: mins, maxs = [], []
45/11:
for file in files:
    minn, maxx = tur(file)
    mins.append(minn)
    maxs.append(maxx)
45/12:
for i,j in enumerate(maxs):
    print(i, j)
47/1: file = '/home/kamo/resources/icon-fuv/ncfiles/l0/ICON_L0P_FUV_Ancillary_2021-04-06_v03r000.NC'
47/2: anc = netCDF4.Dataset(file, mode='r')
47/3: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-04-06_v04r000.NC'
47/4: l1 = netCDF4.Dataset(file, mode='r')
47/5: tur = l1.variables['ICON_L1_FUV_Turret'][:]
47/6: plt.plot(tur)
47/7: anc.variables.keys()
47/8: plt.plot(anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_LATLONALT'][:,2,150,2])
47/9: anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_LATLONALT'][:].shape
47/10: plt.plot(anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_LATLONALT'][:,150,2,2])
47/11: plt.clear()
47/12: plt.clr()
47/13: plt.cla()
47/14: plt.plot(anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_LATLONALT'][:,150,2,2])
47/15: plt.plot(anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_LATLONALT'][:,150,:,2])
47/16: plt.cla()
47/17: plt.plot(anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_LATLONALT'][:,150,:,2])
47/18: plt.plot(anc.variables['ICON_ANCILLARY_FUVA_FOV_ZENITH_ANGLE'][:,150,:])
47/19: plt.plot(anc.variables['ICON_ANCILLARY_FUVA_FOV_ZENITH_ANGLE'][1800:2250,150,:])
47/20: asdasdasdasdasdasdasd
47/21: plt.figure(); plt.plot(tur[1800:2250])
47/22: plt.figure(); plt.plot(tur[1800:2250])
49/1: from keras.models import load_model
50/1: from keras.models import load_model
50/2: import tensorflow
50/3: tensorflow.__version__
51/1: tensorflow.__version__
51/2: import tensorflow
51/3: tensorflow.__version__
51/4: import keras
52/1: import keras
52/2: from keras.models import load_model
52/3: from keras import backend
52/4: from iconfuv.misc import get_br_nights
52/5: get_br_nights?
52/6: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-01_v03r004.NC'
52/7: l1 = netCDF4.Dataset(file, mode='r')
52/8: brs,_,_,_,_,_,_=get_br_nights(l1)
52/9: brs,_,_,_,_,_=get_br_nights(l1)
52/10: len(brs)
52/11: brs[2].shape
52/12: plt.imshow(brs[2][2])
52/13: ptm = './residual_network_v3.71.h5'
52/14: from remove_stars import remove_stars
52/15: import remove_stars
52/16: import remove_stars
52/17: remove_stars
52/18: amo = remove_stars(br[2], ptm)
52/19: amo = remove_stars(brs[2], ptm)
52/20: from remove_stars import remove_stars
52/21: amo = remove_stars(brs[2], ptm)
52/22: __get_br_nights__
52/23: a.b=None
52/24: from remove_stars import remove_stars
52/25: amo = remove_stars(brs[2], ptm)
52/26: amo = remove_stars(brs[2], ptm)
52/27: amo = remove_stars(brs[2], ptm)
53/1: plt.plot(np.arange(4))
54/1: import keras.models import load_model
54/2: from keras.models import load_model
55/1: from keras.models import load_model
56/1: from iconfuv.misc import get_br_nights
58/1: plt
58/2: plt.plot
59/1: import netCDF4
59/2: from iconfuv.misc import get_br_nights
59/3:
def get_br_nights(l1, anc=None):
    mirror_dir = ['M9','M6','M3','P0','P3','P6']
    mode = l1.variables['ICON_L1_FUV_Mode'][:]
    mode_night = (mode == 2).astype(np.int)
    if anc is not None:
        alt = anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_LATLONALT'][:,:,:,2]
        ind = np.sum(alt<300, axis=1) - 1
        xx, yy = np.meshgrid(np.arange(alt.shape[0]), np.arange(6), indexing='ij')
        sza = anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_SZA'][:]
        sza300 = np.min(sza[xx,ind,yy], axis=1)
    nights = np.diff(mode_night, prepend=0)
    nights[nights==-1] = 0
    idxs = np.where(mode==2)[0][:]
    nights = np.cumsum(nights)[idxs]
    brs = []
    brsc = []
    brs_err = []
    mask_arr = []
    szas = []
    for night in np.unique(nights):
        night_ind = np.where(nights==night)[0]
        br = np.zeros((6, len(night_ind), 256))
        brc = np.zeros((6, len(night_ind), 256))
        br_err = np.zeros((6, len(night_ind), 256))
        mask = np.zeros_like(br, dtype=np.bool)
        for i in range(6):
            tmp = l1.variables['ICON_L1_FUVA_SWP_PROF_%s' % mirror_dir[i]][idxs[night_ind],:]
            tmp2 = l1.variables['ICON_L1_FUVA_SWP_PROF_%s_CLEAN' % mirror_dir[i]][idxs[night_ind],:]
            br_err[i] = l1.variables['ICON_L1_FUVA_SWP_PROF_%s_Error' % mirror_dir[i]][idxs[night_ind],:].filled(fill_value=0)
            mask[i] = tmp.mask
            br[i] = tmp.filled(fill_value=0)
            brc[i] = tmp2.filled(fill_value=0)
        if anc is not None:
            szas.append(sza300[idxs[night_ind]])
        brs.append(br)
        brsc.append(brc)
        brs_err.append(br_err)
        mask_arr.append(mask)
    if anc is not None:
        return brs, brsc, szas, brs_err, mask_arr, nights, idxs
    else:
        return brs, brsc, brs_err, mask_arr, nights, idxs
59/4: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-01_v03r004.NC'
59/5: l1 = netCDF4.Dataset(file, mode='r')
59/6: brs,_,_,_,_,_=get_br_nights(l1)
59/7: from remove_stars import remove_stars
59/8: ls
59/9: cd scripts/
59/10: from remove_stars import remove_stars
59/11: amo = remove_stars(brs[2], ptm)
59/12: ptm = './residual_network_v3.71.h5'
59/13: amo = remove_stars(brs[2], ptm)
59/14: plt.imshow(amo)
59/15: plt.imshow(amo[2])
59/16: plt.figure(); plt.imshow(brs[2])
59/17: plt.figure(); plt.imshow(brs[2][2])
59/18: plt.figure(); plt.imshow(brs[2][2], vmax=amo[2].max())
60/1: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-01_v03r004.NC'
60/2: import netCDF4
60/3: l1 = netCDF4.Dataset(file, mode='r')
60/4: from iconfuv.misc import get_br_nights
60/5:
def get_br_nights(l1, anc=None):
    mirror_dir = ['M9','M6','M3','P0','P3','P6']
    mode = l1.variables['ICON_L1_FUV_Mode'][:]
    mode_night = (mode == 2).astype(np.int)
    if anc is not None:
        alt = anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_LATLONALT'][:,:,:,2]
        ind = np.sum(alt<300, axis=1) - 1
        xx, yy = np.meshgrid(np.arange(alt.shape[0]), np.arange(6), indexing='ij')
        sza = anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_SZA'][:]
        sza300 = np.min(sza[xx,ind,yy], axis=1)
    nights = np.diff(mode_night, prepend=0)
    nights[nights==-1] = 0
    idxs = np.where(mode==2)[0][:]
    nights = np.cumsum(nights)[idxs]
    brs = []
    brsc = []
    brs_err = []
    mask_arr = []
    szas = []
    for night in np.unique(nights):
        night_ind = np.where(nights==night)[0]
        br = np.zeros((6, len(night_ind), 256))
        brc = np.zeros((6, len(night_ind), 256))
        br_err = np.zeros((6, len(night_ind), 256))
        mask = np.zeros_like(br, dtype=np.bool)
        for i in range(6):
            tmp = l1.variables['ICON_L1_FUVA_SWP_PROF_%s' % mirror_dir[i]][idxs[night_ind],:]
            tmp2 = l1.variables['ICON_L1_FUVA_SWP_PROF_%s_CLEAN' % mirror_dir[i]][idxs[night_ind],:]
            br_err[i] = l1.variables['ICON_L1_FUVA_SWP_PROF_%s_Error' % mirror_dir[i]][idxs[night_ind],:].filled(fill_value=0)
            mask[i] = tmp.mask
            br[i] = tmp.filled(fill_value=0)
            brc[i] = tmp2.filled(fill_value=0)
        if anc is not None:
            szas.append(sza300[idxs[night_ind]])
        brs.append(br)
        brsc.append(brc)
        brs_err.append(br_err)
        mask_arr.append(mask)
    if anc is not None:
        return brs, brsc, szas, brs_err, mask_arr, nights, idxs
    else:
        return brs, brsc, brs_err, mask_arr, nights, idxs
60/6: brs,_,_,_,_,_=get_br_nights(l1)
60/7: len(brs)
60/8: brs[2].shape
60/9: mao = brs[0].copy()
60/10:
for i in range(14):
    mao = np.append(mao,brs[i+1],axis=1)
60/11: mao.shape
60/12: from remove_stars import remove_stars
60/13: ls
60/14: cd resources/icon-fuv/python3/scripts/
60/15: from remove_stars import remove_stars
60/16: ptm = './residual_network_v3.71.h5'
60/17: amo = remove_stars(mao, ptm)
60/18: plt.imshow(mao[2].T, origin='lower', aspect='auto', vmax=30, cmap='jet')
60/19: plt.imshow(amo[2].T, origin='lower', aspect='auto', vmax=30, cmap='jet')
60/20: plt.clorbar()
60/21: plt.colorbar()
60/22: plt.imshow(amo[2].T, origin='lower', aspect='auto', vmax=30, vmin=-5, cmap='jet')
60/23: plt.figure(); plt.imshow(mao[2].T, origin='lower', aspect='auto', vmax=30, vmin=-5, cmap='jet')
60/24: from artifact_removal2 import artifact_removal_orbit
60/25: from iconfuv.artifact_removal2 import artifact_removal_orbit
60/26: br = artifact_removal_orbit(brs[2],2)
60/27: plt.figure(); plt.imshow(brs[2][2].T, origin='lower', aspect='auto', vmax=30, vmin=-5, cmap='jet')
60/28: plt.figure(); plt.imshow(br[2].T, origin='lower', aspect='auto', vmax=30, vmin=-5, cmap='jet')
61/1: import netCDF4
61/2: from iconfuv.artifact_removal2 import artifact_removal
61/3: a = np.arange(50).reshape(5,10)
61/4: a
61/5: a[[(0,0), (0,-1), (-1,0), (-1,-1)]]=np.nan
61/6: np.where(a>47)
61/7: a
61/8: a.shape
61/9: a[([4,4],[5,6])]
61/10: a[([0,0,-1,-1],[0,-1,0,-1])]=np.nan
61/11: a = a.astype(np.float)
61/12: a[([0,0,-1,-1],[0,-1,0,-1])]=np.nan
61/13: a
61/14: a=np.repeat(a[:,:,np.newaxis],15, axis=2)
61/15: a.shape
61/16: a[:,:,4]
61/17: medtop = np.nanmedian(a[:,:2], axis=(0,1))
61/18: medtop.shape
61/19: medtop
61/20: b = np.ma.array(a, mask=np.isnan(a))
61/21: medtop = np.nanmedian(a[:,:2], axis=(0,1))
61/22: medtop = np.nanmedian(b[:,:2], axis=(0,1))
61/23: medtop
61/24: b
61/25: b[:,:,0]
61/26: c= b.copy()
61/27: medbot = np.nanmedian(b[:,-2:], axis=(0,1))
61/28: medbot
61/29:
x = np.ma.array(np.arange(9).reshape(3, 3), mask=[[1, 0, 0],

                                                  [1, 0, 0],

                                                  [0, 0, 0]])
61/30: x.filled(fill_value=np.arange(3))
61/31: x.filled(fill_value=np.arange(2))
61/32:
x = np.ma.array(np.arange(9).reshape(3, 3), mask=[[1, 1, 0],

                                                  [0, 0, 0],

                                                  [0, 0, 0]])
61/33: x.filled(fill_value=np.arange(3))
61/34: x
61/35: c.shape
61/36: medtops = np.repeat(medtop[pn.newaxis,np.newaxis,:],(5,10),axis=(0,1))
61/37: medtops = np.repeat(medtop[np.newaxis,np.newaxis,:],(5,10),axis=(0,1))
61/38: medtops = np.repeat(medtop[np.newaxis,:],10,axis=0)
61/39: medtops.shape
61/40: medtops
61/41: medtops = np.repeat(medtosp[np.newaxis,:],5,axis=0)
61/42: medtops = np.repeat(medtops[np.newaxis,:],5,axis=0)
61/43: medtops.shape
61/44: c[:,:2].shape
61/45: c[:,:2]=c[:,:2].filled(fill_value=medtops[:,:2])
61/46: c[:,:2,3]
61/47: c[:,:,3]
61/48: c[:,:,3].data
62/1: a=np.ones((2,3,4))*np.nan
62/2: a = np.ma.array(a, mask=np.isnan(a))
62/3: b = a.filled(fill_value=np.arange(3))
62/4: b = a.filled(fill_value=np.arange(3)[None,:,None])
62/5: b[:,0,:]
62/6: b[:,1,:]
62/7: b[:,2,:]
62/8: a.mask
62/9: b.mask
62/10: c=a.copy()
62/11: x.mask
62/12: c.mask
62/13: c[:] = a.filled(fill_value=np.arange(3)[None,:,None])
62/14: c.mask
62/15:
def get_br_nights(l1, anc=None):
    mirror_dir = ['M9','M6','M3','P0','P3','P6']
    mode = l1.variables['ICON_L1_FUV_Mode'][:]
    mode_night = (mode == 2).astype(np.int)
    if anc is not None:
        alt = anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_LATLONALT'][:,:,:,2]
        ind = np.sum(alt<300, axis=1) - 1
        xx, yy = np.meshgrid(np.arange(alt.shape[0]), np.arange(6), indexing='ij')
        sza = anc.variables['ICON_ANCILLARY_FUVA_TANGENTPOINTS_SZA'][:]
        sza300 = np.min(sza[xx,ind,yy], axis=1)
    nights = np.diff(mode_night, prepend=0)
    nights[nights==-1] = 0
    idxs = np.where(mode==2)[0][:]
    nights = np.cumsum(nights)[idxs]
    brs = []
    brsc = []
    brs_err = []
    mask_arr = []
    szas = []
    for night in np.unique(nights):
        night_ind = np.where(nights==night)[0]
        br = np.zeros((6, len(night_ind), 256))
        brc = np.zeros((6, len(night_ind), 256))
        br_err = np.zeros((6, len(night_ind), 256))
        mask = np.zeros_like(br, dtype=np.bool)
        for i in range(6):
            tmp = l1.variables['ICON_L1_FUVA_SWP_PROF_%s' % mirror_dir[i]][idxs[night_ind],:]
            tmp2 = l1.variables['ICON_L1_FUVA_SWP_PROF_%s_CLEAN' % mirror_dir[i]][idxs[night_ind],:]
            br_err[i] = l1.variables['ICON_L1_FUVA_SWP_PROF_%s_Error' % mirror_dir[i]][idxs[night_ind],:].filled(fill_value=0)
            mask[i] = tmp.mask
            br[i] = tmp.filled(fill_value=0)
            brc[i] = tmp2.filled(fill_value=0)
        if anc is not None:
            szas.append(sza300[idxs[night_ind]])
        brs.append(br)
        brsc.append(brc)
        brs_err.append(br_err)
        mask_arr.append(mask)
    if anc is not None:
        return brs, brsc, szas, brs_err, mask_arr, nights, idxs
    else:
        return brs, brsc, brs_err, mask_arr, nights, idxs
62/16: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-01_v03r004.NC'
62/17: l1 = netCDF4.Dataset(file, mode='r')
62/18: import netCDF4
62/19: l1 = netCDF4.Dataset(file, mode='r')
62/20: brs,_,_,_,_,_=get_br_nights(l1)
62/21: from iconfuv.artifact_removal2 import artifact_removal_orbit
62/22: br = artifact_removal_orbit(brs[2],2)
62/23: br = artifact_removal_orbit(brs[2],2, path_to_model='./residual_network_v3.71.h5')
62/24: plt.figure(); plt.imshow(br[2].T, origin='lower', aspect='auto', vmax=30, vmin=-5, cmap='jet')
62/25: plt.figure(); plt.imshow(brs[2][2].T, origin='lower', aspect='auto', vmax=30, vmin=-5, cmap='jet')
63/1: from iconfuv.misc import get_oplus
64/1: a = np.ma.array(a, mask=np.isnan(a))
64/2: a=np.arange(5)
64/3: a.shape
64/4: import netCDF4
64/5: a.shape
64/6: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-01_v03r004.NC'
64/7: l1 = netCDF4.Dataset(file, mode='r')
64/8: br = l1.variables['ICON_L1_FUVA_SWP_PROF_P3'][:]
64/9: br.shape
64/10: br.swapaxes(0,1).shape
64/11: from modify_l1 import rewriter
64/12: rewriter('2020-01-01')
64/13: rewriter('2020-01-01')
64/14: ipdb.pm()
64/15: rewriter('2020-01-01')
64/16: ipdb.pm()
64/17: rewriter('2020-01-01')
64/18: ipdb.pm()
64/19: rewriter('2020-01-01')
64/20: rewriter('2020-01-01')
64/21: ipdb.pm()
64/22: rewriter('2020-01-01')
64/23: rewriter('2020-01-01')
64/24: rewriter('2020-01-01')
64/25: a = 'asdasdsad'
64/26: a[3:6]='asd'
64/27: rewriter('2020-01-01')
64/28: rewriter('2020-01-01')
64/29: rewriter('2020-01-01')
64/30: rewriter('2020-01-01')
64/31: rewriter('2020-01-01')
64/32: l1.close()
64/33: l1_new.close()
64/34: rewriter('2020-01-01')
64/35: import netCDF4
65/1: rewriter('2020-01-01')
65/2: from modify_l1 import rewriter
65/3: rewriter('2020-01-01')
65/4: rewriter('2020-01-01')
65/5: rewriter('2020-01-01')
65/6: l1.close()
65/7: from modify_l1 import rewriter
65/8: rewriter('2020-01-01')
66/1: from modify_l1 import rewriter
66/2: rewriter('2020-04-02')
66/3: rewriter('2020-06-18'); rewriter('2020-10-17')
66/4: rewriter('2020-01-01')
66/5: rewriter('2020-01-01')
66/6: rewriter('2020-01-01')
66/7: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-01_v90r004.NC'
66/8: import netCDF4
66/9: l1 = netCDF4.Dataset(file, mode='r')
66/10: l1.variables.keys()
66/11: from iconfuv.misc import get_br_nights
66/12: brs,_,_,_,_,_=get_br_nights(l1)
66/13: plt.figure(); plt.imshow(brs[2][2].T, origin='lower', aspect='auto', vmax=30, vmin=-5, cmap='jet')
66/14: brs,brsc,_,_,_,_=get_br_nights(l1)
66/15: plt.figure(); plt.imshow(brsc[2][2].T, origin='lower', aspect='auto', vmax=30, vmin=-5, cmap='jet')
66/16: rewriter('2020-04-02'); rewriter('2020-06-18'); rewriter('2020-10-17')
66/17: rewriter('2020-02-02'); rewriter('2020-03-15'); rewriter('2020-11-27')
67/1: import netCDF4
67/2: file = '/home/kamo/resources/icon-fuv/ncfiles/l2/ICON_L2-5_FUV_Night_2020-01-01_v04r000.NC'
67/3: l2 = netCDF4.Dataset(file, mode='r')
67/4: qual = l2.variables['ICON_L25_Quality'][:]
67/5: qual.shape
67/6: qual[3,3]
67/7: l2.variables['ICON_L25_NMF2'][:].shape
67/8: %run artifact_update_retrieval_comparison.py
67/9: quals_old[0].shape
67/10: quals_old[1].shape
67/11: nmf2s_old[3].shape
67/12: nmf2s_q1_old[3].shape
67/13: quals_old_total = np.array(quals_old)
67/14: quals_old.total.shape
67/15: quals_old_total.shape
67/16:
for i in quals_old:
    i=i.flatten()
    print('Q0:{:.2f}%, Q.5:{:.2f}%, Q1:{:.2f}%'.format(len(i==0.0)/len(i), len(i==0.5)/len(i), len(i==1.0)/len(i)))
67/17: i.shape
67/18: len(i==0.0)
67/19: len(i==0.5)
67/20: sum(i==0.5)
67/21:
for i in quals_old:
    i=i.flatten()
    print('Q0:{:.2f}%, Q.5:{:.2f}%, Q1:{:.2f}%'.format(sum(i==0.0)/len(i), sum(i==0.5)/len(i), sum(i==1.0)/len(i)))
67/22:
for i in quals_new:
    i=i.flatten()
    print('Q0:{:.2f}%, Q.5:{:.2f}%, Q1:{:.2f}%'.format(len(i==0.0)/len(i), len(i==0.5)/len(i), len(i==1.0)/len(i)))
67/23:
for i in quals_new:
    i=i.flatten()
    print('Q0:{:.2f}%, Q.5:{:.2f}%, Q1:{:.2f}%'.format(sum(i==0.0)/len(i), sum(i==0.5)/len(i), sum(i==1.0)/len(i)))
67/24:
for i in nmf2s_old:
    print(i.mean())
67/25:
for i in nmf2s_new:
    print(i.mean())
67/26:
for i in nmf2s_q1_old:
    print(i.mean())
67/27:
for i in nmf2s_q1_old:
    print(i.median())
67/28:
for i in nmf2s_q1_old:
    print(np.mean(i))
67/29:
for i in nmf2s_q1_old:
    print(np.median(i))
67/30:
for i in nmf2s_q1_new:
    print(np.mean(i))
67/31: plt.hist(nmf2s_q1_old[0])
67/32: plt.figure(); plt.hist(nmf2s_q1_new[0])
68/1: file = '/home/kamo/resources/icon-fuv/ncfiles/l2/ICON_L2-5_FUV_Night_2020-01-01_v04r000.NC'
68/2: import netCDF4
68/3: l2 = netCDF4.Dataset(file, mode='r')
68/4: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-01_v90r004.NC'
68/5: l1_new = netCDF4.Dataset(file, mode='r')
68/6: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-01_v03r004.NC'
68/7: l1_old = netCDF4.Dataset(file, mode='r')
68/8: mode = l1.variables['ICON_L1_FUV_Mode'][:]
68/9: mode = l1_old.variables['ICON_L1_FUV_Mode'][:]
68/10:
    mirror_dir = ['M9','M6','M3','P0','P3','P6']
    profiles_new = np.zeros((6, len(mode), 256))
    for i in range(6):
        profiles[i] = l1_new.variables['ICON_L1_FUVA_SWP_PROF_%s_CLEAN' % mirror_dir[i]][:]
68/11:
    mirror_dir = ['M9','M6','M3','P0','P3','P6']
    profiles_new = np.zeros((6, len(mode), 256))
    for i in range(6):
        profiles_new[i] = l1_new.variables['ICON_L1_FUVA_SWP_PROF_%s_CLEAN' % mirror_dir[i]][:]
68/12:
    mirror_dir = ['M9','M6','M3','P0','P3','P6']
    profiles_old = np.zeros((6, len(mode), 256))
    for i in range(6):
        profiles_old[i] = l1_new.variables['ICON_L1_FUVA_SWP_PROF_%s_CLEAN' % mirror_dir[i]][:]
68/13: t = l1_new.variables['ICON_L1_FUVA_SWP_Center_Times'][:]
68/14: profiles_new = profiles_new[:,mode==2,:]
68/15: profiles_old = profiles_old[:,mode==2,:]
68/16: t=t[mode==2]
68/17: t[100]
68/18: t[120]
68/19: t[115]
68/20: plt.plot(profiles_old[3,114,:], np.arange(256))
68/21: plt.plot(profiles_new[3,114,:], np.arange(256))
68/22:
    mirror_dir = ['M9','M6','M3','P0','P3','P6']
    profiles_old = np.zeros((6, len(mode), 256))
    for i in range(6):
        profiles_old[i] = l1_old.variables['ICON_L1_FUVA_SWP_PROF_%s_CLEAN' % mirror_dir[i]][:]
68/23: plt.plot(profiles_old[3,114,:], np.arange(256))
68/24: profiles_old = profiles_old[:,mode==2,:]
68/25: plt.plot(profiles_old[3,114,:], np.arange(256))
68/26: plt.plot(profiles_new[3,114,:], np.arange(256))
68/27: file = '/home/kamo/resources/icon-fuv/ncfiles/l2/ICON_L2-5_FUV_Night_2020-01-01_v90r000.NC'
68/28: l2_new = netCDF4.Dataset(file, mode='r')
68/29: op = l2.variables['ICON_L25_O_Plus_Density'][:]
68/30: op_new = l2_new.variables['ICON_L25_O_Plus_Density'][:]
68/31: alt = l2.variables['ICON_L25_O_Plus_Profile_Altitude'][:]
68/32: op.shape
68/33: plt.figure(); plt.plot(op[114,:,3], alt[114,:,3])
68/34: plt.plot(op_new[114,:,3], alt_new[114,:,3])
68/35: plt.plot(op_new[114,:,3], alt[114,:,3])
69/1: file = '/home/kamo/resources/icon-fuv/ncfiles/l0/ICON_L0P_FUV_Ancillary_2021-04-06_v03r000.NC'
69/2: import netCDF4; anc1 = netCDF4.Dataset(file, mode='r')
69/3: file = '/home/kamo/resources/icon-fuv/ncfiles/l0/ICON_L0P_FUV_Ancillary_2021-04-06_v03r100.NC'
69/4: anc2 = netCDF4.Dataset(file, mode='r')
69/5: plt.plot(anc1.variables['ICON_ANCILLARY_FUVA_FOV_ZENITH_ANGLE'][1800:2250,150,:])
69/6: plt.figure(); plt.plot(anc2.variables['ICON_ANCILLARY_FUVA_FOV_ZENITH_ANGLE'][1800:2250,150,:])
69/7: plt.plot(anc1.variables['ICON_ANCILLARY_FUVA_FOV_ZENITH_ANGLE'][1800:1900,150,:])
69/8: plt.figure(); plt.plot(anc2.variables['ICON_ANCILLARY_FUVA_FOV_ZENITH_ANGLE'][1800:1900,150,:])
69/9: for i in range(5):plt.plot(anc1.variables['ICON_ANCILLARY_FUVA_FOV_ZENITH_ANGLE'][1800:1900,150,:])
69/10: for i in range(5):plt.plot(anc1.variables['ICON_ANCILLARY_FUVA_FOV_ZENITH_ANGLE'][1800:1900,150,i], label='stripe {}'.format(i)); plt.legend()
69/11: for i in range(6):plt.plot(anc1.variables['ICON_ANCILLARY_FUVA_FOV_ZENITH_ANGLE'][1800:1900,150,i], label='stripe {}'.format(i)); plt.legend()
69/12: plt.figure(); for i in range(6):plt.plot(anc2.variables['ICON_ANCILLARY_FUVA_FOV_ZENITH_ANGLE'][1800:1900,150,i], label='stripe {}'.format(i)); plt.legend()
69/13: plt.figure()
71/1: from iconfuv.misc import lastfile
71/2: date='2020-04-06'
71/3:         file_l2 = lastfile(path_dir+'l2/ICON_L2-5_FUV_Night_{}_v03r100*'.format(date))
71/4: path_dir = '/home/kamo/resources/icon-fuv/ncfiles/'
71/5:         file_l2 = lastfile(path_dir+'l2/ICON_L2-5_FUV_Night_{}_v03r100*'.format(date))
71/6: date='2020-01-01'
71/7: file = '/home/kamo/resources/icon-fuv/ncfiles/l2/ICON_L2-5_FUV_Night_2020-01-01_v90r000.NC'
71/8: file[-20:]
71/9: file[-30:]
71/10: file[-40:]
71/11: file[-41:]
71/12: file[-41:-3]
71/13: i=3
71/14: '%d' %i
71/15: 'kom%d' %i
71/16: 'kom%d' %i+'as'
72/1: from iconfuv.misc import profiler
72/2: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-06-18_v03r002.NC'
73/1: from iconfuv.misc import profiler
73/2: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-06-18_v03r002.NC'
73/3: l1 = netCDF4.Dataset(file, mode='r')
73/4: import netCDF4
73/5: profiles = profiler(l1)
73/6: l1 = netCDF4.Dataset(file, mode='r')
73/7: profiles = profiler(l1)
73/8: profiles.shape
73/9: from iconfuv.misc import get_br_nights
73/10: brs,brsc,_,_,_,_=get_br_nights(l1)
73/11: brsc[5].shape
73/12: plt.figure(); plt.imshow(brsc[2][2].T, origin='lower', aspect='auto', vmax=30, vmin=-5, cmap='jet')
73/13: plt.figure(); plt.imshow(brsc[2][5].T, origin='lower', aspect='auto', vmax=30, vmin=-5, cmap='jet')
73/14: plt.figure(); plt.imshow(brsc[2][7].T, origin='lower', aspect='auto', vmax=30, vmin=-5, cmap='jet')
73/15: plt.figure(); plt.imshow(brsc[5][2].T, origin='lower', aspect='auto', vmax=30, vmin=-5, cmap='jet')
73/16: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-06-18_v90r002.NC'
73/17: l1 = netCDF4.Dataset(file, mode='r')
73/18: brs2,brsc2,_,_,_,_=get_br_nights(l1)
73/19: plt.figure(); plt.imshow(brsc2[5][2].T, origin='lower', aspect='auto', vmax=30, vmin=-5, cmap='jet')
73/20: brs[5].shape
73/21: from iconfuv.artifact_removal2 import artifact_removal_orbit
73/22: amo = artifact_removal_orbit(brs[5],2,'./residual_network_v3.71.h5')
73/23: amo = artifact_removal_orbit(brs[5],2,'./residual_network_v3.71.h5')
73/24: plt.imshow(brs[:,75,:])
73/25: plt.imshow(brs[5][:,75,:])
73/26: plt.imshow(brs[5][:,75,:].T, aspect='auto', origin='lower')
74/1: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-04-06_v04r000.NC'
74/2: l1 = netCDF4.Dataset(file, mode='r')
74/3: a = l1.variables['ICON_L1_FUVA_SWP_PROF_P6_Error'][:]
74/4: a.shape
74/5: np.max(a)
74/6: np.min(a)
79/1: import matplotlib.pyplot as plt
80/1: matplotlib.pyplot
80/2: import matplotlib.pyplot
80/3: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-04-06_v04r000.NC'
80/4: import netCDF4
80/5: l1 = netCDF4.Dataset(file, mode='r')
80/6: a = l1.variables['ICON_L1_FUVA_SWP_PROF_P6_Error'][:]
80/7: a[(3,4)]
80/8: type(a)
80/9: a.size
80/10: a.shape
80/11: sum(a.mask)
80/12: np.sum(a.mask)
80/13: np.sum(a.mask)/a.size
80/14: a.shape
80/15: a2 = a[:,100:250]
80/16: type(a2)
80/17: b = np.ma.masked_array([[1,2,3],[4,5,6]],mask=[[1,1,0],[0,0,0]])
80/18: b
80/19: np.sum(b,axis=0)
80/20: np.sum(b.mask,axis=0)
80/21: np.sum(a2.mask,axis=1)
80/22: np.sum(a2.mask,axis=1).max()
80/23: np.histogram(np.sum(a2.mask,axis=1))
80/24: b = l1.variables['ICON_L1_FUVA_SWP_PROF_M6_Error'][:][:,100:250]
80/25: np.histogram(np.sum(b.mask,axis=1))
80/26: file = '/home/kamo/resources/icon-fuv/ncfiles/l2/ICON_L2-5_FUV_Night_2021-04-06_v03r101.NC'
80/27: l2 = netCDF4.Dataset(file, mode='r')
80/28: l2.History
80/29: l2.variables['ICON_L25_Quality']
80/30: l2.variables['ICON_L25_Quality_Flags']
80/31: l2.History
80/32: l2.MODS
80/33: type(l2.History)
80/34: type(l2.MODS)
80/35: type(l2.variables['ICON_L25_Quality_Flags'])
80/36: type(l2.variables['ICON_L25_Quality_Flags'].setncattr)
80/37: type(l2.variables['ICON_L25_Quality_Flags'].notes)
80/38: type(l2.variables['ICON_L25_Quality_Flags'].CatDesc)
80/39: l2.variables['ICON_L25_Quality_Flags'].CatDesc
80/40: l2.variables['ICON_L25_Quality_Flags'].FieldNam
80/41: l2.variables['ICON_L25_Quality_Flags'].FillVal
80/42: l2.variables['ICON_L25_Quality_Flags'].Long_Name
80/43: l2.variables['ICON_L25_Quality_Flags'].Var_Notes
80/44: print(l2.variables['ICON_L25_Quality_Flags'].Var_Notes)
80/45: print(l2.History)
80/46: print(l2.Generated_By)
80/47: l2.Software_Version
81/1: import glob
81/2: a = glob.glob('dset1/')
81/3: a
81/4: a = glob.glob('dset1')
81/5: a
81/6: a = glob.glob('./dset1')
81/7: a
81/8: ls dset1
81/9: a = glob.glob('/home/kamo/resources/icon-fuv/ncfiles/l1/dset1')
81/10: a
81/11: a = glob.glob('dset1/*')
81/12: a
81/13: a[4]
81/14: a4[-20:]
81/15: a[4][-20:]
81/16: a[4][-21:]
81/17: a[4][-21:-10]
81/18: a[4][-21:-11]
81/19: pwd
81/20: j scr
82/1: %run profile_extractor.py
82/2: %run profile_extractor.py
82/3: %run profile_extractor.py
82/4: %run profile_extractor.py
82/5: %run profile_extractor.py
82/6: %run profile_extractor.py
82/7: %run profile_extractor.py
82/8: %run profile_extractor.py
82/9: %run profile_extractor.py
82/10: %run profile_extractor.py
83/1: %run profile_extractor.py
83/2: %run profile_extractor.py
83/3: %run profile_extractor.py
84/1: %run profile_extractor.py
85/1: path_dir = '/home/kamo/resources/icon-fuv/ncfiles/l1/'
85/2: files = glob.glob(path_dir + 'dset2/*')
85/3: files.sort()
85/4: import glob
85/5: files = glob.glob(path_dir + 'dset2/*')
85/6: files.sort()
85/7: files
85/8: files[28]
85/9: files[29:-1]
85/10: %run profile_extractor.py
86/1: '{:.2d}'.format(5)
86/2: '{:.2d}'.format(5.0)
86/3: '{:.2f}'.format(5.0)
86/4: '{:02d}'.format(5)
86/5: '{:04d}'.format(5)
86/6: '{:04d}'.format(15)
86/7: ind = np.random.permutation(20160)
86/8: ind[:10]
86/9: import glob
86/10: files = glob.glob('./*')
86/11: len(files)
86/12: cp
86/13: mv
86/14: files[0]
86/15:
for i,file in enumerate(files):
    mv file './s{:05d}'.format(i)+file[2:]
86/16: import os
86/17: files.sort()
86/18: files[:3]
86/19: print('./s{:05d}'.format(i)+files[2])
86/20: print('./s{:05d}'.format(3)+files[2])
86/21: print('./s{:05d}'.format(3)+files[2][2:])
86/22: print('./s{:05d}_'.format(3)+files[2][2:])
86/23: print(files[2])
86/24:
for i in range(len(files)):
    os.rename(files[i],'./s{:05d}_'.format(i+1)+files[i][2:])
86/25:
for i in range(len(files)):
    os.rename(files[i],'./s{:05d}_'.format(ind[i]+1)+files[i][9:])
86/26: files = glob.glob('./*')
86/27: files.sort()
86/28: files[3]
86/29: files[3][9:]
86/30: ind[3]
86/31:
for i in range(len(files)):
    os.rename(files[i],'./s{:05d}_'.format(ind[i]+1)+files[i][9:])
87/1: import glob
87/2: files = glob.glob('./*')
87/3: files.sort()
87/4: len(files)
87/5: import os
87/6: ind = np.random.permutation(20500)
87/7:
for i in range(len(files)):
    os.rename(files[i],'./s{:05d}_'.format(ind[i]+1)+files[i][2:])
88/1: import pandas
88/2: import pandas as pd
88/3: pandas
88/4: pd
88/5: import glob
88/6: ds1 = glob.glob('./dset1/figs/*')
88/7: ds1.sort()
88/8: ds1[3]
88/9: ds1 = ds1[2068]
88/10: ds1 = glob.glob('./dset1/figs/*')
88/11: ds1.sort()
88/12: ds1[2068]
88/13: ds1 = ds1[:2068]
88/14: len(ds1)
88/15: ds1[3]
88/16: ds1[3][20:-4]
88/17:
for i in range(len(ds1)):
    ds1[i] = ds1[i][20:-4]
88/18: ds1[3]
88/19: ds1[3].split('_Ep_')
88/20: ds1s = []
88/21:
for i in range(len(ds1)):
    ds1s.append(ds1[i].split('_Ep_'))
88/22: ds1s[3]
88/23: f1 = pd.DataFrame(ds1s)
88/24: f1
88/25: ds1[3]
88/26: ds1.sort()
88/27: ds1[3]
88/28: ds1s = []
88/29:
for i in range(len(ds1)):
    ds1s.append(ds1[i].split('_Ep_'))
88/30: f1 = pd.DataFrame(ds1s)
88/31: ds2 = glob.glob('./dset2/figs/*')
88/32: ds2.sort()
88/33: ds2 = ds2[:2040]
88/34:
for i in range(len(ds2)):
    ds2[i] = ds2[i][20:-4]
88/35: ds2[3]
88/36: ds2.sort()
88/37: ds2s = []
88/38:
for i in range(len(ds2)):
    ds2s.append(ds2[i].split('_Ep_'))
88/39: ds2s[3]
88/40: f2 = pd.DataFrame(ds2s)
88/41: df = pd.concat([f1,f2])
88/42: df
88/43: f.rename({'0':'Date','1':'Epoch'})
88/44: df.rename({'0':'Date','1':'Epoch'})
88/45: df=df.rename({'0':'Date','1':'Epoch'})
88/46: df
88/47: df=df.rename(columns={'0':'Date','1':'Epoch'})
88/48: df
88/49: df.rename(columns={'0':'Date','1':'Epoch'})
88/50: df.rename(columns={"0":"Date"})
88/51: df.rename(columns={0:'Date',1:'Epoch'})
88/52: f1
88/53: f1.rename(columns={0:'Date',1:'Epoch'})
88/54: f2.rename(columns={0:'Date',1:'Epoch'})
88/55: f1.to_csv('dataset1.csv')
88/56: f2.to_csv('dataset2.csv')
88/57: f1
88/58: f1=f1.rename(columns={0:'Date',1:'Epoch'})
88/59: f2=f2.rename(columns={0:'Date',1:'Epoch'})
88/60: f1.to_csv('dataset1.csv')
88/61: f2.to_csv('dataset2.csv')
89/1: pwd
89/2: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-04-06_v04r000.NC'
89/3: l1 = netCDF4.Dataset(file, mode='r')
89/4: dd=l1.variables['ICON_L1_FUVA_SWP_Center_Times'][:]
89/5: dd[3]
89/6:
from dateutil import parser
import datetime
89/7: dn=parser.parse(dd[3])
89/8: dn
89/9: dn < datetime.datetime(2020,5,10, tzinfo=dn.tzinfo)
89/10: dn < datetime.datetime(2022,5,10, tzinfo=dn.tzinfo)
89/11: pw
89/12: pwd
89/13: cd scripts
89/14: from modify_l1 import rewriter
89/15: date = '2020-01-02'
89/16: rewriter(date)
89/17: rewriter(date)
89/18: rewriter(date)
89/19: from keras.models import load_model
89/20: mo = load_model('cnn_model_SW_old_v5.4/')
89/21: mo = load_model('cnn_model_SW_old_v5.4/saved_model.pb')
89/22: import tensorflow as tf
89/23: mo = tf.keras.models.load_model('cnn_model_SW_old_v5.4/saved_model.pb')
89/24: mo = tf.keras.models.load_model('cnn_model_SW_old_v5.4/')
89/25: mo = tf.keras.models.load_model('cnn_model_SW_old_v5.4')
89/26: mo = tf.keras.models.load_model('cnn_model_SW_old_v5.4/variables/')
89/27: mo = tf.keras.models.load_model('cnn_model_SW_new_v5.4/')
89/28: mo = tf.saved_model.load('cnn_model_SW_new_v5.4/')
89/29: from tf.saved_model import load
89/30: from tf import saved_model.load as load
89/31: from tensorflow import saved_model.load as load
89/32: from tensorflow.saved_model import load
89/33: rewriter(date)
89/34: rewriter(date)
89/35: mo.predict()
89/36: mo
89/37: mo.tensorflow_version
89/38: mo.optimizer
89/39: mo.signatures
89/40: mo.summary()
90/1: from keras.models import load_model
90/2: path_dir = '/home/kamo/resources/icon-fuv/ncfiles/'
90/3:         path = path_dir + '/../python3/scripts/cnn_model_SW_old_v5.4'
90/4: mo = load_model(path)
90/5: import tensorflow as tf
90/6: model = tf.saved_model.load(path)
90/7: model.evaluate()
90/8: model.predict()
90/9: model.Predict()
90/10: model = tf.saved_model.load(path+'saved_model.pb')
90/11: model = tf.saved_model.load(path+'/saved_model.pb')
91/1: import keras
91/2: keras.__version__
92/1: from keras.models import load_model
93/1: from keras.models import load_model
93/2: import tensorflow
93/3: tensorflow.__version__
94/1: import keras
94/2: keras.__version__
94/3: from keras.models import load_model
94/4: path_dir = '/home/kamo/resources/icon-fuv/ncfiles/'
94/5:         path = path_dir + '/../python3/scripts/cnn_model_SW_old_v5.4'
94/6: mo = load_model(path)
94/7: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-01-02_v04r000.NC'
94/8: l1 = netCDF4.Dataset(file, mode='r')
94/9: import netCDF4
94/10: l1 = netCDF4.Dataset(file, mode='r')
94/11: from modify_l1 import rewriter
95/1: import netCDF4
95/2: date = '2020-01-03'
95/3: rewrite(date)
95/4: from modify_l1 import rewriter
95/5: rewriter(date)
95/6: from iconfuv.misc import get_br_nights
95/7: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-03_v03r003.NC'
95/8: l1 = netCDF4.Dataset(file, mode='r')
95/9: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-03_v90r003.NC'
95/10: l11 = netCDF4.Dataset(file, mode='r')
95/11: brs,brsc,_,_,_,_=get_br_nights(l1)
95/12: brs2,brsc2,_,_,_,_=get_br_nights(l11)
95/13: plt.imshow(brs[5][:,75,:].T, aspect='auto', origin='lower')
95/14: import matplotlib.pyplot as plt
95/15: plt.imshow(brs[5][:,75,:].T, aspect='auto', origin='lower')
95/16: plt.savefig('amo.png')
95/17: plt.imshow(brs2[5][:,75,:].T, aspect='auto', origin='lower')
95/18: plt.savefig('amo2.png')
95/19: plt.imshow(brs2[5][:,:,2].T, aspect='auto', origin='lower')
96/1: plt.plot(np.arange(5))
96/2: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-03_v03r003.NC'
96/3: l1 = netCDF4.Dataset(file, mode='r')
96/4: import netCDF4
96/5: l1 = netCDF4.Dataset(file, mode='r')
96/6: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-03_v90r003.NC'
96/7: l11 = netCDF4.Dataset(file, mode='r')
96/8: brs,brsc,_,_,_,_=get_br_nights(l1)
96/9: from iconfuv.misc import get_br_nights
96/10: brs, brsc, _, _, _, _ = get_br_nights(l1)
96/11: brs2,brsc2,_,_,_,_=get_br_nights(l11)
96/12: plt.imshow(brs2[5][:,:,2].T, aspect='auto', origin='lower')
96/13: plt.imshow(brs2[5][2,:,:].T, aspect='auto', origin='lower')
96/14: plt.imshow(brs[5][2,:,:].T, aspect='auto', origin='lower')
96/15: plt.imshow(brs2[5][2,:,:].T, aspect='auto', origin='lower')
96/16: plt.imshow(brs[5][2,:,:].T, aspect='auto', origin='lower')
96/17: brs[5].shape
96/18: import keras
96/19: keras.__version__
96/20: path_dir = '/home/kamo/resources/icon-fuv/ncfiles/'
96/21:         path = path_dir + '/../python3/scripts/cnn_model_SW_old_v5.4'
96/22: mo = load_model(path)
96/23: from keras.models import load_model
96/24: mo = load_model(path)
96/25: from iconfuv.artifact_removal2 import remove_stars
96/26: amo = remove_stars(brs[5],path)
96/27: plt.imshow(brs[5][2,:,:].T, aspect='auto', origin='lower')
96/28: plt.imshow(amo[2,:,:].T, aspect='auto', origin='lower')
96/29: plt.imshow(brs[5][2,:,:].T, aspect='auto', origin='lower')
96/30: plt.imshow(amo[2,:,:].T, aspect='auto', origin='lower')
96/31: plt.figure(); plt.imshow(brs[5][2,:,:].T, aspect='auto', origin='lower', vmax=120)
96/32: date = '2020-01-03'
96/33: rewriter(date)
96/34: from modify_l1 import rewriter
96/35: rewriter(date)
96/36: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-03_v90r003.NC'
96/37: l11.close()
96/38: l11 = netCDF4.Dataset(file, mode='r')
96/39: brs2,brsc2,_,_,_,_=get_br_nights(l11)
96/40: plt.figure(); plt.imshow(brs[5][2,:,:].T, aspect='auto', origin='lower', vmax=120)
96/41: plt.figure(); plt.imshow(brs2[5][2,:,:].T, aspect='auto', origin='lower', vmax=120)
96/42: rewriter(date)
96/43: l11.close()
96/44: rewriter(date)
96/45: l1.closE()
96/46: l1.close()
96/47: rewriter(date)
96/48: rewriter(date)
96/49: amo = remove_stars(brs[5],path)
96/50: plt.figure(); plt.imshow(amo[2,:,:].T, aspect='auto', origin='lower', vmax=120)
96/51: plt.figure(); plt.imshow(brs[5][2,:,:].T, aspect='auto', origin='lower', vmax=120)
96/52:         path2 = path_dir + '/../python3/scripts/residual_network_v3.71.h5''
96/53:         path2 = path_dir + '/../python3/scripts/residual_network_v3.71.h5'
96/54: amo2 = remove_stars(brs[5],path2)
96/55: plt.figure(); plt.imshow(brs[5][2,:,:].T, aspect='auto', origin='lower', vmax=120)
96/56: plt.figure(); plt.imshow(amo[2,:,:].T, aspect='auto', origin='lower', vmax=120)
96/57: plt.figure(); plt.imshow(amo2[2,:,:].T, aspect='auto', origin='lower', vmax=120)
96/58: keras.__version__
97/1: import keras
97/2: keras.__version__
98/1: plt.plot(np.arange(4))
98/2: from iconfuv.artifact_removal2 import remove_stars
98/3: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-03_v03r003.NC'
98/4: l1 = netCDF4.Dataset(file, mode='r')
98/5: import netCDF4
98/6: l1 = netCDF4.Dataset(file, mode='r')
98/7: brs, brsc, _, _, _, _ = get_br_nights(l1)
98/8: from iconfuv.misc import get_br_nights
98/9: brs, brsc, _, _, _, _ = get_br_nights(l1)
98/10: amo = remove_stars(brs[5])
98/11: path_dir = '/home/kamo/resources/icon-fuv/ncfiles/'
98/12:         path = path_dir + '/../python3/scripts/cnn_model_SW_old_v5.4'
98/13: amo = remove_stars(brs[5], path)
98/14: plt.figure(); plt.imshow(amo[2,:,:].T, aspect='auto', origin='lower', vmax=120)
98/15: plt.figure(); plt.imshow(brs[5][2,:,:].T, aspect='auto', origin='lower', vmax=120)
98/16: plt.figure(); plt.imshow(brsc[5][2,:,:].T, aspect='auto', origin='lower', vmax=120)
98/17: from iconfuv.artifact_removal2 import artifact_removal_orbit
98/18: amo2 = artifact_removal_orbit(brs[5], 2, path)
98/19: amo2.shape
98/20: amo.shape
98/21: plt.figure(); plt.imshow(amo[2,:,:].T, aspect='auto', origin='lower', vmax=120)
98/22: plt.figure(); plt.imshow(amo2[2,:,:].T, aspect='auto', origin='lower', vmax=120)
98/23:     mode = l1.variables['ICON_L1_FUV_Mode'][:]
98/24:
    mirror_dir = ['M9','M6','M3','P0','P3','P6']
    profiles = np.zeros((6, len(mode), 256))
    for i in range(6):
        profiles[i] = l1.variables['ICON_L1_FUVA_SWP_PROF_%s' % mirror_dir[i]][:]
98/25: profiles.shape
98/26:     profiles = np.swapaxes(profiles, 1, 2)
98/27: profiles.shape
98/28: from iconfuv.artifact_removal2 import artifact_removal
98/29: amos = artifact_removal(profiles, channel=1, fuv_mode=mode, path_to_model=path)
98/30: amos.shape
98/31: plt.imshow(profiles[2,:,:100],aspect='auto',origin='lower')
98/32: plt.imshow(profiles[2,:,mode[:100]],aspect='auto',origin='lower')
98/33: mode.shape
98/34: plt.imshow(profiles[2,:,(mode==2)[:100]],aspect='auto',origin='lower')
98/35: len(mode==2)
98/36: sum(mode==2)
98/37: (mode==2)[:100]
98/38: (mode==2)[:100].shape
98/39: plt.imshow(profiles[2,:,np.where(mode==2)[0][:100]],aspect='auto',origin='lower')
98/40: plt.imshow(profiles[2,:,np.where(mode==2)[0][:100]].T,aspect='auto',origin='lower')
98/41: plt.imshow(amos[2,:,np.where(mode==2)[0][:100]].T,aspect='auto',origin='lower')
98/42: plt.imshow(profiles[2,:,np.where(mode==2)[0][:100]].T,aspect='auto',origin='lower', vmax=95)
98/43: plt.imshow(amos[2,:,np.where(mode==2)[0][:100]].T,aspect='auto',origin='lower')
98/44: plt.imshow(profiles[2,:,np.where(mode==2)[0][:100]].T,aspect='auto',origin='lower', vmax=95)
98/45: plt.imshow(amos[2,:,np.where(mode==2)[0][:100]].T,aspect='auto',origin='lower')
98/46: plt.imshow(profiles[2,:,np.where(mode==2)[0][:100]].T,aspect='auto',origin='lower', vmax=95)
98/47: plt.imshow(amos[2,:,np.where(mode==2)[0][:100]].T,aspect='auto',origin='lower')
98/48: from modify_l1 import rewriter
98/49: date = '2020-01-03'
98/50: rewriter(date)
98/51: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-03_v90r003.NC'
98/52: l11 = netCDF4.Dataset(file, mode='r')
98/53: brs2,brsc2,_,_,_,_=get_br_nights(l11)
98/54: plt.figure(); plt.imshow(brs[5][2,:,:].T, aspect='auto', origin='lower', vmax=120)
98/55: plt.figure(); plt.imshow(brsc[5][2,:,:].T, aspect='auto', origin='lower', vmax=120)
98/56: plt.figure(); plt.imshow(brsc2[5][2,:,:].T, aspect='auto', origin='lower', vmax=120)
98/57: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-06-18_v03r002.NC'
98/58: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-06-18_v03r002.NC'
98/59: date = '2020-06-18'
98/60: rewriter(date)
98/61: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-06-18_v03r002.NC'
98/62: l1 = netCDF4.Dataset(file, mode='r')
98/63: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-06-18_v90r002.NC'
98/64: l11 = netCDF4.Dataset(file, mode='r')
98/65: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-06-18_v90r002_old.NC'
98/66: l10 = netCDF4.Dataset(file, mode='r')
98/67: brs, brsc, _, _, _, _ = get_br_nights(l1)
98/68: brs0, brsc0, _, _, _, _ = get_br_nights(l10)
98/69: brs1, brsc1, _, _, _, _ = get_br_nights(l11)
98/70: plt.figure(); plt.imshow(brs[5][2,:,:].T, aspect='auto', origin='lower', vmax=120)
98/71: plt.figure(); plt.imshow(brs[5][2,:,:].T, aspect='auto', origin='lower', cmap=jet, vmax=120)
98/72: plt.figure(); plt.imshow(brs[5][2,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=120)
98/73: plt.figure(); plt.imshow(brs[-5][2,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=120)
98/74: plt.figure(); plt.imshow(brs[-5][2,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=60)
98/75: plt.figure(); plt.imshow(brs[-5][2,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=60)
98/76: plt.figure(); plt.imshow(brsc0[-5][2,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=60)
98/77: plt.figure(); plt.imshow(brs[-5][2,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=30, vmin=-5)
98/78: plt.figure(); plt.imshow(brsc0[-5][2,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=30, vmin=-5)
98/79: plt.figure(); plt.imshow(brsc1[-5][2,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=30, vmin=-5)
98/80: plt.figure(); plt.imshow(brsc0[-5][2,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/81: plt.figure(); plt.imshow(brsc1[-5][2,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/82: plt.figure(); plt.imshow(brsc0[-5][2,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=30, vmin=-5)
98/83: plt.colorbar()
98/84: plt.figure(); plt.imshow(brsc0[-5][2,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=30, vmin=-5)
98/85: plt.colorbar()
98/86: plt.figure(); plt.imshow(brsc1[-5][2,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=30, vmin=-5)
98/87: plt.colorbar()
98/88: plt.figure(); plt.imshow(brs[-5][2,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=30, vmin=-5)
98/89: plt.colorbar()
98/90: day=True
98/91:     modeval = 1 if day else 2
98/92: modeval
98/93: day=False
98/94:     modeval = 1 if day else 2
98/95: modeval
98/96: plt.figure(); plt.imshow(brs[-5][5,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=30, vmin=-5)
98/97: plt.figure(); plt.imshow(brsc0[-5][5,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=30, vmin=-5)
98/98: plt.figure(); plt.imshow(brsc1[-5][5,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=30, vmin=-5)
98/99: plt.figure(); plt.imshow(brsc[-5][5,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=30, vmin=-5)
98/100: brs, brsc, _, _, _, _ = get_br_nights(l1, day=True)
98/101: brs0, brsc0, _, _, _, _ = get_br_nights(l10, day=True)
98/102: brs1, brsc1, _, _, _, _ = get_br_nights(l11, day=True)
98/103: plt.figure(); plt.imshow(brs[-5][5,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/104: plt.figure(); plt.imshow(brs[-5][5,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=1e3)
98/105: plt.figure(); plt.imshow(brsc[-5][5,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=1e3)
98/106: plt.figure(); plt.imshow(brsc0[-5][5,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=1e3)
98/107: plt.figure(); plt.imshow(brsc1[-5][5,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=1e3)
98/108: l11.close()
98/109: date
98/110: rewriter(date)
98/111: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-06-18_v90r002.NC'
98/112: l11 = netCDF4.Dataset(file, mode='r')
98/113: brs1, brsc1, _, _, _, _ = get_br_nights(l11, day=True)
98/114: plt.figure(); plt.imshow(brsc[-5][5,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=1e3)
98/115: plt.figure(); plt.imshow(brsc0[-5][5,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=1e3)
98/116: plt.figure(); plt.imshow(brs[-5][5,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=1e3)
98/117: plt.figure(); plt.imshow(brsc1[-5][5,:,:].T, aspect='auto', origin='lower', cmap='jet', vmax=1e3)
98/118: plt.figure(); plt.imshow(brsc1[-5][5,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/119: plt.figure(); plt.imshow(brsc1[-9][5,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/120:         path = path_dir + '/../python3/scripts/cnn_model_SW_new_v5.4'
98/121: amo = remove_stars(brs[5], path)
98/122: plt.figure(); plt.imshow(brs[5][5,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/123: plt.figure(); plt.imshow(brsc[5][5,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/124: plt.figure(); plt.imshow(brs[5][5,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/125: plt.figure(); plt.imshow(brsc[5][5,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/126: plt.figure(); plt.imshow(brs[5][5,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/127: plt.figure(); plt.imshow(amo[5,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/128: plt.figure(); plt.imshow(amo[4,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/129: plt.figure(); plt.imshow(amo[3,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/130: plt.figure(); plt.imshow(amo[2,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/131: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-03_v03r003.NC'
98/132: l1 = netCDF4.Dataset(file, mode='r')
98/133: brs, brsc, _, _, _, _ = get_br_nights(l1, day=True)
98/134: plt.figure(); plt.imshow(brs[5][5,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/135:         path = path_dir + '/../python3/scripts/cnn_model_SW_old_v5.4'
98/136: amo = remove_stars(brs[5], path)
98/137: plt.figure(); plt.imshow(amo[2,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/138: plt.figure(); plt.imshow(amo[4,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/139: plt.figure(); plt.imshow(brsc1[-9][5,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/140: plt.figure(); plt.imshow(amo[4,:,:].T, aspect='auto', origin='lower', cmap='jet')
98/141: plt.figure(); plt.imshow(brsc1[0][5,:,:].T, aspect='auto', origin='lower', cmap='jet')
99/1: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-01-03_v03r003.NC'
99/2: l1 = netCDF4.Dataset(file, mode='r')
99/3: import netCDF4
99/4: brs, brsc, _, _, _, _ = get_br_nights(l1, day=True)
99/5: from iconfuv.misc import get_br_nights
99/6: brs, brsc, _, _, _, _ = get_br_nights(l1, day=True)
99/7: l1 = netCDF4.Dataset(file, mode='r')
99/8: brs, brsc, _, _, _, _ = get_br_nights(l1, day=True)
99/9: from iconfuv.artifact_removal2 import remove_stars
99/10: path_dir = '/home/kamo/resources/icon-fuv/ncfiles/'
99/11:         path = path_dir + '/../python3/scripts/cnn_model_SW_old_v5.4'
99/12: amo = remove_stars(brs[5], path)
99/13: plt.figure(); plt.imshow(amo[4,:,:].T, aspect='auto', origin='lower', cmap='jet')
99/14: brs[5].max()
99/15: brs[5].shape
99/16: np.isnan(brs[5])
99/17: np.isnan(brs[5]).shape
99/18: np.sum(np.isnan(brs[5]))
99/19: brs[5].min()
99/20: brs[5].max()
99/21: bro = brs[5].copy()
99/22: bro[bro<0]==0
99/23: bro[bro<0]=0
99/24: bro.min()
99/25: amo2 = remove_stars(bro, path)
99/26: plt.figure(); plt.imshow(amo2[4,:,:].T, aspect='auto', origin='lower', cmap='jet')
99/27: plt.figure(); plt.imshow(bro[4,:,:].T, aspect='auto', origin='lower', cmap='jet')
99/28: plt.figure(); plt.imshow(amo2[4,:,:].T, aspect='auto', origin='lower', cmap='jet')
99/29: plt.colorbar()
99/30: plt.colorbar()
99/31: plt.colorbar()
99/32: plt.figure(); plt.imshow(brs[5][4,:,:].T, aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
99/33: plt.title('Original Input')
99/34: plt.figure(); plt.imshow(amo[4,:,:].T, aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
99/35: plt.title('Output of Original')
99/36: plt.figure(); plt.imshow(bro[4,:,:].T, aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
99/37: plt.title('Nonnegative Input')
99/38: plt.figure(); plt.imshow(amo2[4,:,:].T, aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
99/39: plt.title('Output of Nonnegative')
99/40: plt.title('Output of Nonnegative Input')
99/41: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-06-18_v03r002.NC'
99/42: l1 = netCDF4.Dataset(file, mode='r')
99/43: brs, brsc, _, _, _, _ = get_br_nights(l1, day=True)
99/44: plt.figure(); plt.imshow(brs[5][4,:,:].T, aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
99/45: brs[5].min()
99/46:         path = path_dir + '/../python3/scripts/cnn_model_SW_new_v5.4'
99/47: amo = remove_stars(brs[5], path)
99/48: bro = brs[5].copy()
99/49: bro[bro<0]=0
99/50: amo2 = remove_stars(bro, path)
99/51: plt.figure(); plt.imshow(amo[4,:,:].T, aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
99/52: plt.figure(); plt.imshow(amo2[4,:,:].T, aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
99/53: plt.figure(); plt.imshow(brs[5][4,:,:].T, aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
101/1: plt.plot(np.arange(4))
102/1: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-06-18_v03r002.NC'
102/2: import netCDF4
102/3: l1 = netCDF4.Dataset(file, mode='r')
102/4: from iconfuv.misc import get_br_nights
102/5: brs, brsc, _, _, _, _ = get_br_nights(l1, day=True)
102/6: brs[5].min()
102/7: brs[5][4].min()
102/8: plt.hist(brs[5][4])
102/9: plt.hist(brs[5][4][:])
102/10: am = np.sort(brs[5][4][:])
102/11: am.shape
102/12: am = np.sort(brs[5][4].flatten)
102/13: am = np.sort(brs[5][4].flatten())
102/14: am.shape
102/15: am[-1]
102/16: am[0]
102/17: plt.plot(am[:50])
102/18: plt.plot(am[:250])
102/19: am = brs[5][4].T
102/20: plt.figure(); plt.imshow(am<-100, aspect='auto', origin='lower', cmap='jet')
102/21: plt.figure(); plt.imshow(am<0, aspect='auto', origin='lower', cmap='jet')
102/22: am.shape
102/23: plt.plot(am[:,100])
103/1: import netCDF4
103/2: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-11-28_v03r001.NC'
103/3: l1 = netCDF4.Dataset(file, mode='r')
103/4: mode = l1_old.variables['ICON_L1_FUV_Mode'][:]
103/5: mode = l1.variables['ICON_L1_FUV_Mode'][:]
103/6: br = l1.variables['ICON_L1_FUVA_SWP_PROF_P0_CLEAN'][mode==1]
103/7: br.shape
103/8: w,v = np.linalg.eigh(br.T@br)
103/9: w,v = np.linalg.eigh(br.T @ br)
103/10: amo = br.T @ br
103/11: br = br.filled(0)
103/12: w,v = np.linalg.eigh(br.T @ br)
103/13: w.shape
103/14: v.shape
103/15: plt.plot(w)
103/16: plt.plot(np.log(w+1e-5))
103/17: plt.plot(v[:,-1])
103/18: plt.plot(v[:,-2])
103/19: plt.plot(v[:,-3])
103/20: plt.plot(v[:,-4])
103/21: plt.plot(v[:,-5])
103/22: plt.plot(v[:,-6])
103/23: plt.plot(v[:,-16])
103/24: plt.plot(v[:,-116])
103/25: plt.plot(v[:,-50])
103/26: plt.plot(v[:,-40])
103/27: plt.plot(v[:,-30])
103/28: plt.plot(v[:,-20])
103/29: plt.plot(v[:,-10])
103/30: br0 = br - np.mean(br, axis=0)
103/31: plt.plot(br[0])
103/32: plt.plot(br0[0])
103/33: w2,v2 = np.linalg.eigh(br0.T @ br0)
103/34: plt.plot(v[:,-1])
103/35: plt.plot(v2[:,-1])
103/36: plt.plot(v2[:,-2])
103/37: plt.plot(v2[:,-3])
103/38: plt.plot(v2[:,-10])
104/1: path = '/home/kamo/resources/icon-fuv/ncfiles/l1/'
104/2: amo = np.genfromtxt(path+'dataset1.csv')
104/3: amo.shape
104/4: amo[0]
104/5: amo[50]
104/6: import pandas as pd
104/7: amo = np.genfromtxt(path+'dataset1.csv', delimiter=',')
104/8: amo[0]
104/9: amo[4]
104/10: df = pd.read_csv(path+'dataset1.csv', sep=',')
104/11: df
104/12: df['dates']
104/13: df['Date']
104/14: from iconfuv.misc import lastfile
104/15: path
104/16: lastfile(path+'2020-01-03')
104/17: lastfile(path+'*2020-01-03*')
104/18: import glob
104/19: glob.glob(path+'2020-01-03')
104/20: glob.glob(path+'*2020-01-03*')
104/21: glob.glob(path+'*2020-01-03*')[-1]
104/22: df['Date'=='2019-11-16']
104/23: df.loc[df[['Date']=='2019-11-16']]
104/24: df.loc[df['Date']=='2019-11-16']
104/25: df.loc[df['Date']=='2019-11-16']['Epoch']
104/26: np.array(df.loc[df['Date']=='2019-11-16']['Epoch'])
104/27: df.loc[df['Date']=='2019-11-16']['Epoch'][2]
104/28: df['Date']
104/29: set(df['Date'])
104/30: a = np.empty()
104/31: a = np.empty(None,256,6)
104/32: a = np.empty((None,256,6))
104/33: a = np.empty((0,256,6))
104/34: a.shape
104/35: b = np.ones((5,256,6))
104/36: a.append(b,axis=0)
104/37: np.stack((a,b),axis=0)
104/38: np.append((a,b),axis=0)
104/39: c=np.vstack((a,b))
104/40: c.shape
104/41: np.random.permutation(10)
104/42: path
104/43: ls
104/44: cd resources/icon-fuv/python3/scripts/
104/45: ls
104/46: cd star_network_training/
104/47: from model import read_rawdata
104/48: from model import read_rawdata
104/49: from model import read_rawdata
104/50: from model import read_rawdata
104/51: from model import read_rawdata
104/52: amo = read_rawdata(path+'dataset1.csv',path+'/dset1/')
104/53: amo = read_rawdata(path+'dataset1.csv',path+'/dset1/')
104/54: amo = read_rawdata(path+'dataset1.csv',path+'/dset1/')
104/55: amo = read_rawdata(path+'dataset1.csv',path+'/dset1/')
104/56: ipdb.pm()
104/57: amo = read_rawdata(path+'dataset1.csv',path+'/dset1/')
104/58: amo.shape
104/59: plt.imshow(amo[100], aspect='auto', cmap='jet', origin='lower')
104/60: plt.plot(amo[100])
104/61: plt.plot(amo[np.random.randint(2000)])
104/62: plt.plot(amo[np.random.randint(2000)])
104/63: plt.plot(amo[np.random.randint(2000)])
104/64: plt.plot(amo[np.random.randint(2000)])
104/65: plt.plot(amo[np.random.randint(2000)])
104/66: plt.plot(amo[np.random.randint(2000)])
104/67: plt.plot(amo[np.random.randint(2000)])
104/68: plt.plot(amo[np.random.randint(2000)])
104/69: plt.plot(amo[np.random.randint(2000)])
104/70: plt.plot(amo[np.random.randint(2000)])
104/71: l1.close()
104/72: path
104/73: from model import generate_data2
104/74: generate_data2()
104/75: generate_data2()
104/76: generate_data2()
104/77: ipdb.pm()
104/78: generate_data2()
105/1: cd resources/icon-fuv/python3/scripts/
105/2: cd star_network_training/
105/3: from model import generate_data2
105/4: generate_data2()
105/5: generate_data2()
105/6: generate_data2()
105/7: generate_data2()
105/8: generate_data2()
106/1: from model import generate_data2
106/2: generate_data2()
107/1: generate_data2()
107/2: from model import generate_data2
107/3: generate_data2()
108/1: amo = np.load('/home/kamo/resources/icon-fuv/ncfiles/l1/synthetic1/D_LW_old_nS=25_maxA=1e+04_noise=0_smooth=0_v4.30/P0000/L1000_000.npy')
108/2: cd /home/kamo/resources/icon-fuv/ncfiles/l1/synthetic1/D_LW_old_nS=25_maxA=1e+04_noise=0_smooth=0_v4.30/
108/3: cd P0021/
108/4: amo = np.load('L1_021_000.npy')
108/5: amo = np.load('L1_021_000.npy', allow_pickle=True)
108/6: amo.shape
109/1: cd D_LW_new_nS=25_maxA=1e+04_noise=0_smooth=0_v4.30/P0002
109/2: amo = np.load('L1_002_005.npy')
109/3: amo = np.load('L1_002_005.npy', allow_pickle=True)
109/4: type(amo)
109/5: amo[3]
109/6: amo.item.get()
109/7: amo.item.get('x0')
109/8: amo
109/9: amo['image_clean']
109/10: dtype(amo)
109/11: type(amo)
109/12: amo[1]
109/13: amo
109/14: amo[0][0].shape
109/15: type(amo[0])
109/16: type(amo[0][0])
109/17: type(amo[0][0][0])
109/18: amo
109/19: amo = amo.item()
109/20: type(amo)
109/21: amo['image_clean'].shape
109/22: plt.plot(amo['image_clean'])
109/23: plt.plot(amo['image_ori'])
109/24: plt.plot(amo['image_clean'])
109/25: plt.plot(amo['image_stars'])
109/26: plt.plot(amo['image_clean'])
109/27: plt.figure(); plt.plot(amo['image_stars'])
110/1: from model import load_data
110/2: x,y = load_data()
110/3: x,y = load_data()
110/4: from model import load_data
110/5: x,y = load_data()
110/6: x,y = load_data()
110/7: x,y = load_data()
110/8: x.shape
110/9: y.shape
110/10: plt.plot(x[5])
110/11: plt.plot(x[5,:,:,0])
110/12: plt.plot(y[5,:,:,0])
110/13: plt.plot(y[5,:,:,0])
110/14: plt.plot(x[5,:,:,0])
110/15: plt.plot(x[5,:,:,0]-y[5,:,:,0])
110/16: plt.plot(x[15,:,:,0]-y[15,:,:,0])
110/17: plt.plot(x[125,:,:,0]-y[125,:,:,0])
110/18: maxamp=1e4
110/19: minamp=20
110/20: maxlog=np.log10(maxamp)
110/21: minlog=np.log10(minamp)
110/22: amp = np.random.rand()*(max_log - min_log) + min_log
110/23: amp = np.random.rand()*(maxlog - minlog) + minlog
110/24: amp
110/25: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/26: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/27: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/28: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/29: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/30: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/31: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/32: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/33: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/34: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/35: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/36: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/37: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/38: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/39: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/40: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/41: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/42: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/43: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/44: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/45: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/46: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/47: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/48: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/49: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/50: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/51: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/52: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/53: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/54: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/55: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/56: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/57: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/58: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/59: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/60: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/61: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/62: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/63: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/64: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/65: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/66: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/67: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/68: 10**(np.random.rand()*(maxlog - minlog) + minlog)
110/69: from model import _synthetize_stars
110/70: stars,x0s,y0s,amps = _synthetize_stars(25,wavelength='LW',period='old')
110/71: from model import generate_data2
110/72: generate_data2()
110/73: generate_data2()
110/74: x,y = load_data()
110/75: x,y = load_data()
110/76: plt.plot(x[125,:,:,0]-y[125,:,:,0])
110/77: plt.plot(x[12,:,:,0]-y[12,:,:,0])
110/78: plt.plot(x[1,:,:,0]-y[1,:,:,0])
110/79: plt.plot(x[2,:,:,0]-y[2,:,:,0])
110/80: plt.plot(x[2,:,:,0])
110/81: plt.plot(x[4,:,:,0])
110/82: plt.plot(x[6,:,:,0])
110/83: plt.plot(x[8,:,:,0])
110/84: plt.plot(x[8,:,:,0]-y[8,:,:,0])
110/85: plt.plot(x[9,:,:,0]-y[9,:,:,0])
110/86: plt.plot(x[9,:,:,0])
110/87: plt.plot(x[10,:,:,0])
110/88: generate_data2()
110/89: t
111/1: from model import generate_data2
111/2: generate_data2()
112/1: from model import generate_data2
112/2: generate_data2()
113/1: import netCDF4
113/2: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-11-28_v03r001.NC'
113/3: l1 = netCDF4.Dataset(file, mode='r')
113/4: l1.variables.keys()
113/5: print(l1.variables.keys())
113/6: print(list(l1.variables.keys()))
113/7:
for i in list(l1.variables.keys()):
    print (i)
115/1: from model import load_data
115/2: x,y = load_data()
115/3: x,y = load_data()
115/4: plt.plot(x[9,:,:,0])
115/5: plt.plot(y[9,:,:,0])
115/6: plt.plot(y[10,:,:,0])
115/7: plt.plot(x[10,:,:,0])
115/8: plt.plot(x[8,:,:,0]-y[8,:,:,0])
115/9: plt.plot(x[3,:,:,0]-y[3,:,:,0])
115/10: plt.plot(x[33,:,:,0]-y[33,:,:,0])
115/11: plt.plot(x[333,:,:,0]-y[333,:,:,0])
115/12: plt.plot(x[333,:,:,0])
115/13: plt.plot(y[333,:,:,0])
116/1: from model import generate_data2
116/2: generate_data2()
117/1: from model import generate_data2
117/2: from model import generate_data2
117/3: generate_data2()
119/1: import torch
119/2: torch.cuda.is_available()
119/3: torch.cuda.current_device()
119/4: torch.cuda.device_count()
119/5: torch.cuda.get_device_name()
119/6: torch.cuda.get_device_capability()
119/7: torch.cuda.get_device_properties()
119/8: torch.cuda.get_device_properties(0)
119/9: print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')
119/10: print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')
120/1: from model import load_data
120/2: x,y = load_data()
120/3: from model import load_data
120/4: plt.plot(x[333,:,:,0])
120/5: plt.plot(y[333,:,:,0])
120/6: plt.plot(y[333,:,:,0])
120/7: plt.plot(x[3,:,:,0]-y[3,:,:,0])
120/8: plt.plot(x[33,:,:,0]-y[33,:,:,0])
120/9: plt.plot(x[31,:,:,0]-y[31,:,:,0])
120/10: plt.plot(x[31,:,:,0])
120/11: x.shape
120/12: x,y = load_data()
120/13: plt.plot(x[31,:,:,0])
120/14: plt.plot(x[31,:,:,0]-y[31,:,:,0])
120/15: plt.plot(x[311,:,:,0]-y[311,:,:,0])
120/16: plt.plot(x[311,:,:,0]-y[311,:,:,0])
120/17: plt.plot(x[31,:,:,0])
120/18: plt.plot(x[351,:,:,0])
120/19: np.arange(6).reshape(3,2).sort()
120/20: a=np.arange(6).reshape(3,2).sort()
120/21: a
120/22: a=np.sort(np.arange(6).reshape(3,2))
120/23: a
121/1: from model import load_data
121/2: ?np.linalg.eig
121/3: ?np.linalg.svd
121/4: ?np.linalg.svd
121/5: np.arange(9).reshape(3,3)
121/6: x,y = load_data()
121/7: ls
121/8: rpath = '/home/kamo/resources/icon-fuv/ncfiles/l1/synthetic1/D_LW_new_nS=25_maxA=3e+05_noise=0_smooth=0_v4.30/P0000/'
121/9: import glob
121/10: glob.glob(rpath)
121/11: glob.glob(rpath+'*')
121/12: files = glob.glob(rpath+'*')
121/13: files.sort()
121/14: files[:4]
121/15: x,y=[],[]
121/16:
for file in files:
    d = np.load(file,allow_pickle=True).item()
    x.append(d['image_stars'])
    y.append(d['image_clean'])
121/17: len(x)
121/18: x[0].shape
121/19: plt.plot(x[3])
121/20: plt.plot(x[3])
121/21: fig, ax = plt.subplots(1,2)
121/22: ax[0].plot(x[3])
121/23: ax[1].plot(y[3])
121/24: fig, ax = plt.subplots(1,2, sharey=True)
121/25: ax[0].plot(x[3])
121/26: ax[1].plot(y[3])
121/27: plt.tight_layout()
121/28: fig, ax = plt.subplots(1,2, sharey=True)
121/29: fig.get_size_inches()
121/30:
for i in range(31):
    fig, ax = plt.subplots(1,2, sharey=True, figsize=(12.2,5.9))
    ax[0].plot(x[i])
    ax[1].plot(y[i])
    plt.savefig('plt_{}.png'.format(i))
    plt.clf()
121/31: plt.clear()
121/32: plt.clf('all')
121/33: plt.clf()
121/34: plt.close()
121/35:
for i in range(31):
    plt.close()
121/36:
for i in range(31):
    plt.plot(y[i])
    plt.savefig('plt_{}.png'.format(i))
121/37:
for i in range(31):
    plt.plot(y[i])
    plt.savefig('plt_{}.png'.format(i))
    plt.cla()
122/1: from notebook.auth import passwd
122/2: passwd()
124/1: from model import generate_data2
125/1: from model import generate_data2
125/2: generate_data2()
126/1: from model import generate_data2
126/2: from model import generate_data2
126/3: generate_data2()
128/1: import numpy
128/2: import torch
129/1: import torch
129/2:
import torch
torch.cuda.is_available()
129/3:
import torch
torch.cuda.device(0)
129/4:
import torch
torch.cuda.device_count()
129/5:
import torch
torch.cuda.get_device_name(0)
129/6: import nibabel
129/7:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt

im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
im.shape
129/8: plt.imshow(im[:,:,100])
129/9:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt

im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
im = im.get_fdata()
129/10: plt.imshow(im[:,:,100])
129/11:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
im = im.get_fdata()
129/12: plt.imshow(im[:,:,100])
129/13:
for i in range(im.shape[2]):
    plt.imshow(im[:,:,i])
    plt.pause(0.1)
129/14:
fig, ax = plt.subplots(1,1)
for i in range(im.shape[2]):
    ax.imshow(im[:,:,i])
    plt.pause(0.1)
    plt.cla()
129/15:
fig, ax = plt.subplots(1,1)
for i in range(im.shape[2]):
    ax.imshow(im[:,:,i])
    plt.pause(0.1)
    plt.clf()
129/16:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
im = im.get_fdata()
129/17:
for i in range(im.shape[2]):
    clear_output(wait=True)
    plt.imshow(im[:,:,i])
    plt.pause(0.1)
129/18: asd=3
129/19:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
im = im.get_fdata()
129/20: asd=3
129/21:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
im = im.get_fdata()
129/22:
for i in range(im.shape[2]):
    clear_output(wait=True)
    plt.imshow(im[:,:,i])
    plt.title(i)
    plt.pause(0.1)
129/23:
import glob

glob.glob('dataset/training/BraTS20_Training_001/*')
129/24:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz')
im = im.get_fdata()
129/25:
for i in range(im.shape[2]):
    clear_output(wait=True)
    plt.imshow(im[:,:,i])
    plt.title(i)
    plt.pause(0.1)
129/26: type(im)
129/27: im.dtype
129/28: np.max(im)
129/29: np.min(im)
129/30: plt.hist(im)
129/31: plt.hist(im.flatten())
130/1:
from keras import backend as K
K.tensorflow_backend._get_available_gpus()
130/2: from keras import backend as k
130/3: import keras
130/4: from tensorflow import keras
130/5: from tensorflow.python.keras import backend as K
130/6: K.tensorflow_backend._get_available_gpus()
130/7:
import tensorflow as tf
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
130/8: tf.test.is_gpu_available
130/9: tf.test.is_gpu_available()
130/10: tf.config.list_physical_devices('GPU')
131/1: import tensorflow as tf
131/2: tf.config.list_physical_devices('GPU')
131/3:
from tensorflow.python.client import device_lib 
print(device_lib.list_local_devices())
131/4: session = tf.Session(config=tf.ConfigProto(log_device_placement=True))
131/5:
Import tensorflow as tf
print(tf.test.is_built_with_cuda())
131/6: print(tf.test.is_built_with_cuda())
131/7: print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))
131/8: sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))
131/9: tf.test.is_gpu_available
131/10: tf.test.is_gpu_available()
131/11: tf.test.gpu_device_name()
132/1: import tensorflow as tf
133/1: import tensorflow as tf
133/2: tf.test.gpu_device_name()
133/3: tf.test.is_gpu_available()
134/1: import tensorflow as tf
129/32: print("Hello World")
129/33:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz')
im = im.get_fdata()
129/34:
import glob

glob.glob('dataset/training/BraTS20_Training_001/*')
129/35:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz')
im = im.get_fdata()
129/36:
import glob

glob.glob('dataset/training/BraTS20_Training_001/*')
129/37:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
129/38:
z = 100
fig, ax = plt.subplots(1,5, figsize=(15,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(seg[:,:,z])
ax[4].imshow(t2[:,:,z])
ax[0].set_title('t1')
ax[1].set_title('t1ce')
ax[2].set_title('flair')
ax[3].set_title('seg')
ax[4].set_title('t2')


# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
129/39:
z = 100
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(seg[:,:,z])
ax[4].imshow(t2[:,:,z])
ax[0].set_title('t1')
ax[1].set_title('t1ce')
ax[2].set_title('flair')
ax[3].set_title('seg')
ax[4].set_title('t2')


# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
129/40:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
129/41:
z = 80
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(seg[:,:,z])
ax[4].imshow(t2[:,:,z])
ax[0].set_title('t1')
ax[1].set_title('t1ce')
ax[2].set_title('flair')
ax[3].set_title('seg')
ax[4].set_title('t2')


# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
129/42: max(seg)
129/43: np.max(seg)
129/44: np.sum(seg==3)
129/45: np.sum(seg==2)
129/46: np.sum(seg==1)
129/47: np.sum(seg==0)
129/48: seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz')
129/49: seg
129/50: seg.get_header
129/51:
z = 80
for z in [5, 25, 55, 85, 135]:
    fig, ax = plt.subplots(1,5, figsize=(17,10))
    ax[0].imshow(t1[:,:,z])
    ax[1].imshow(t1ce[:,:,z])
    ax[2].imshow(flair[:,:,z])
    ax[3].imshow(seg[:,:,z])
    ax[4].imshow(t2[:,:,z])
    ax[0].set_title('t1')
    ax[1].set_title('t1ce')
    ax[2].set_title('flair')
    ax[3].set_title('seg')
    ax[4].set_title('t2')


# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
129/52:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
129/53:
z = 80
for z in [5, 25, 55, 85, 135]:
    fig, ax = plt.subplots(1,5, figsize=(17,10))
    ax[0].imshow(t1[:,:,z])
    ax[1].imshow(t1ce[:,:,z])
    ax[2].imshow(flair[:,:,z])
    ax[3].imshow(seg[:,:,z])
    ax[4].imshow(t2[:,:,z])
    ax[0].set_title('t1')
    ax[1].set_title('t1ce')
    ax[2].set_title('flair')
    ax[3].set_title('seg')
    ax[4].set_title('t2')


# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
129/54: import ipdb
129/55: import pdb
129/56: print('a')
129/57:
print('a')
import pdb
pdb.set_trace()
print('b')
135/1:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
135/2:
import glob

glob.glob('dataset/training/BraTS20_Training_001/*')
135/3:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
135/4:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output
# %matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
135/5:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
135/6:
import nibabel as nib
import numpy as np
# import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
135/7:
import glob

glob.glob('dataset/training/BraTS20_Training_001/*')
135/8:
z = 80
for z in [5, 25, 55, 85, 135]:
    fig, ax = plt.subplots(1,5, figsize=(17,10))
    ax[0].imshow(t1[:,:,z])
    ax[1].imshow(t1ce[:,:,z])
    ax[2].imshow(flair[:,:,z])
    ax[3].imshow(seg[:,:,z])
    ax[4].imshow(t2[:,:,z])
    ax[0].set_title('t1')
    ax[1].set_title('t1ce')
    ax[2].set_title('flair')
    ax[3].set_title('seg')
    ax[4].set_title('t2')


# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
136/1:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
136/2:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
136/3:
import nibabel as nib
import numpy as np
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
136/4:
import nibabel as nib
import numpy as np
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
136/5:
import nibabel as nib
import numpy as np
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
137/1:
import nibabel as nib
import numpy as np
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
137/2:
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
137/3:
import nibabel as nib
import numpy as np
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
138/1:
import nibabel as nib
import numpy as np
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
139/1: import matplotlib.pyplot as plt
138/2:
import nibabel as nib
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TkAgg')
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
140/1: plt.plot(np.arange(5))
138/3:
import nibabel as nib
import numpy as np
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
138/4:
import glob

glob.glob('dataset/training/BraTS20_Training_001/*')
138/5:
z = 80
for z in [5, 25, 55, 85, 135]:
    fig, ax = plt.subplots(1,5, figsize=(17,10))
    ax[0].imshow(t1[:,:,z])
    ax[1].imshow(t1ce[:,:,z])
    ax[2].imshow(flair[:,:,z])
    ax[3].imshow(seg[:,:,z])
    ax[4].imshow(t2[:,:,z])
    ax[0].set_title('t1')
    ax[1].set_title('t1ce')
    ax[2].set_title('flair')
    ax[3].set_title('seg')
    ax[4].set_title('t2')


# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
138/6:
import nibabel as nib
import numpy as np
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
141/1:
import nibabel as nib
import numpy as np
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# im = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz')
t1 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz').get_fdata()
t1ce = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii.gz').get_fdata()
flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
seg = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
t2 = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_t2.nii.gz').get_fdata()
t1.shape
141/2:
import glob

glob.glob('dataset/training/BraTS20_Training_001/*')
142/1:
import nibabel as nib
import numpy as np
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline
142/2: flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
142/3: print(flair.shape)
142/4:
print(flair.shape)
plt.imshow(flair[:,:,50], cmap='gray')
142/5:
print(flair.shape)
plt.imshow(flair[:,:,50], cmap='gray')
142/6: flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
142/7: flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
142/8: flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
142/9: label = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
142/10:
print(flair.shape)
#plt.imshow(flair[:,:,50], cmap='gray')
142/11:
print(flair.shape)
plt.imshow(label[:,:,50])
142/12:
print(label.shape)
print(label)
plt.imshow(label[:,:,50])
142/13:
print(label.shape)
print(label==1)
plt.imshow(label[:,:,50])
142/14:
print(label.shape)
print(np.sum(label==1))
plt.imshow(label[:,:,50])
142/15:
print(label.shape)
print(np.sum(label==0))
plt.imshow(label[:,:,50])
142/16:
print(label.shape)
print(np.sum(label==2))
plt.imshow(label[:,:,50])
142/17:
print(label.shape)
print(np.sum(label==3))
plt.imshow(label[:,:,50])
142/18:
print(label.shape)
print(np.sum(label==4))
plt.imshow(label[:,:,50])
142/19:
print(label.shape)
print(np.sum(label==5))
plt.imshow(label[:,:,50])
142/20:
print(label.shape)
label = label != 0
plt.imshow(label[:,:,50])
142/21:
print(label.shape)
label = label != 0
label.astype(int)
plt.imshow(label[:,:,50])
142/22:
print(label.shape)
label = label != 0
label.astype(int)
plt.imshow(label[:,:,50], cmap='gray')
142/23:
print(label.shape)
label = label != 0
print(label)
label.astype(int)
plt.imshow(label[:,:,50], cmap='gray')
142/24:
print(label.shape)
label = label != 0
print(label)
label.astype(int)
plt.imshow(label[:,:,50], cmap='gray')
142/25:
print(label.shape)
label = label != 0
print(label)
label.astype(int)
print(label)
plt.imshow(label[:,:,50], cmap='gray')
142/26:
print(label.shape)
label = label != 0
print(label)
label = label.astype(int)
print(label)
plt.imshow(label[:,:,50], cmap='gray')
142/27:
print(label.shape)
label = label != 0
label = label.astype(int)
plt.imshow(label[:,:,50], cmap='gray')
142/28:
print(label.shape)

label = label != 0
label = label.astype(int)

plt.imshow(label[:,:,50], cmap='gray')
142/29: import os
142/30: dir_path = os.path.dirname(os.path.realpath(__file__))
142/31: cd
142/32: ls
142/33: os.getcwd()
142/34: ls
142/35: ls /projects
142/36: ls projects
142/37: ls projects\auggan
142/38: ls projects/auggan
142/39: IMG_ROOT = 'dataset/training/'
142/40: scan_root = 'dataset/training/'
142/41:
for path in os.listdir(scan_root):
    print(path)
142/42: scan_root = '/dataset/training/'
142/43:
for path in os.listdir(scan_root):
    print(path)
142/44: ls
142/45: ls projects/
142/46: scan_root = 'projects/auggan/dataset/training/'
142/47:
for path in os.listdir(scan_root):
    print(path)
142/48:
print(len(os.listdir(scan_root)))
for path in os.listdir(scan_root):
    print(path)
142/49:
def scans_nii2jpg(input_path, output_path):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    print(scan_num)
142/50: scan_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz','projects/auggan/dataset/training/output/001/')
142/51: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz','projects/auggan/dataset/training/output/001/')
142/52:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path)
    print(scan)
142/53: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz','projects/auggan/dataset/training/output')
142/54:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_image()
    print(scan)
142/55: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz','projects/auggan/dataset/training/output')
142/56:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    print(scan)
142/57: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz','projects/auggan/dataset/training/output')
142/58:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    print(scan.shape)
142/59: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz','projects/auggan/dataset/training/output')
142/60:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()[:,:,:]
    print(scan.shape)
142/61: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz','projects/auggan/dataset/training/output')
142/62:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    print(scan)
142/63: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz','projects/auggan/dataset/training/output')
142/64:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    print(np.max(scan))
142/65: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz','projects/auggan/dataset/training/output')
142/66: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_002/BraTS20_Training_002_flair.nii.gz','projects/auggan/dataset/training/output')
142/67:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    print(np.max(scan))
142/68: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_002/BraTS20_Training_002_flair.nii.gz','projects/auggan/dataset/training/output')
142/69: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_003/BraTS20_Training_003_flair.nii.gz','projects/auggan/dataset/training/output')
142/70:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    print(np.max(scan))
142/71:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    scan = scan.astype(np.uint8)
    print(np.max(scan))
142/72: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_003/BraTS20_Training_003_flair.nii.gz','projects/auggan/dataset/training/output')
142/73:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    #scan = scan.astype(np.uint8)
    print(np.max(scan))
142/74: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_003/BraTS20_Training_003_flair.nii.gz','projects/auggan/dataset/training/output')
142/75:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    print(scan)
    #scan = scan.astype(np.uint8)
    print(np.max(scan))
142/76: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_003/BraTS20_Training_003_flair.nii.gz','projects/auggan/dataset/training/output')
142/77:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    print(scan[:,:,20])
    #scan = scan.astype(np.uint8)
    print(np.max(scan))
142/78: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_003/BraTS20_Training_003_flair.nii.gz','projects/auggan/dataset/training/output')
142/79:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    print(scan[150:200,150:200,20])
    #scan = scan.astype(np.uint8)
    print(np.max(scan))
142/80: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_003/BraTS20_Training_003_flair.nii.gz','projects/auggan/dataset/training/output')
142/81:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    print(scan[150:250,150:250,20])
    #scan = scan.astype(np.uint8)
    print(np.max(scan))
142/82: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_003/BraTS20_Training_003_flair.nii.gz','projects/auggan/dataset/training/output')
142/83:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    print(scan[200:250,2000:250,20])
    #scan = scan.astype(np.uint8)
    print(np.max(scan))
142/84: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_003/BraTS20_Training_003_flair.nii.gz','projects/auggan/dataset/training/output')
142/85:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    print(scan[200:250,200:250,20])
    #scan = scan.astype(np.uint8)
    print(np.max(scan))
142/86: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_003/BraTS20_Training_003_flair.nii.gz','projects/auggan/dataset/training/output')
142/87:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    print(scan[200:250,200:250,20])
    #scan = scan.astype(np.uint8)
    print(np.max(scanü axis=1))
142/88:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    print(scan[200:250,200:250,20])
    #scan = scan.astype(np.uint8)
    print(np.max(scan, axis=1))
142/89: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_003/BraTS20_Training_003_flair.nii.gz','projects/auggan/dataset/training/output')
142/90:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    #scan = scan.astype(np.uint8)
    print(np.max(scan, axis=1)
142/91:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    #scan = scan.astype(np.uint8)
    print(np.max(scan, axis=1))
142/92: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_003/BraTS20_Training_003_flair.nii.gz','projects/auggan/dataset/training/output')
142/93:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    #scan = scan.astype(np.uint8)
    print(np.max(scan, axis=2))
142/94: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_003/BraTS20_Training_003_flair.nii.gz','projects/auggan/dataset/training/output')
142/95:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    #scan = scan.astype(np.uint8)
    print(np.max(scan, axis=0))
142/96: scans_nii2jpg('projects/auggan/dataset/training/BraTS20_Training_003/BraTS20_Training_003_flair.nii.gz','projects/auggan/dataset/training/output')
142/97:
def scans_nii2jpg(input_path, output_root):
    scan_num = (input_path.split('/')[-1]).split('_')[2]
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(input_path).get_fdata()
    scan = (scan/scan.max())*255
    scan = scan.astype(np.uint8)
    
    for i in range(scan.shape[2]):
        filename = os.path.join(output_root,scan_num+'_'+i+'.jpg')
        slice_img = scan[:,:,]
        
        cv2.imwrite(filename, slice_img)
142/98:
def scans_nii2jpg(input_path, output_root):
    folder_name = input_path.split('/')[-1]
    scan_num = folder_name.split('_')[2]
    scan_path = os.path.join(input_path, folder_name + '_flair.nii.gz')
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(scan_path).get_fdata()
    scan = (scan/scan.max())*255
    scan = scan.astype(np.uint8)
    
    for i in range(2):
        filename = os.path.join(output_root,scan_num+'_'+i+'.jpg')
        slice_img = scan[:,:,]
        
        cv2.imwrite(filename, slice_img)
142/99:
for path in os.listdir(scan_root):
    scans_nii2jpg(path,'projects/auggan/dataset/training/output')
142/100:
def scans_nii2jpg(input_path, output_root):
    folder_name = input_path.split('/')[-1]
    scan_num = folder_name.split('_')[2]
    scan_path = os.path.join(input_path, folder_name + '_flair.nii.gz')
    print(scan_path)
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(scan_path).get_fdata()
    scan = (scan/scan.max())*255
    scan = scan.astype(np.uint8)
    
    for i in range(2):
        filename = os.path.join(output_root,scan_num+'_'+i+'.jpg')
        slice_img = scan[:,:,]
        
        cv2.imwrite(filename, slice_img)
142/101:
for path in os.listdir(scan_root):
    scans_nii2jpg(path,'projects/auggan/dataset/training/output')
142/102:
def scans_nii2jpg(input_path, output_root):
    folder_name = input_path.split('/')[-1]
    scan_num = folder_name.split('_')[2]
    scan_path = os.path.join(input_path, folder_name + '_flair.nii.gz')
    print(scan_path)
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(scan_path).get_fdata()
    scan = (scan/scan.max())*255
    scan = scan.astype(np.uint8)
    
    for i in range(2):
        filename = os.path.join(output_root,scan_num+'_'+i+'.jpg')
        slice_img = scan[:,:,]
        
        cv2.imwrite(filename, slice_img)
142/103:
for path in os.path.join(scan_root,os.listdir(scan_root)):
    scans_nii2jpg(path,'projects/auggan/dataset/training/output')
142/104:
def scans_nii2jpg(input_path, output_root):
    folder_name = input_path.split('/')[-1]
    scan_num = folder_name.split('_')[2]
    scan_path = os.path.join(input_path, folder_name + '_flair.nii.gz')
    print(scan_path)
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(scan_path).get_fdata()
    scan = (scan/scan.max())*255
    scan = scan.astype(np.uint8)
    
    for i in range(2):
        filename = os.path.join(output_root,scan_num+'_'+i+'.jpg')
        slice_img = scan[:,:,]
        
        cv2.imwrite(filename, slice_img)
142/105:
for path in scan_root,os.listdir(scan_root):
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/training/output')
142/106:
def scans_nii2jpg(input_path, output_root):
    print(input_path)
    folder_name = input_path.split('/')[-1]
    scan_num = folder_name.split('_')[2]
    scan_path = os.path.join(input_path, folder_name + '_flair.nii.gz')
    print(scan_path)
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(scan_path).get_fdata()
    scan = (scan/scan.max())*255
    scan = scan.astype(np.uint8)
    
    for i in range(2):
        filename = os.path.join(output_root,scan_num+'_'+i+'.jpg')
        slice_img = scan[:,:,]
        
        cv2.imwrite(filename, slice_img)
142/107:
for path in scan_root,os.listdir(scan_root):
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/training/output')
142/108:
for path in os.listdir(scan_root):
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/training/output')
142/109:
def scans_nii2jpg(input_path, output_root):
    print(input_path)
    folder_name = input_path.split('/')[-1]
    scan_num = folder_name.split('_')[2]
    scan_path = os.path.join(input_path, folder_name + '_flair.nii.gz')
    print(scan_path)
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(scan_path).get_fdata()
    scan = (scan/scan.max())*255
    scan = scan.astype(np.uint8)
    
    for i in range(2):
        filename = os.path.join(output_root,scan_num+'_'+str(i)+'.jpg')
        slice_img = scan[:,:,]
        
        cv2.imwrite(filename, slice_img)
142/110:
for path in os.listdir(scan_root):
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/training/output')
142/111:
import os
import cv2
142/112: import os
142/113:
import os
import cv2
142/114:
def scans_nii2jpg(input_path, output_root):
    print(input_path)
    folder_name = input_path.split('/')[-1]
    scan_num = folder_name.split('_')[2]
    scan_path = os.path.join(input_path, folder_name + '_flair.nii.gz')
    print(scan_path)
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(scan_path).get_fdata()
    scan = (scan/scan.max())*255
    scan = scan.astype(np.uint8)
    
    for i in range(2):
        filename = os.path.join(output_root,scan_num+'_'+str(i)+'.jpg')
        slice_img = scan[:,:,]
        
        cv2.imwrite(filename, slice_img)
142/115:
for path in os.listdir(scan_root):
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/training/output')
142/116:
def scans_nii2jpg(input_path, output_root):
    print(input_path)
    folder_name = input_path.split('/')[-1]
    scan_num = folder_name.split('_')[2]
    scan_path = os.path.join(input_path, folder_name + '_flair.nii.gz')
    print(scan_path)
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(scan_path).get_fdata()
    scan = (scan/scan.max())*255
    scan = scan.astype(np.uint8)
    
    for i in range(2):
        filename = os.path.join(output_root,scan_num+'_'+str(i)+'.jpg')
        slice_img = scan[:,:,i]
        
        cv2.imwrite(filename, slice_img)
142/117:
for path in os.listdir(scan_root):
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/training/output')
142/118:
for path in os.listdir(scan_root):
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training')
142/119:
def scans_nii2jpg(input_path, output_root):
    print(input_path)
    folder_name = input_path.split('/')[-1]
    scan_num = folder_name.split('_')[2]
    scan_path = os.path.join(input_path, folder_name + '_flair.nii.gz')
    print(scan_path)
    #output_path = os.path.join(output_root,scan_num)
    print(scan_num)
    scan = nib.load(scan_path).get_fdata()
    scan = (scan/scan.max())*255
    scan = scan.astype(np.uint8)
    
    for i in range(scan.shape[2]):
        filename = os.path.join(output_root,scan_num+'_'+str(i)+'.jpg')
        slice_img = scan[:,:,i]
        
        cv2.imwrite(filename, slice_img)
142/120:
for i, path in enumerate(os.listdir(scan_root)):
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training')
    if i==1:
        break
142/121:
for i, path in enumerate(os.listdir(scan_root)):
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training')
    if i==1:
        break
142/122:
for i, path in enumerate(os.listdir(scan_root)):
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training')
    if i==1:
        break
142/123:
for i, path in enumerate(os.listdir(scan_root)):
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
    if i==1:
        break
142/124:
def labels_nii2jpg(input_path, output_root):
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    label = label != 0
    label = label.astype(np.uint8)
    
    for i in range(scan.shape[2]):
        filename = os.path.join(output_root,scan_num+'_'+str(i)+'.jpg')
        slice_img = scan[:,:,i]
        
        cv2.imwrite(filename, slice_img)
142/125:
for i, path in enumerate(os.listdir(scan_root)):
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
    if i==1:
        break
142/126:
def labels_nii2jpg(input_path, output_root):
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    label = label != 0
    label = label.astype(np.uint8)
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
142/127:
for i, path in enumerate(os.listdir(scan_root)):
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
    if i==1:
        break
142/128:
for i, path in enumerate(os.listdir(label_root)):
    labels_nii2jpg(os.path.join(label_root,path),'projects/auggan/dataset/slices_2d/training/labels')
    if i==1:
        break
142/129:
for i, path in enumerate(os.listdir(scan_root)):
    labels_nii2jpg(os.path.join(label_root,path),'projects/auggan/dataset/slices_2d/training/labels')
    if i==1:
        break
142/130:
for i, path in enumerate(os.listdir(scan_root)):
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
    if i==1:
        break
142/131:
def labels_nii2jpg(input_path, output_root):
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    label = label != 0
    label = label * 255
    label = label.astype(np.uint8)
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
142/132:
for i, path in enumerate(os.listdir(scan_root)):
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
    if i==1:
        break
142/133: label = nib.load('dataset/training/BraTS20_Training_185/BraTS20_Training_185_seg.nii.gz').get_fdata()
142/134: label = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
142/135: label = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
142/136: label = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz').get_fdata()
142/137: flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
142/138: cd
143/1:
import nibabel as nib
import numpy as np
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline
143/2:
import os
import cv2
143/3: flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
143/4: label = nib.load('dataset/training/BraTS20_Training_185/BraTS20_Training_185_seg.nii.gz').get_fdata()
143/5:
print(label.shape)

label = label != 0
label = label.astype(int)

plt.imshow(label[:,:,50], cmap='gray')
143/6: scan_root = 'projects/auggan/dataset/training/'
143/7:
def scans_nii2jpg(input_path, output_root):
    folder_name = input_path.split('/')[-1]
    scan_num = folder_name.split('_')[2]
    scan_path = os.path.join(input_path, folder_name + '_flair.nii.gz')
    scan = nib.load(scan_path).get_fdata()
    scan = (scan/scan.max())*255
    scan = scan.astype(np.uint8)
    
    for i in range(scan.shape[2]):
        filename = os.path.join(output_root,scan_num+'_'+str(i)+'.jpg')
        slice_img = scan[:,:,i]
        
        cv2.imwrite(filename, slice_img)
143/8:
def labels_nii2jpg(input_path, output_root):
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    label = label != 0
    label = label * 255
    label = label.astype(np.uint8)
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
143/9:
for i, path in enumerate(os.listdir(scan_root)):
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
    if i==1:
        break
143/10: cd
143/11: ls
143/12: ls projects\
143/13: ls projects/
143/14: ls projects/auggan/
143/15: scan_root = 'dataset/training/'
143/16:
for i, path in enumerate(os.listdir(scan_root)):
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
    if i==1:
        break
143/17: scan_root = 'projects/auggan/dataset/training/'
143/18:
for i, path in enumerate(os.listdir(scan_root)):
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
    if i==1:
        break
143/19:
for i, path in enumerate(os.listdir(scan_root)):
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
    if i==1:
        break
143/20: cd
143/21:
for i, path in enumerate(os.listdir(scan_root)):
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
    if i==1:
        break
143/22: ls
143/23:
for i, path in enumerate(os.listdir(scan_root)):
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
    if i==1:
        break
143/24:
for i, path in enumerate(os.listdir(scan_root)):
    if i==50:
        break
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/25:
for i, path in enumerate(os.listdir(scan_root)):
    if i==50:
        break
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
144/1:
for folder_name in os.listdir('projects/auggan/dataset/slices_2d/training/scans'):
    print(folder_name)
144/2:
import os
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'projects/auggan/dataset/slices_2d/training/scans'
        self.img_root = 'projects/auggan/dataset/slices_2d/training/labels'
        
        self.transform = transform
        #self.inputs_dtype = torch.float32
        #self.targets_dtype = torch.long
        
        for folder_name in os.listdir(self.img_root):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name, "*.jpg"))
        for folder_name in os.listdir(self.label_root):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name, "*.jpg"))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.inputs)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.inputs[index]
        target_ID = self.targets[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)

        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/3:
for folder_name in os.listdir('projects/auggan/dataset/slices_2d/training/scans'):
    print(folder_name)
144/4:
for folder_name in os.listdir('dataset/slices_2d/training/scans'):
    print(folder_name)
144/5:
import os
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'projects/auggan/dataset/slices_2d/training/scans'
        self.img_root = 'projects/auggan/dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for folder_name in os.listdir(self.img_root):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for folder_name in os.listdir(self.label_root):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.inputs)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)

        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/6:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/7:
import os
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.img_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for folder_name in os.listdir(self.img_root):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for folder_name in os.listdir(self.label_root):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.inputs)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)

        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/8:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/9:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.img_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for folder_name in os.listdir(self.img_root):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for folder_name in os.listdir(self.label_root):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.inputs)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)

        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/10:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/11:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for folder_name in os.listdir(self.img_root):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for folder_name in os.listdir(self.label_root):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.inputs)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)

        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/12:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/13:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for folder_name in os.listdir(self.img_root):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for folder_name in os.listdir(self.label_root):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)
        print(self.img_path)

    def __len__(self):
        return len(self.inputs)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)

        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/14:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/15:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for folder_name in os.listdir(self.img_root):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for folder_name in os.listdir(self.label_root):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.inputs)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)

        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/16:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for folder_name in os.listdir(self.img_root):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for folder_name in os.listdir(self.label_root):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)

        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/17:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/18:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/19: print(y)
144/20: print(np.max(y))
144/21: print(y)
144/22:
import torch.max
print(y)
144/23:
import torch
print(torch.max(y))
144/24:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/25:
import torch
print(torch.max(y))
144/26:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/27:
import torch
print(torch.max(y))
144/28:
import torch
print(y)
144/29:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/30:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/31:
import torch
y_np = y.numpy()
print(y_np)
144/32:
import torch
y_np = y.numpy()
print(y_np)
print(y_np(np.nonzero(y_-np)))
144/33:
import torch
y_np = y.numpy()
print(y_np)
print(y_np(np.nonzero(y_np)))
144/34:
import torch
y_np = y.numpy()
print(y_np)
print(y_np[np.nonzero(y_np)])
144/35:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for folder_name in os.listdir(self.img_root):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for folder_name in os.listdir(self.label_root):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/36:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/37:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/38:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/39:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/40:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/41:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/42:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/43:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/44:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/45:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            if i==0:
                print(folder_name)
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            if i==0:
                print(folder_name)
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/46:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/47:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            if i==100:
                print(folder_name)
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            if i==100:
                print(folder_name)
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/48:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/49:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/50:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/51:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/52:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            if i==1000:
                print(folder_name)
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            if i==1000:
                print(folder_name)
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/53:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/54:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            if i==10000:
                print(folder_name)
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            if i==10000:
                print(folder_name)
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/55:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/56:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            if i==2000:
                print(folder_name)
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            if i==2000:
                print(folder_name)
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/57:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
143/26:
def scans_nii2jpg(input_path, output_root):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    scan_num = folder_name.split('_')[2]
    scan_path = os.path.join(input_path, folder_name + '_flair.nii.gz')
    scan = nib.load(scan_path).get_fdata()
    scan = (scan/scan.max())*255
    scan = scan.astype(np.uint8)
    
    for i in range(scan.shape[2]):
        filename = os.path.join(output_root,scan_num+'_'+str(i)+'.jpg')
        slice_img = scan[:,:,i]
        
        cv2.imwrite(filename, slice_img)
143/27:
def labels_nii2jpg(input_path, output_root):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    label = label != 0
    label = label * 255
    label = label.astype(np.uint8)
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
143/28:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/29:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
144/58:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            if i==2000:
                print(folder_name)
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            if i==2000:
                print(folder_name)
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/59:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/60:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            if i==10:
                print(folder_name)
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            if i==10:
                print(folder_name)
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/61:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/62:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            if i==30:
                print(folder_name)
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            if i==30:
                print(folder_name)
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/63:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/64:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            if i==774:
                print(folder_name)
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            if i==774:
                print(folder_name)
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/65:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
143/30:
for i, path in enumerate(os.listdir(scan_root)):
    if i==50:
        break
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/31:
for i, path in enumerate(os.listdir(scan_root)):
    if i==50:
        break
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
144/66:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            if i==1000:
                print(folder_name)
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            if i==1000:
                print(folder_name)
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/67:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/68:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            if i==2000:
                print(folder_name)
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            if i==2000:
                print(folder_name)
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/69:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/70:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            if i==5000:
                print(folder_name)
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            if i==5000:
                print(folder_name)
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/71:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            if i==7000:
                print(folder_name)
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            if i==7000:
                print(folder_name)
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/72:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/73: imread(dataset/slices_2d/training/labels/018_58.jpg)
144/74: imread('dataset/slices_2d/training/labels/018_58.jpg')
144/75:
y_np = imread('dataset/slices_2d/training/labels/018_58.jpg')
print(y_np[np.nonzero(y_np)])
143/32:
def labels_nii2jpg(input_path, output_root):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    label = label != 0
    label = label.astype(np.uint8)
    #label = label * 255
    
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
143/33:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/34:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
143/35:
def labels_nii2jpg(input_path, output_root):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    label = label != 0
    label = label.astype(np.uint8)
    label = label * 255
    
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
143/36:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/37:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
144/76:
y_np = imread('dataset/slices_2d/training/labels/018_58.jpg')
print(y_np[np.nonzero(y_np)])
144/77:
y_np = imread('dataset/slices_2d/training/labels/018_58.jpg')
print(y_np[np.nonzero(y_np)])
143/38:
def labels_nii2jpg(input_path, output_root):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    label = label != 0
    label = label.astype(np.uint8)
    
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
143/39:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/40:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
144/78:
y_np = imread('dataset/slices_2d/training/labels/018_58.jpg')
print(y_np[np.nonzero(y_np)])
143/41:
def labels_nii2jpg(input_path, output_root):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    label = (label != 0)
    label = label.astype(np.uint8)
    
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
143/42:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/43:
def labels_nii2jpg(input_path, output_root):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    label = (label != 0)
    label = label.astype(int)
    
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
143/44:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/45:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
144/79:
y_np = imread('dataset/slices_2d/training/labels/018_58.jpg')
print(y_np[np.nonzero(y_np)])
143/46:
def labels_nii2jpg(input_path, output_root):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    label = (label != 0)
    #label = label.astype(int)
    
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
143/47:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/48:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
143/49:
def labels_nii2jpg(input_path, output_root):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    label = int(label != 0)
    #label = label.astype(int)
    
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
143/50:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/51:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
143/52:
def labels_nii2jpg(input_path, output_root):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    label = label != 0
    label = label.astype(int)
    
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
143/53:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/54:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
144/80:
y_np = imread('dataset/slices_2d/training/labels/018_58.jpg')
print(y_np[np.nonzero(y_np)])
144/81:
y_np = imread('dataset/slices_2d/training/labels/018_58.jpg')
print(y_np[np.nonzero(y_np)])
143/55:
def labels_nii2jpg(input_path, output_root):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    #label = label != 0
    #label = label.astype(int)
    label.astype(bool).astype(int)
    
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
143/56:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/57:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
144/82:
y_np = imread('dataset/slices_2d/training/labels/018_58.jpg')
print(y_np[np.nonzero(y_np)])
143/58:
def labels_nii2jpg(input_path, output_root):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    #label = label != 0
    #label = label.astype(int)
    label = label.astype(bool).astype(int)
    
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
143/59:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/60:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
144/83:
y_np = imread('dataset/slices_2d/training/labels/018_58.jpg')
print(y_np[np.nonzero(y_np)])
143/61:
def labels_nii2jpg(input_path, output_root):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    #label = label != 0
    #label = label.astype(int)
    label = (label 1= 0)
    label = label * 1
    #label = label.astype(bool).astype(int)
    
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
143/62:
def labels_nii2jpg(input_path, output_root):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    #label = label != 0
    #label = label.astype(int)
    label = (label 1== 0)
    label = label * 1
    #label = label.astype(bool).astype(int)
    
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
143/63:
def labels_nii2jpg(input_path, output_root):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    #label = label != 0
    #label = label.astype(int)
    label = (label != 0)
    label = label * 1
    #label = label.astype(bool).astype(int)
    
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
143/64:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/65:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
144/84:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/85:
y_np = imread('dataset/slices_2d/training/labels/018_58.jpg')
print(y_np[np.nonzero(y_np)])
143/66:
def labels_nii2jpg(input_path, output_root):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    #label = label != 0
    #label = label.astype(int)
    label = (label > 0)
    label = label * 1
    #label = label.astype(bool).astype(int)
    
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        
        cv2.imwrite(filename, label_img)
143/67:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/68:
for i, path in enumerate(os.listdir(scan_root)):
    if i==5:
        break
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
144/86:
y_np = imread('dataset/slices_2d/training/labels/018_58.jpg')
print(y_np[np.nonzero(y_np)])
144/87:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.img_root = 'dataset/slices_2d/training/scans'
        self.label_root = 'dataset/slices_2d/training/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            if i==7000:
                print(folder_name)
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            if i==7000:
                print(folder_name)
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/88:
training_dataset = SegmentationDataSet(transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
143/69:
training_root = 'projects/auggan/dataset/training/'
validation_root = 'projects/auggan/dataset/validation/'
143/70:
for i, path in enumerate(os.listdir(training_root)):
    if i==50:
        break
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/71:
for i, path in enumerate(os.listdir(training_root)):
    if i==50:
        break
    scans_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/72:
for i, path in enumerate(os.listdir(training_root)):
    if i==50:
        break
    labels_nii2jpg(os.path.join(scan_root,path),'projects/auggan/dataset/slices_2d/training/labels')
143/73:
for i, path in enumerate(os.listdir(training_root)):
    if i==50:
        break
    scans_nii2jpg(os.path.join(training_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/74:
for i, path in enumerate(os.listdir(training_root)):
    if i==50:
        break
    labels_nii2jpg(os.path.join(training_root,path),'projects/auggan/dataset/slices_2d/training/labels')
143/75:
for i, path in enumerate(os.listdir(validation_root)):
    if i==50:
        break
    scans_nii2jpg(os.path.join(validation_root,path),'projects/auggan/dataset/slices_2d/validation/scans')
143/76:
for i, path in enumerate(os.listdir(validation_root)):
    if str.endswith(".csv"):
        continue
    if i==50:
        break
    scans_nii2jpg(os.path.join(validation_root,path),'projects/auggan/dataset/slices_2d/validation/scans')
143/77:
for i, path in enumerate(os.listdir(validation_root)):
    if path.endswith(".csv"):
        continue
    if i==50:
        break
    scans_nii2jpg(os.path.join(validation_root,path),'projects/auggan/dataset/slices_2d/validation/scans')
143/78:
for i, path in enumerate(os.listdir(validation_root)):
    if path.endswith(".csv"):
        continue
    if i==50:
        break
    scans_nii2jpg(os.path.join(validation_root,path),'projects/auggan/dataset/slices_2d/validation/labels')
144/89:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            if i==7000:
                print(folder_name)
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            if i==7000:
                print(folder_name)
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
144/90:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/91:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/92:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/93:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/94:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/95:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
144/96:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
141/3:
z = 85
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(seg[:,:,z])
ax[4].imshow(t2[:,:,z])
ax[0].set_title('t1')
ax[1].set_title('t1ce')
ax[2].set_title('flair')
ax[3].set_title('seg')
ax[4].set_title('t2')


# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/4:
z = 85
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
ax[4].imshow(seg[:,:,z])
ax[0].set_title('T1')
ax[1].set_title('T1Gd')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('SEGMENTATION')


# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/5:
z = 85
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
ax[4].imshow(seg[:,:,z])
ax[0].set_title('T1')
ax[1].set_title('T1Gd')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('SEGMENTATION')

fig, ax = plt.subplots(2,5, figsize=(17,10))
for i, z in enumerate([15, 45, 75, 105, 135]):
ax[i].imshow(flair[:,:,z])
ax[i].set_title('Slice: {}'.format)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/6:
z = 85
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
ax[4].imshow(seg[:,:,z])
ax[0].set_title('T1')
ax[1].set_title('T1Gd')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('SEGMENTATION')

fig, ax = plt.subplots(2,5, figsize=(17,10))
for i, z in enumerate([15, 45, 75, 105, 135]):
ax[0,i].imshow(flair[:,:,z])
ax[0,i].set_title('Slice: {}'.format(z))
ax[1,i].imshow(seg[:,:,z])

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/7:
z = 85
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
ax[4].imshow(seg[:,:,z])
ax[0].set_title('T1')
ax[1].set_title('T1Gd')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('SEGMENTATION')

fig, ax = plt.subplots(2,5, figsize=(17,10))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z])

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/8:
z = 85
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
ax[4].imshow(seg[:,:,z])
ax[0].set_title('T1')
ax[1].set_title('T1Gd')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('SEGMENTATION')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(2,5, figsize=(17,5))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z])

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/9:
z = 85
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
ax[4].imshow(seg[:,:,z])
ax[0].set_title('T1')
ax[1].set_title('T1Gd')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('SEGMENTATION')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(2,5)
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z])

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/10:
z = 85
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
ax[4].imshow(seg[:,:,z])
ax[0].set_title('T1')
ax[1].set_title('T1Gd')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('SEGMENTATION')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(2,5, figsize=(17,8))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z])

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/11:
z = 85
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
ax[4].imshow(seg[:,:,z])
ax[0].set_title('T1')
ax[1].set_title('T1Gd')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('SEGMENTATION')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(2,5, figsize=(17,7))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z])

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/12:
z = 85
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
ax[4].imshow(seg[:,:,z])
ax[0].set_title('T1')
ax[1].set_title('T1Gd')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('SEGMENTATION')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(5,5, figsize=(17,27))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]==1)
    ax[2,i].imshow(seg[:,:,z]==1)
    ax[3,i].imshow(seg[:,:,z]==2)
    ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/13:
z = 85
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
ax[4].imshow(seg[:,:,z])
ax[0].set_title('T1')
ax[1].set_title('T1Gd')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('SEGMENTATION')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(5,5, figsize=(17,20))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]==1)
    ax[2,i].imshow(seg[:,:,z]==1)
    ax[3,i].imshow(seg[:,:,z]==2)
    ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/14:
z = 85
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
ax[4].imshow(seg[:,:,z])
ax[0].set_title('T1')
ax[1].set_title('T1Gd')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('SEGMENTATION')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(5,5, figsize=(17,20))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z])
    ax[2,i].imshow(seg[:,:,z]==1)
    ax[3,i].imshow(seg[:,:,z]==2)
    ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/15:
z = 85
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
ax[4].imshow(seg[:,:,z])
ax[0].set_title('T1')
ax[1].set_title('T1Gd')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('SEGMENTATION')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(5,5, figsize=(17,20))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
    ax[2,i].imshow(seg[:,:,z]==1)
    ax[3,i].imshow(seg[:,:,z]==2)
    ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/16:
z = 85
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
ax[4].imshow(seg[:,:,z])
ax[0].set_title('T1')
ax[1].set_title('T1Gd')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('SEGMENTATION')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(5,5, figsize=(17,20))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
    ax[2,i].imshow(seg[:,:,z]==1)
    ax[3,i].imshow(seg[:,:,z]==2)
    ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
144/97:
import argparse
import logging
import pdb

import torch
import torch.backends.cudnn as cudnn

from config import *
from dataset import *
from models import *
from utils import *


def train(args):

    # Variables and logger Init
    device = config.device
    cudnn.benchmark = True
    get_logger()

    # Data Load
    trainloader = data_loader(args, mode='train')
    validloader = data_loader(args, mode='valid')

    # Model Load
    net, optimizer, best_score, start_epoch =\
        load_model(args, class_num=config.class_num, mode='train')
    log_msg = '\n'.join(['%s Train Start'%(args.model)])
    logging.info(log_msg)

    for epoch in range(start_epoch, start_epoch+args.epochs):

        # Train Model
        print('\n\n\nEpoch: {}\n<Train>'.format(epoch))
        net.train(True)
        loss = 0
        lr = args.lr * (0.5 ** (epoch // 4))
        for param_group in optimizer.param_groups:
            param_group["lr"] = lr
        torch.set_grad_enabled(True)
        for idx, (inputs, targets, paths) in enumerate(trainloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            if type(outputs) == tuple:
                outputs = outputs[0]
            batch_loss = dice_coef(outputs, targets)
            optimizer.zero_grad()
            batch_loss.backward()
            optimizer.step()
            loss += float(batch_loss)
            progress_bar(idx, len(trainloader), 'Loss: %.5f, Dice-Coef: %.5f'
                         %((loss/(idx+1)), (1-(loss/(idx+1)))))
        log_msg = '\n'.join(['Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'\
                         %(epoch, loss/(idx+1), 1-(loss/(idx+1)))])
        logging.info(log_msg)

        # Validate Model
        print('\n\n<Validation>')
        net.eval()
        for module in net.module.modules():
            if isinstance(module, torch.nn.modules.Dropout2d):
                module.train(True)
            elif isinstance(module, torch.nn.modules.Dropout):
                module.train(True)
            else:
                pass
        loss = 0
        torch.set_grad_enabled(False)
        for idx, (inputs, targets, paths) in enumerate(validloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            if type(outputs) == tuple:
                outputs = outputs[0]
            #outputs = post_process(args, inputs, outputs, save=False)
            batch_loss = dice_coef(outputs, targets, backprop=False)
            loss += float(batch_loss)
            progress_bar(idx, len(validloader), 'Loss: %.5f, Dice-Coef: %.5f'
                         %((loss/(idx+1)), (1-(loss/(idx+1)))))
        log_msg = '\n'.join(['Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'
                        %(epoch, loss/(idx+1), 1-(loss/(idx+1)))])
        logging.info(log_msg)

        # Save Model
        loss /= (idx+1)
        score = 1 - loss
        if score > best_score:
            checkpoint = Checkpoint(net, optimizer, epoch, score)
            checkpoint.save(os.path.join(args.ckpt_root, args.model+'.tar'))
            best_score = score
            print("Saving...")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("--resume", type=bool, default=False,
                        help="Model Trianing resume.")
    parser.add_argument("--model", type=str, default='pspnet_res50',
                        help="Model Name (unet, pspnet_squeeze, pspnet_res50,\
                        pspnet_res34, pspnet_res50, deeplab)")
    parser.add_argument("--in_channel", type=int, default=1,
                        help="A number of images to use for input")
    parser.add_argument("--batch_size", type=int, default=80,
                        help="The batch size to load the data")
    parser.add_argument("--epochs", type=int, default=30,
                        help="The training epochs to run.")
    parser.add_argument("--drop_rate", type=float, default=0.1,
                        help="Drop-out Rate")
    parser.add_argument("--lr", type=float, default=0.001,
                        help="Learning rate to use in training")
    parser.add_argument("--data", type=str, default="complete",
                        help="Label data type.")
    parser.add_argument("--img_root", type=str, default="../../data/train/image_FLAIR",
                        help="The directory containing the training image dataset.")
    parser.add_argument("--label_root", type=str, default="../../data/train/label",
                        help="The directory containing the training label dataset")
    parser.add_argument("--output_root", type=str, default="./output/prediction",
                        help="The directory containing the result predictions")
    parser.add_argument("--ckpt_root", type=str, default="./checkpoint",
                        help="The directory containing the checkpoint files")
    args = parser.parse_args()

    train(args)
144/98:
import argparse
import logging
import pdb

import torch
import torch.backends.cudnn as cudnn

from BraTs.pytorch.config import *
from dataset import *
from models import *
from utils import *


def train(args):

    # Variables and logger Init
    device = config.device
    cudnn.benchmark = True
    get_logger()

    # Data Load
    trainloader = training_dataloader
    validloader = validation_dataloader

    # Model Load
    net, optimizer, best_score, start_epoch =\
        load_model(args, class_num=config.class_num, mode='train')
    log_msg = '\n'.join(['%s Train Start'%(args.model)])
    logging.info(log_msg)

    for epoch in range(start_epoch, start_epoch+args.epochs):

        # Train Model
        print('\n\n\nEpoch: {}\n<Train>'.format(epoch))
        net.train(True)
        loss = 0
        lr = args.lr * (0.5 ** (epoch // 4))
        for param_group in optimizer.param_groups:
            param_group["lr"] = lr
        torch.set_grad_enabled(True)
        for idx, (inputs, targets, paths) in enumerate(trainloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            if type(outputs) == tuple:
                outputs = outputs[0]
            batch_loss = dice_coef(outputs, targets)
            optimizer.zero_grad()
            batch_loss.backward()
            optimizer.step()
            loss += float(batch_loss)
            progress_bar(idx, len(trainloader), 'Loss: %.5f, Dice-Coef: %.5f'
                         %((loss/(idx+1)), (1-(loss/(idx+1)))))
        log_msg = '\n'.join(['Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'\
                         %(epoch, loss/(idx+1), 1-(loss/(idx+1)))])
        logging.info(log_msg)

        # Validate Model
        print('\n\n<Validation>')
        net.eval()
        for module in net.module.modules():
            if isinstance(module, torch.nn.modules.Dropout2d):
                module.train(True)
            elif isinstance(module, torch.nn.modules.Dropout):
                module.train(True)
            else:
                pass
        loss = 0
        torch.set_grad_enabled(False)
        for idx, (inputs, targets, paths) in enumerate(validloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            if type(outputs) == tuple:
                outputs = outputs[0]
            #outputs = post_process(args, inputs, outputs, save=False)
            batch_loss = dice_coef(outputs, targets, backprop=False)
            loss += float(batch_loss)
            progress_bar(idx, len(validloader), 'Loss: %.5f, Dice-Coef: %.5f'
                         %((loss/(idx+1)), (1-(loss/(idx+1)))))
        log_msg = '\n'.join(['Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'
                        %(epoch, loss/(idx+1), 1-(loss/(idx+1)))])
        logging.info(log_msg)

        # Save Model
        loss /= (idx+1)
        score = 1 - loss
        if score > best_score:
            checkpoint = Checkpoint(net, optimizer, epoch, score)
            checkpoint.save(os.path.join(args.ckpt_root, args.model+'.tar'))
            best_score = score
            print("Saving...")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("--resume", type=bool, default=False,
                        help="Model Trianing resume.")
    parser.add_argument("--model", type=str, default='pspnet_res50',
                        help="Model Name (unet, pspnet_squeeze, pspnet_res50,\
                        pspnet_res34, pspnet_res50, deeplab)")
    parser.add_argument("--in_channel", type=int, default=1,
                        help="A number of images to use for input")
    parser.add_argument("--batch_size", type=int, default=80,
                        help="The batch size to load the data")
    parser.add_argument("--epochs", type=int, default=30,
                        help="The training epochs to run.")
    parser.add_argument("--drop_rate", type=float, default=0.1,
                        help="Drop-out Rate")
    parser.add_argument("--lr", type=float, default=0.001,
                        help="Learning rate to use in training")
    parser.add_argument("--data", type=str, default="complete",
                        help="Label data type.")
    parser.add_argument("--img_root", type=str, default="../../data/train/image_FLAIR",
                        help="The directory containing the training image dataset.")
    parser.add_argument("--label_root", type=str, default="../../data/train/label",
                        help="The directory containing the training label dataset")
    parser.add_argument("--output_root", type=str, default="./output/prediction",
                        help="The directory containing the result predictions")
    parser.add_argument("--ckpt_root", type=str, default="./checkpoint",
                        help="The directory containing the checkpoint files")
    args = parser.parse_args()

    train(args)
144/99:
import argparse
import logging
import pdb

import torch
import torch.backends.cudnn as cudnn

from BraTs.pytorch.config import *
#from dataset import *
from BraTs.pytorch.models import *
from BraTs.pytorch.utils import *


def train(args):

    # Variables and logger Init
    device = config.device
    cudnn.benchmark = True
    get_logger()

    # Data Load
    trainloader = training_dataloader
    validloader = validation_dataloader

    # Model Load
    net, optimizer, best_score, start_epoch =\
        load_model(args, class_num=config.class_num, mode='train')
    log_msg = '\n'.join(['%s Train Start'%(args.model)])
    logging.info(log_msg)

    for epoch in range(start_epoch, start_epoch+args.epochs):

        # Train Model
        print('\n\n\nEpoch: {}\n<Train>'.format(epoch))
        net.train(True)
        loss = 0
        lr = args.lr * (0.5 ** (epoch // 4))
        for param_group in optimizer.param_groups:
            param_group["lr"] = lr
        torch.set_grad_enabled(True)
        for idx, (inputs, targets, paths) in enumerate(trainloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            if type(outputs) == tuple:
                outputs = outputs[0]
            batch_loss = dice_coef(outputs, targets)
            optimizer.zero_grad()
            batch_loss.backward()
            optimizer.step()
            loss += float(batch_loss)
            progress_bar(idx, len(trainloader), 'Loss: %.5f, Dice-Coef: %.5f'
                         %((loss/(idx+1)), (1-(loss/(idx+1)))))
        log_msg = '\n'.join(['Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'\
                         %(epoch, loss/(idx+1), 1-(loss/(idx+1)))])
        logging.info(log_msg)

        # Validate Model
        print('\n\n<Validation>')
        net.eval()
        for module in net.module.modules():
            if isinstance(module, torch.nn.modules.Dropout2d):
                module.train(True)
            elif isinstance(module, torch.nn.modules.Dropout):
                module.train(True)
            else:
                pass
        loss = 0
        torch.set_grad_enabled(False)
        for idx, (inputs, targets, paths) in enumerate(validloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            if type(outputs) == tuple:
                outputs = outputs[0]
            #outputs = post_process(args, inputs, outputs, save=False)
            batch_loss = dice_coef(outputs, targets, backprop=False)
            loss += float(batch_loss)
            progress_bar(idx, len(validloader), 'Loss: %.5f, Dice-Coef: %.5f'
                         %((loss/(idx+1)), (1-(loss/(idx+1)))))
        log_msg = '\n'.join(['Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'
                        %(epoch, loss/(idx+1), 1-(loss/(idx+1)))])
        logging.info(log_msg)

        # Save Model
        loss /= (idx+1)
        score = 1 - loss
        if score > best_score:
            checkpoint = Checkpoint(net, optimizer, epoch, score)
            checkpoint.save(os.path.join(args.ckpt_root, args.model+'.tar'))
            best_score = score
            print("Saving...")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("--resume", type=bool, default=False,
                        help="Model Trianing resume.")
    parser.add_argument("--model", type=str, default='pspnet_res50',
                        help="Model Name (unet, pspnet_squeeze, pspnet_res50,\
                        pspnet_res34, pspnet_res50, deeplab)")
    parser.add_argument("--in_channel", type=int, default=1,
                        help="A number of images to use for input")
    parser.add_argument("--batch_size", type=int, default=80,
                        help="The batch size to load the data")
    parser.add_argument("--epochs", type=int, default=30,
                        help="The training epochs to run.")
    parser.add_argument("--drop_rate", type=float, default=0.1,
                        help="Drop-out Rate")
    parser.add_argument("--lr", type=float, default=0.001,
                        help="Learning rate to use in training")
    parser.add_argument("--data", type=str, default="complete",
                        help="Label data type.")
    parser.add_argument("--img_root", type=str, default="../../data/train/image_FLAIR",
                        help="The directory containing the training image dataset.")
    parser.add_argument("--label_root", type=str, default="../../data/train/label",
                        help="The directory containing the training label dataset")
    parser.add_argument("--output_root", type=str, default="./output/prediction",
                        help="The directory containing the result predictions")
    parser.add_argument("--ckpt_root", type=str, default="./checkpoint",
                        help="The directory containing the checkpoint files")
    args = parser.parse_args()

    train(args)
141/17:
z = 85
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
ax[4].imshow(seg[:,:,z])
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('SEGMENTATION')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(5,5, figsize=(17,20))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
    ax[2,i].imshow(seg[:,:,z]==1)
    ax[3,i].imshow(seg[:,:,z]==2)
    ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
144/100: from BraTs.pytorch.models import UNet
144/101: from BraTs.pytorch.models.unet import UNet
144/102:
from BraTs.pytorch.models.unet import UNet

model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)

print(f'Out: {out.shape}')
144/103:
from BraTs.pytorch.models.unet import UNet

model = UNet(drop_rate = 0.1)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)

print(f'Out: {out.shape}')
141/18:
z = 85
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
ax[4].imshow(seg[:,:,z]>0.5)
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('SEGMENTATION')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(2,5, figsize=(17,7))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
#     ax[2,i].imshow(seg[:,:,z]==1)
#     ax[3,i].imshow(seg[:,:,z]==2)
#     ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
144/104:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
144/105:
from torch.torchsummary import summary
summary = summary(model, (1, 512, 512))
141/19:
z = 85
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
ax[4].imshow(seg[:,:,z]>0.5)
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('SEGMENTATION')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(2,5, figsize=(17,7))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('FLAIR - Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
    ax[1,i].set_title('SEG. - Slice: {}'.format(z))
#     ax[2,i].imshow(seg[:,:,z]==1)
#     ax[3,i].imshow(seg[:,:,z]==2)
#     ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
144/106:
from torch.torchsummary import summary
summary = summary(model, (1, 512, 512))
144/107:
from BraTs.pytorch.models.unet import UNet

model = UNet(drop_rate = 0.1)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)

print(f'Out: {out.shape}')
144/108:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
144/109:
from BraTs.pytorch.models.unet import UNet

model = UNet(drop_rate = 0.1)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        print("sa")
        model.cuda()

print(f'Out: {out.shape}')
144/110:
from BraTs.pytorch.models.unet import UNet

model = UNet(drop_rate = 0.1)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
144/111:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
144/112:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
144/113:
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
'''
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)
'''
# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=dataloader_training,
                  validation_DataLoader=dataloader_validation,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
144/114:
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
'''
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)
'''
# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
144/115:
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
'''
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)
'''
# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
144/116:
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
'''
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)
'''
# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
144/117:
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
'''
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)
'''
# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
144/118:
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
'''
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)
'''
# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
141/20: import ipywidgets
144/119:
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
'''
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)
'''
# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
144/120:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
'''
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)
'''
# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
144/121:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
'''
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)
'''
# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
144/122:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
'''
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)
'''
# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
144/123:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
'''
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)
'''
# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
144/124:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
'''
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)
'''
# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
144/125:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
'''
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)
'''
# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
144/126:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
'''
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)
'''
# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
145/1:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            if i==7000:
                print(folder_name)
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            if i==7000:
                print(folder_name)
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
145/2:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
145/3:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
145/4:
from BraTs.pytorch.models.unet import UNet

model = UNet(drop_rate = 0.1)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
145/5:
from BraTs.pytorch.models.unet import UNet

model = UNet(drop_rate = 0.1)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
145/6:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
145/7:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
145/8:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
'''
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)
'''
# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
145/9:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
145/10: %debug
146/1:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        print(input_ID)
        print(target_ID)  
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
146/2:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/3:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/4:
from BraTs.pytorch.models.unet import UNet

model = UNet(drop_rate = 0.1)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
146/5:
from BraTs.pytorch.models.unet import UNet

model = UNet(drop_rate = 0.1)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
146/6:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
146/7:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
146/8:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model

model = UNet(drop_rate = 0.1).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
141/21:
z = 85
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
ax[4].imshow(seg[:,:,z]>0.5)
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('Segmentation')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(2,5, figsize=(17,7))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('FLAIR - Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
    ax[1,i].set_title('Segmentation - Slice: {}'.format(z))
#     ax[2,i].imshow(seg[:,:,z]==1)
#     ax[3,i].imshow(seg[:,:,z]==2)
#     ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
146/9:
import argparse
import logging
import pdb

import torch
import torch.backends.cudnn as cudnn

from BraTs.pytorch.config import *
#from BraTs.pytorch.dataset import *
from BraTs.pytorch.models import *
from BraTs.pytorch.utils import *


def train(args):

    # Variables and logger Init
    device = config.device
    cudnn.benchmark = True
    get_logger()

    # Data Load
    trainloader = training_dataloader
    validloader = validation_dataloader

    # Model Load
    net, optimizer, best_score, start_epoch =\
        load_model(args, class_num=config.class_num, mode='train')
    log_msg = '\n'.join(['%s Train Start'%(args.model)])
    logging.info(log_msg)

    for epoch in range(start_epoch, start_epoch+args.epochs):

        # Train Model
        print('\n\n\nEpoch: {}\n<Train>'.format(epoch))
        net.train(True)
        loss = 0
        lr = args.lr * (0.5 ** (epoch // 4))
        for param_group in optimizer.param_groups:
            param_group["lr"] = lr
        torch.set_grad_enabled(True)
        for idx, (inputs, targets, paths) in enumerate(trainloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            if type(outputs) == tuple:
                outputs = outputs[0]
            batch_loss = dice_coef(outputs, targets)
            optimizer.zero_grad()
            batch_loss.backward()
            optimizer.step()
            loss += float(batch_loss)
            progress_bar(idx, len(trainloader), 'Loss: %.5f, Dice-Coef: %.5f'
                         %((loss/(idx+1)), (1-(loss/(idx+1)))))
        log_msg = '\n'.join(['Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'\
                         %(epoch, loss/(idx+1), 1-(loss/(idx+1)))])
        logging.info(log_msg)

        # Validate Model
        print('\n\n<Validation>')
        net.eval()
        for module in net.module.modules():
            if isinstance(module, torch.nn.modules.Dropout2d):
                module.train(True)
            elif isinstance(module, torch.nn.modules.Dropout):
                module.train(True)
            else:
                pass
        loss = 0
        torch.set_grad_enabled(False)
        for idx, (inputs, targets, paths) in enumerate(validloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            if type(outputs) == tuple:
                outputs = outputs[0]
            #outputs = post_process(args, inputs, outputs, save=False)
            batch_loss = dice_coef(outputs, targets, backprop=False)
            loss += float(batch_loss)
            progress_bar(idx, len(validloader), 'Loss: %.5f, Dice-Coef: %.5f'
                         %((loss/(idx+1)), (1-(loss/(idx+1)))))
        log_msg = '\n'.join(['Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'
                        %(epoch, loss/(idx+1), 1-(loss/(idx+1)))])
        logging.info(log_msg)

        # Save Model
        loss /= (idx+1)
        score = 1 - loss
        if score > best_score:
            checkpoint = Checkpoint(net, optimizer, epoch, score)
            checkpoint.save(os.path.join(args.ckpt_root, args.model+'.tar'))
            best_score = score
            print("Saving...")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("--resume", type=bool, default=False,
                        help="Model Trianing resume.")
    parser.add_argument("--model", type=str, default='pspnet_res50',
                        help="Model Name (unet, pspnet_squeeze, pspnet_res50,\
                        pspnet_res34, pspnet_res50, deeplab)")
    parser.add_argument("--in_channel", type=int, default=1,
                        help="A number of images to use for input")
    parser.add_argument("--batch_size", type=int, default=80,
                        help="The batch size to load the data")
    parser.add_argument("--epochs", type=int, default=30,
                        help="The training epochs to run.")
    parser.add_argument("--drop_rate", type=float, default=0.1,
                        help="Drop-out Rate")
    parser.add_argument("--lr", type=float, default=0.001,
                        help="Learning rate to use in training")
    parser.add_argument("--data", type=str, default="complete",
                        help="Label data type.")
    parser.add_argument("--img_root", type=str, default="../../data/train/image_FLAIR",
                        help="The directory containing the training image dataset.")
    parser.add_argument("--label_root", type=str, default="../../data/train/label",
                        help="The directory containing the training label dataset")
    parser.add_argument("--output_root", type=str, default="./output/prediction",
                        help="The directory containing the result predictions")
    parser.add_argument("--ckpt_root", type=str, default="./checkpoint",
                        help="The directory containing the checkpoint files")
    args = parser.parse_args()

    train(args)
146/10:
import argparse
import logging
import pdb

import torch
import torch.backends.cudnn as cudnn

from BraTs.pytorch.config import *
#from BraTs.pytorch.dataset import *
from BraTs.pytorch.models import *
from BraTs.pytorch.utils import *


def train(args):

    # Variables and logger Init
    device = config.device
    cudnn.benchmark = True
    get_logger()

    # Data Load
    trainloader = training_dataloader
    validloader = validation_dataloader

    # Model Load
    net, optimizer, best_score, start_epoch =\
        load_model(args, class_num=config.class_num, mode='train')
    log_msg = '\n'.join(['%s Train Start'%(args.model)])
    logging.info(log_msg)

    for epoch in range(start_epoch, start_epoch+args.epochs):

        # Train Model
        print('\n\n\nEpoch: {}\n<Train>'.format(epoch))
        net.train(True)
        loss = 0
        lr = args.lr * (0.5 ** (epoch // 4))
        for param_group in optimizer.param_groups:
            param_group["lr"] = lr
        torch.set_grad_enabled(True)
        for idx, (inputs, targets, paths) in enumerate(trainloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            if type(outputs) == tuple:
                outputs = outputs[0]
            batch_loss = dice_coef(outputs, targets)
            optimizer.zero_grad()
            batch_loss.backward()
            optimizer.step()
            loss += float(batch_loss)
            progress_bar(idx, len(trainloader), 'Loss: %.5f, Dice-Coef: %.5f'
                         %((loss/(idx+1)), (1-(loss/(idx+1)))))
        log_msg = '\n'.join(['Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'\
                         %(epoch, loss/(idx+1), 1-(loss/(idx+1)))])
        logging.info(log_msg)

        # Validate Model
        print('\n\n<Validation>')
        net.eval()
        for module in net.module.modules():
            if isinstance(module, torch.nn.modules.Dropout2d):
                module.train(True)
            elif isinstance(module, torch.nn.modules.Dropout):
                module.train(True)
            else:
                pass
        loss = 0
        torch.set_grad_enabled(False)
        for idx, (inputs, targets, paths) in enumerate(validloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            if type(outputs) == tuple:
                outputs = outputs[0]
            #outputs = post_process(args, inputs, outputs, save=False)
            batch_loss = dice_coef(outputs, targets, backprop=False)
            loss += float(batch_loss)
            progress_bar(idx, len(validloader), 'Loss: %.5f, Dice-Coef: %.5f'
                         %((loss/(idx+1)), (1-(loss/(idx+1)))))
        log_msg = '\n'.join(['Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'
                        %(epoch, loss/(idx+1), 1-(loss/(idx+1)))])
        logging.info(log_msg)

        # Save Model
        loss /= (idx+1)
        score = 1 - loss
        if score > best_score:
            checkpoint = Checkpoint(net, optimizer, epoch, score)
            checkpoint.save(os.path.join(args.ckpt_root, args.model+'.tar'))
            best_score = score
            print("Saving...")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("--resume", type=bool, default=False,
                        help="Model Trianing resume.")
    parser.add_argument("--model", type=str, default='pspnet_res50',
                        help="Model Name (unet, pspnet_squeeze, pspnet_res50,\
                        pspnet_res34, pspnet_res50, deeplab)")
    parser.add_argument("--in_channel", type=int, default=1,
                        help="A number of images to use for input")
    parser.add_argument("--batch_size", type=int, default=80,
                        help="The batch size to load the data")
    parser.add_argument("--epochs", type=int, default=30,
                        help="The training epochs to run.")
    parser.add_argument("--drop_rate", type=float, default=0.1,
                        help="Drop-out Rate")
    parser.add_argument("--lr", type=float, default=0.001,
                        help="Learning rate to use in training")
    parser.add_argument("--data", type=str, default="complete",
                        help="Label data type.")
    parser.add_argument("--img_root", type=str, default="../../data/train/image_FLAIR",
                        help="The directory containing the training image dataset.")
    parser.add_argument("--label_root", type=str, default="../../data/train/label",
                        help="The directory containing the training label dataset")
    parser.add_argument("--output_root", type=str, default="./output/prediction",
                        help="The directory containing the result predictions")
    parser.add_argument("--ckpt_root", type=str, default="./checkpoint",
                        help="The directory containing the checkpoint files")
    args = parser.parse_args()

    train(args)
146/11:
import argparse
import logging
import pdb

import torch
import torch.backends.cudnn as cudnn

from BraTs.pytorch.config import *
#from BraTs.pytorch.dataset import *
from BraTs.pytorch.models import *
from BraTs.pytorch.utils import *


def train(args):

    # Variables and logger Init
    device = config.device
    cudnn.benchmark = True
    get_logger()

    # Data Load
    trainloader = training_dataloader
    validloader = validation_dataloader

    # Model Load
    net, optimizer, best_score, start_epoch =\
        load_model(args, class_num=config.class_num, mode='train')
    log_msg = '\n'.join(['%s Train Start'%(args.model)])
    logging.info(log_msg)

    for epoch in range(start_epoch, start_epoch+args.epochs):

        # Train Model
        print('\n\n\nEpoch: {}\n<Train>'.format(epoch))
        net.train(True)
        loss = 0
        lr = args.lr * (0.5 ** (epoch // 4))
        for param_group in optimizer.param_groups:
            param_group["lr"] = lr
        torch.set_grad_enabled(True)
        for idx, (inputs, targets, paths) in enumerate(trainloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            if type(outputs) == tuple:
                outputs = outputs[0]
            batch_loss = dice_coef(outputs, targets)
            optimizer.zero_grad()
            batch_loss.backward()
            optimizer.step()
            loss += float(batch_loss)
            progress_bar(idx, len(trainloader), 'Loss: %.5f, Dice-Coef: %.5f'
                         %((loss/(idx+1)), (1-(loss/(idx+1)))))
        log_msg = '\n'.join(['Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'\
                         %(epoch, loss/(idx+1), 1-(loss/(idx+1)))])
        logging.info(log_msg)

        # Validate Model
        print('\n\n<Validation>')
        net.eval()
        for module in net.module.modules():
            if isinstance(module, torch.nn.modules.Dropout2d):
                module.train(True)
            elif isinstance(module, torch.nn.modules.Dropout):
                module.train(True)
            else:
                pass
        loss = 0
        torch.set_grad_enabled(False)
        for idx, (inputs, targets, paths) in enumerate(validloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            if type(outputs) == tuple:
                outputs = outputs[0]
            #outputs = post_process(args, inputs, outputs, save=False)
            batch_loss = dice_coef(outputs, targets, backprop=False)
            loss += float(batch_loss)
            progress_bar(idx, len(validloader), 'Loss: %.5f, Dice-Coef: %.5f'
                         %((loss/(idx+1)), (1-(loss/(idx+1)))))
        log_msg = '\n'.join(['Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'
                        %(epoch, loss/(idx+1), 1-(loss/(idx+1)))])
        logging.info(log_msg)

        # Save Model
        loss /= (idx+1)
        score = 1 - loss
        if score > best_score:
            checkpoint = Checkpoint(net, optimizer, epoch, score)
            checkpoint.save(os.path.join(args.ckpt_root, args.model+'.tar'))
            best_score = score
            print("Saving...")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("--resume", type=bool, default=False,
                        help="Model Trianing resume.")
    parser.add_argument("--model", type=str, default='pspnet_res50',
                        help="Model Name (unet, pspnet_squeeze, pspnet_res50,\
                        pspnet_res34, pspnet_res50, deeplab)")
    parser.add_argument("--in_channel", type=int, default=1,
                        help="A number of images to use for input")
    parser.add_argument("--batch_size", type=int, default=80,
                        help="The batch size to load the data")
    parser.add_argument("--epochs", type=int, default=30,
                        help="The training epochs to run.")
    parser.add_argument("--drop_rate", type=float, default=0.1,
                        help="Drop-out Rate")
    parser.add_argument("--lr", type=float, default=0.001,
                        help="Learning rate to use in training")
    parser.add_argument("--data", type=str, default="complete",
                        help="Label data type.")
    parser.add_argument("--img_root", type=str, default="../../data/train/image_FLAIR",
                        help="The directory containing the training image dataset.")
    parser.add_argument("--label_root", type=str, default="../../data/train/label",
                        help="The directory containing the training label dataset")
    parser.add_argument("--output_root", type=str, default="./output/prediction",
                        help="The directory containing the result predictions")
    parser.add_argument("--ckpt_root", type=str, default="./checkpoint",
                        help="The directory containing the checkpoint files")
    args = parser.parse_args()

    train(args)
146/12:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
146/13:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
146/14:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
141/22:
z = 85
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
# ax[4].imshow(seg[:,:,z]>0.5)
ax[4].imshow(np.stack((seg[:,:,z]==1,seg[:,:,z]==2,seg[:,:,z]==4)))
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('Segmentation')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(2,5, figsize=(17,7))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('FLAIR - Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
    ax[1,i].set_title('Segmentation - Slice: {}'.format(z))
#     ax[2,i].imshow(seg[:,:,z]==1)
#     ax[3,i].imshow(seg[:,:,z]==2)
#     ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/23:
z = 85
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
# ax[4].imshow(seg[:,:,z]>0.5)
ax[4].imshow(np.stack((seg[:,:,z]==1,seg[:,:,z]==2,seg[:,:,z]==4), axis=2))
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('Segmentation')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(2,5, figsize=(17,7))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('FLAIR - Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
    ax[1,i].set_title('Segmentation - Slice: {}'.format(z))
#     ax[2,i].imshow(seg[:,:,z]==1)
#     ax[3,i].imshow(seg[:,:,z]==2)
#     ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
146/15:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
146/16:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
141/24:
z = 85
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
# ax[4].imshow(seg[:,:,z]>0.5)
ax[4].imshow(np.stack((1.0*seg[:,:,z]==1,1.0*seg[:,:,z]==2,1.0*seg[:,:,z]==4), axis=2))
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('Segmentation')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(2,5, figsize=(17,7))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('FLAIR - Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
    ax[1,i].set_title('Segmentation - Slice: {}'.format(z))
#     ax[2,i].imshow(seg[:,:,z]==1)
#     ax[3,i].imshow(seg[:,:,z]==2)
#     ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/25:
z = 85
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
# ax[4].imshow(seg[:,:,z]>0.5)
r=(seg[:,:,z]==1).astype(np.float16)
g=(seg[:,:,z]==2).astype(np.float16)
b=(seg[:,:,z]==4).astype(np.float16)
ax[4].imshow(np.stack((r,g,b), axis=2))
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('Segmentation')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(2,5, figsize=(17,7))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('FLAIR - Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
    ax[1,i].set_title('Segmentation - Slice: {}'.format(z))
#     ax[2,i].imshow(seg[:,:,z]==1)
#     ax[3,i].imshow(seg[:,:,z]==2)
#     ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/26: np.dtype(r)
141/27: r.dtype
141/28: r.shape
146/17:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/18:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)

        return x, y
146/19:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/20:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=2,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/21:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/22:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
146/23:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=240,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
146/24:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=240,
             out_channels=240,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
146/25:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=240,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
146/26:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
146/27:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))
x = np.expand_dims(x, 1)

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/28:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/29:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))
x = np.expand_dims(x, 1)

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/30:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))
x = np.expand_dims(x, 1)
y = np.expand_dims(y, 1)

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/31:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))
x = np.expand_dims(x, 1)
y = y.unsqueeze(1)

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/32:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))
x = np.expand_dims(x, 1)
y = y.unsqueeze(1)

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/33:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
146/34:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
146/35:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
146/36:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
146/37:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 1)
        y = y.unsqueeze(1)
        return x, y
146/38:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/39:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        y = y.unsqueeze(0)
        return x, y
146/40:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/41:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/42:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
146/43:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
146/44:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
146/45:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
146/46:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
146/47:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/48:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/49:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
146/50:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
146/51:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
146/52:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
146/53: training_losses
146/54:
training_losses
validation_losses
146/55: training_losses
146/56: validation_losses
143/79:
for i, path in enumerate(os.listdir(training_root)):
    if i>=50:
        scans_nii2jpg(os.path.join(training_root,path),'projects/auggan/dataset/slices_2d/validation/scans')
    if i==70:
        break
    scans_nii2jpg(os.path.join(training_root,path),'projects/auggan/dataset/slices_2d/training/scans')
143/80:
for i, path in enumerate(os.listdir(training_root)):
    if i>=50:
        labels_nii2jpg(os.path.join(training_root,path),'projects/auggan/dataset/slices_2d/validation/labels')
    if i==70:
        break
    labels_nii2jpg(os.path.join(training_root,path),'projects/auggan/dataset/slices_2d/training/labels')
146/57:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
146/58:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/59:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/60:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
146/61:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
146/62:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
146/63:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
146/64:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')

    return fig
146/65:
fig = plot_training(training_losses,
                   validation_losses,
                   learning_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
146/66:
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
146/67:
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))

plt.imshow()
146/68:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    
    plt.show()

    return fig
146/69:
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
146/70:
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
plt.show()
146/71:
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
146/72:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
146/73:
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
146/74:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    #import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
146/75:
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
146/76:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
146/77:
# Imports
import pathlib

import numpy as np
import torch
from skimage.io import imread
from skimage.transform import resize

from inference import predict
from transformations import normalize_01, re_normalize
from unet import UNet

# root directory
root = pathlib.Path.cwd() / 'Carvana' / 'Test'
def get_filenames_of_path(path: pathlib.Path, ext: str = '*'):
    """Returns a list of files in a directory/path. Uses pathlib."""
    filenames = [file for file in path.glob(ext) if file.is_file()]
    return filenames

# input and target files
images_names = get_filenames_of_path(root / 'Input')
targets_names = get_filenames_of_path(root / 'Target')

# read images and store them in memory
images = [imread(img_name) for img_name in images_names]
targets = [imread(tar_name) for tar_name in targets_names]

# Resize images and targets
images_res = [resize(img, (128, 128, 3)) for img in images]
resize_kwargs = {'order': 0, 'anti_aliasing': False, 'preserve_range': True}
targets_res = [resize(tar, (128, 128), **resize_kwargs) for tar in targets]

# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

# preprocess function
def preprocess(img: np.ndarray):
    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img

# predict the segmentation maps 
output = [predict(img, model, preprocess, postprocess, device) for img in images_res]
146/78:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(trainloader, 0):
        image,label = data
        print(image.shape)
        if i==0:
            break
    '''
    # Generate prediction
    prediction = UNet(image)

    # Predicted class value using argmax
    predicted_class = np.argmax(prediction)

    # Reshape image
    image = image.reshape(28, 28, 1)

    # Show result
    plt.imshow(image, cmap='gray')
    plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    '''
146/79:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        print(image.shape)
        if i==0:
            break
    '''
    # Generate prediction
    prediction = UNet(image)

    # Predicted class value using argmax
    predicted_class = np.argmax(prediction)

    # Reshape image
    image = image.reshape(28, 28, 1)

    # Show result
    plt.imshow(image, cmap='gray')
    plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    '''
146/80:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[1,:,:,:]
        print(image.shape)
        if i==0:
            break
    '''
    # Generate prediction
    prediction = UNet(image)

    # Predicted class value using argmax
    predicted_class = np.argmax(prediction)

    # Reshape image
    image = image.reshape(28, 28, 1)

    # Show result
    plt.imshow(image, cmap='gray')
    plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    '''
146/81:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[1,:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    prediction = UNet(image)

    # Predicted class value using argmax
    predicted_class = np.argmax(prediction)

    # Reshape image
    image = image.reshape(28, 28, 1)

    # Show result
    plt.imshow(image, cmap='gray')
    plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/82:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[1,:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    prediction = UNet(image)

    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)

    # Reshape image
    image = image.reshape(28, 28, 1)

    # Show result
    plt.imshow(image, cmap='gray')
    plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/83:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[1,:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    prediction = model(image)

    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)

    # Reshape image
    image = image.reshape(28, 28, 1)

    # Show result
    plt.imshow(image, cmap='gray')
    plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/84:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        #image = image[1,:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    prediction = model(image)

    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)

    # Reshape image
    image = image.reshape(28, 28, 1)

    # Show result
    plt.imshow(image, cmap='gray')
    plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/85:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        #image = image[1,:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)

    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)

    # Reshape image
    image = image.reshape(28, 28, 1)

    # Show result
    plt.imshow(image, cmap='gray')
    plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/86:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        #image = image[1,:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)

    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)

    # Reshape image
    image = image.reshape(240, 240, 1)

    # Show result
    plt.imshow(image, cmap='gray')
    plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/87:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)

    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)

    # Reshape image
    image = image.reshape(240, 240, 1)

    # Show result
    plt.imshow(image, cmap='gray')
    plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/88:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)

    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)

    # Reshape image
    image = image.reshape(240, 240)

    # Show result
    plt.imshow(image, cmap='gray')
    plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/89:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)

    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)

    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/90:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)

    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)

    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/91:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)

    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)

    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/92:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)

    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/93:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/94:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/95:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction[:,0,:,:]
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/96:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction[:,0,:,:]
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/97:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction[:,0,:,:]
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/98:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction[:,0,:,:]
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/99:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction[:,0,:,:]
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/100:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction[:,0,:,:]
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/101:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction[:,0,:,:]
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/102:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction[:,0,:,:]
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/103:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction[:,0,:,:]
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/104:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction[:,0,:,:]
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/105:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction[:,0,:,:]
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/106:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction[:,0,:,:]
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/107:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction[:,0,:,:]
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/108:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction[:,0,:,:]
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/109:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction[:,0,:,:]
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/110:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    image = prediction[:,0,:,:]
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/111:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/112:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/113:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/114:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/115:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/116:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/117:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/118:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/119:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/120:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/121:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/122:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/123:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/124:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/125:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/126:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction2[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/127:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/128:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/129:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/130:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/131:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/132:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/133:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction-prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/134:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction-prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/135:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction-prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/136:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction-prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/137:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction-prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/138:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction-prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/139:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/140:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
146/141:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
146/142:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/143:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/144:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
146/145:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
146/146:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
146/147:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
146/148:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
146/149:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
146/150:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/151:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/152:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
146/153:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
146/154:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
146/155:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
146/156:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/157:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/158:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=1,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
146/159:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
146/160:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
146/161:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
146/162:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    #import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
146/163:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
146/164:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/165:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/166:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/167:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/168:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,1,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/169:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
146/170:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
146/171:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/172:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/173:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=1,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
146/174:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
146/175:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
146/176:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
146/177:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    #import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
146/178:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
146/179:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    '''
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    '''
    #prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
146/180:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
146/181:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
146/182:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/183:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/184:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=1,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
146/185:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
146/186:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
146/187:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
146/188:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=1,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
146/189:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=1,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
146/190:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
146/191:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/192:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
146/193:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
146/194:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
148/1:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
148/2:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
148/3:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
148/4:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
149/1:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
149/2:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
149/3:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
149/4:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=1,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
149/5:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
149/6:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
149/7:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=1,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
150/1:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
150/2:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
150/3:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
151/1:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
151/2:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
151/3:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
151/4:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
151/5:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
151/6:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
151/7:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
151/8:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
151/9:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    #import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
151/10:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
151/11:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    #prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
151/12:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
151/13:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
151/14:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
151/15:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
151/16:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
151/17:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
151/18:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
151/19:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
151/20:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
151/21:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
151/22:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
152/1:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
152/2:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
152/3:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
152/4:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
152/5:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
152/6:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
152/7:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
152/8:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
152/9:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
152/10:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
152/11:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
152/12:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=1,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
152/13:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
152/14:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
152/15:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=1,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
141/29:
z = 85
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
# ax[4].imshow(seg[:,:,z]>0.5)
r=(seg[:,:,z]==1).astype(np.float16)
g=(seg[:,:,z]==2).astype(np.float16)
b=(seg[:,:,z]==4).astype(np.float16)
ax[4].imshow(np.stack((r,g,b), axis=2))
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('Segmentation')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(2,5, figsize=(17,7))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('FLAIR - Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
    ax[1,i].set_title('Segmentation - Slice: {}'.format(z))
#     ax[2,i].imshow(seg[:,:,z]==1)
#     ax[3,i].imshow(seg[:,:,z]==2)
#     ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/30: plt.imshow(r)
141/31: type(r)
141/32: r.dtype
141/33:
z = 85
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
# ax[4].imshow(seg[:,:,z]>0.5)
r=(seg[:,:,z]==1).astype(np.float32)
g=(seg[:,:,z]==2).astype(np.float32)
b=(seg[:,:,z]==4).astype(np.float32)
ax[4].imshow(np.stack((r,g,b), axis=2))
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('Segmentation')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(2,5, figsize=(17,7))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('FLAIR - Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
    ax[1,i].set_title('Segmentation - Slice: {}'.format(z))
#     ax[2,i].imshow(seg[:,:,z]==1)
#     ax[3,i].imshow(seg[:,:,z]==2)
#     ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/34:
z = 85
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
# ax[4].imshow(seg[:,:,z]>0.5)
r=(seg[:,:,z]==1).astype(np.float32)
g=(seg[:,:,z]==2).astype(np.float32)
b=(seg[:,:,z]==4).astype(np.float32)
ax[4].imshow(np.stack((r,g,b), axis=2))
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('Segmentation')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
# fig, ax = plt.subplots(2,5, figsize=(17,7))
fig, ax = plt.subplots(5,5, figsize=(17,17))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('FLAIR - Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
    ax[1,i].set_title('Segmentation - Slice: {}'.format(z))
    ax[2,i].imshow(seg[:,:,z]==1)
    ax[3,i].imshow(seg[:,:,z]==2)
    ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/35:
z = 75
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
# ax[4].imshow(seg[:,:,z]>0.5)
r=(seg[:,:,z]==1).astype(np.float32)
g=(seg[:,:,z]==2).astype(np.float32)
b=(seg[:,:,z]==4).astype(np.float32)
ax[4].imshow(np.stack((r,g,b), axis=2))
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('Segmentation')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
# fig, ax = plt.subplots(2,5, figsize=(17,7))
fig, ax = plt.subplots(5,5, figsize=(17,17))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('FLAIR - Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
    ax[1,i].set_title('Segmentation - Slice: {}'.format(z))
    ax[2,i].imshow(seg[:,:,z]==1)
    ax[3,i].imshow(seg[:,:,z]==2)
    ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/36:
from matplotlib.lines import Line2D
custom_lines = [Line2D([0], [0], color='r', lw=4),
                Line2D([0], [0], color='g', lw=4),
                Line2D([0], [0], color='b', lw=4)]

z = 75
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
# ax[4].imshow(seg[:,:,z]>0.5)
r=(seg[:,:,z]==1).astype(np.float32)
g=(seg[:,:,z]==2).astype(np.float32)
b=(seg[:,:,z]==4).astype(np.float32)
ax[4].imshow(np.stack((r,g,b), axis=2))
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('Segmentation')
ax[4].legend(custom_lines, ['NCR/NET', 'ED', 'ET'])

# fig, ax = plt.subplots(2,5, figsize=(17,10))
# fig, ax = plt.subplots(2,5, figsize=(17,7))
fig, ax = plt.subplots(5,5, figsize=(17,17))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('FLAIR - Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
    ax[1,i].set_title('Segmentation - Slice: {}'.format(z))
    ax[2,i].imshow(seg[:,:,z]==1)
    ax[3,i].imshow(seg[:,:,z]==2)
    ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
154/1:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
154/2:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
154/3:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
154/4:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=1,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
154/5:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
154/6:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
154/7:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=1,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
141/37:
from matplotlib.lines import Line2D
custom_lines = [Line2D([0], [0], color='r', lw=4),
                Line2D([0], [0], color='g', lw=4),
                Line2D([0], [0], color='b', lw=4)]

z = 75
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
# ax[4].imshow(seg[:,:,z]>0.5)
r=(seg[:,:,z]==1).astype(np.float32)
g=(seg[:,:,z]==2).astype(np.float32)
b=(seg[:,:,z]==4).astype(np.float32)
ax[4].imshow(np.stack((r,g,b), axis=2))
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('Segmentation')
ax[4].legend(custom_lines, ['NCR/NET', 'ED', 'ET'], loc='lower left')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
# fig, ax = plt.subplots(2,5, figsize=(17,7))
fig, ax = plt.subplots(5,5, figsize=(17,17))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('FLAIR - Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
    ax[1,i].set_title('Segmentation - Slice: {}'.format(z))
    ax[2,i].imshow(seg[:,:,z]==1)
    ax[3,i].imshow(seg[:,:,z]==2)
    ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
155/1:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
155/2:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
155/3:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
155/4:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
155/5:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
155/6:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
155/7:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
141/38:
from matplotlib.lines import Line2D
custom_lines = [Line2D([0], [0], color='r', lw=4),
                Line2D([0], [0], color='g', lw=4),
                Line2D([0], [0], color='b', lw=4)]

def label_to_rgb(x):
    r=(x==1).astype(np.float32)
    g=(x==2).astype(np.float32)
    b=(x==4).astype(np.float32)
    return np.stack((r,g,b), axis=2)

z = 75
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
# ax[4].imshow(seg[:,:,z]>0.5)
ax[4].imshow(label_to_rgb(seg[:,:,z]))
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('Segmentation')
ax[4].legend(custom_lines, ['NCR/NET', 'ED', 'ET'], loc='lower left')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
# fig, ax = plt.subplots(2,5, figsize=(17,7))
fig, ax = plt.subplots(5,5, figsize=(17,17))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('FLAIR - Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
    ax[1,i].set_title('Segmentation - Slice: {}'.format(z))
    ax[2,i].imshow(seg[:,:,z]==1)
    ax[3,i].imshow(seg[:,:,z]==2)
    ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/39:
from matplotlib.lines import Line2D
custom_lines = [Line2D([0], [0], color='r', lw=4),
                Line2D([0], [0], color='g', lw=4),
                Line2D([0], [0], color='b', lw=4)]

def label_to_rgb(x):
    r=(x==1).astype(np.float32)
    g=(x==2).astype(np.float32)
    b=(x==4).astype(np.float32)
    return np.stack((r,g,b), axis=2)

z = 75
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
# ax[4].imshow(seg[:,:,z]>0.5)
ax[4].imshow(label_to_rgb(seg[:,:,z]))
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('Segmentation')
ax[4].legend(custom_lines, ['NCR/NET', 'ED', 'ET'], loc='lower left')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
# fig, ax = plt.subplots(2,5, figsize=(17,7))
fig, ax = plt.subplots(5,5, figsize=(17,17))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('FLAIR - Slice: {}'.format(z))
    ax[1,i].imshow(label_to_rgb(seg[:,:,z]))
    ax[1,i].set_title('Segmentation - Slice: {}'.format(z))
#     ax[2,i].imshow(seg[:,:,z]==1)
#     ax[3,i].imshow(seg[:,:,z]==2)
#     ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
141/40:
from matplotlib.lines import Line2D
custom_lines = [Line2D([0], [0], color='r', lw=4),
                Line2D([0], [0], color='g', lw=4),
                Line2D([0], [0], color='b', lw=4)]

def label_to_rgb(x):
    r=(x==1).astype(np.float32)
    g=(x==2).astype(np.float32)
    b=(x==4).astype(np.float32)
    return np.stack((r,g,b), axis=2)

z = 75
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
# ax[4].imshow(seg[:,:,z]>0.5)
ax[4].imshow(label_to_rgb(seg[:,:,z]))
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('Segmentation')
ax[4].legend(custom_lines, ['NCR/NET', 'ED', 'ET'], loc='lower left')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(2,5, figsize=(17,7))
# fig, ax = plt.subplots(5,5, figsize=(17,17))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('FLAIR - Slice: {}'.format(z))
    ax[1,i].imshow(label_to_rgb(seg[:,:,z]))
    ax[1,i].set_title('Segmentation - Slice: {}'.format(z))
#     ax[2,i].imshow(seg[:,:,z]==1)
#     ax[3,i].imshow(seg[:,:,z]==2)
#     ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
155/8:
model_name =  'carvana_model.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
155/9:
import pathlib

model_name =  'carvana_model.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
155/10:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    #import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
155/11:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
155/12:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
155/13:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
155/14:
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
155/15:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=3,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

# preprocess function
def preprocess(img: np.ndarray):
    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img

# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/16:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

# preprocess function
def preprocess(img: np.ndarray):
    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img

# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/17:
from inference import predict

if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

# preprocess function
def preprocess(img: np.ndarray):
    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img

# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/18:
def predict(
    img,
    model,
    preprocess,
    postprocess,
    device,
):
    model.eval()
    img = preprocess(img)  # preprocess image
    x = torch.from_numpy(img).to(device)  # to torch, send to device
    with torch.no_grad():
        out = model(x)  # send through model/network

    out_softmax = torch.softmax(out, dim=1)  # perform softmax on outputs
    result = postprocess(out_softmax)  # postprocess outputs

    return result
155/19:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

# preprocess function
def preprocess(img: np.ndarray):
    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img

# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/20:
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[1,:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
155/21:
def predict(
    img,
    model,
    preprocess,
    postprocess,
    device,
):
    model.eval()
    img = preprocess(img)  # preprocess image
    x = torch.from_numpy(img).to(device)  # to torch, send to device
    with torch.no_grad():
        out = model(x)  # send through model/network

    out_softmax = torch.softmax(out, dim=1)  # perform softmax on outputs
    result = postprocess(out_softmax)  # postprocess outputs

    return result
155/22:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

# preprocess function
def preprocess(img: np.ndarray):
    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img

# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/23:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img

# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/24:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
155/25:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    print(img)
    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img

# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/26:
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[1,:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    #image = image.cuda()
155/27:
def predict(
    img,
    model,
    preprocess,
    postprocess,
    device,
):
    model.eval()
    img = preprocess(img)  # preprocess image
    x = torch.from_numpy(img).to(device)  # to torch, send to device
    with torch.no_grad():
        out = model(x)  # send through model/network

    out_softmax = torch.softmax(out, dim=1)  # perform softmax on outputs
    result = postprocess(out_softmax)  # postprocess outputs

    return result
155/28:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    print(img)
    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img

# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/29:
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[1,:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    #image = image.cuda()
    image = image.numpy()
155/30:
def predict(
    img,
    model,
    preprocess,
    postprocess,
    device,
):
    model.eval()
    img = preprocess(img)  # preprocess image
    x = torch.from_numpy(img).to(device)  # to torch, send to device
    with torch.no_grad():
        out = model(x)  # send through model/network

    out_softmax = torch.softmax(out, dim=1)  # perform softmax on outputs
    result = postprocess(out_softmax)  # postprocess outputs

    return result
155/31:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    print(img)
    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img

# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
141/41:
from matplotlib.lines import Line2D
custom_lines = [Line2D([0], [0], color='r', lw=4),
                Line2D([0], [0], color='g', lw=4),
                Line2D([0], [0], color='b', lw=4)]

def label_to_rgb(x):
    r=(x==1).astype(np.float32)
    g=(x==2).astype(np.float32)
    b=(x==4).astype(np.float32)
    return np.stack((r,g,b), axis=2)

z = 75
plt.gray()
# for z in [5, 25, 55, 85, 135]:
fig, ax = plt.subplots(1,5, figsize=(17,10))
ax[0].imshow(t1[:,:,z])
ax[1].imshow(t1ce[:,:,z])
ax[2].imshow(flair[:,:,z])
ax[3].imshow(t2[:,:,z])
# ax[4].imshow(seg[:,:,z]>0.5)
ax[4].imshow(label_to_rgb(seg[:,:,z]))
ax[0].set_title('T1')
ax[1].set_title('T1c')
ax[2].set_title('FLAIR')
ax[3].set_title('T2')
ax[4].set_title('Segmentation')
ax[4].legend(custom_lines, ['NCR/NET', 'ED', 'ET'], loc='lower left')

# fig, ax = plt.subplots(2,5, figsize=(17,10))
fig, ax = plt.subplots(2,5, figsize=(17,7))
# fig, ax = plt.subplots(5,5, figsize=(17,17))
for i, z in enumerate([15, 45, 75, 105, 135]):
    ax[0,i].imshow(flair[:,:,z])
    ax[0,i].set_title('FLAIR - Slice: {}'.format(z))
    ax[1,i].imshow(seg[:,:,z]>0.5)
#     ax[1,i].imshow(label_to_rgb(seg[:,:,z]))
    ax[1,i].set_title('Segmentation - Slice: {}'.format(z))
#     ax[2,i].imshow(seg[:,:,z]==1)
#     ax[3,i].imshow(seg[:,:,z]==2)
#     ax[4,i].imshow(seg[:,:,z]==4)

# for i in range(im.shape[2]):
#     clear_output(wait=True)
#     plt.imshow(im[:,:,i])
#     plt.title(i)
#     plt.pause(0.1)
155/32:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

def normalize_01(inp: np.ndarray):
    """Squash image input to the value range [0, 1] (no clipping)"""
    inp_out = (inp - np.min(inp)) / np.ptp(inp)
    return inp_out

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    print(img)
    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img

# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/33:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

def normalize_01(inp: np.ndarray):
    """Squash image input to the value range [0, 1] (no clipping)"""
    inp_out = (inp - np.min(inp)) / np.ptp(inp)
    return inp_out

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    print(img)
    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img

print(image.shape)

# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/34:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

def normalize_01(inp: np.ndarray):
    """Squash image input to the value range [0, 1] (no clipping)"""
    inp_out = (inp - np.min(inp)) / np.ptp(inp)
    return inp_out

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    print(img)
    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    print(img.shape)
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img


# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/35:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

def normalize_01(inp: np.ndarray):
    """Squash image input to the value range [0, 1] (no clipping)"""
    inp_out = (inp - np.min(inp)) / np.ptp(inp)
    return inp_out

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    print(img)
    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    print(img.shape)
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    print(img.shape)
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img


# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/36:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

def normalize_01(inp: np.ndarray):
    """Squash image input to the value range [0, 1] (no clipping)"""
    inp_out = (inp - np.min(inp)) / np.ptp(inp)
    return inp_out

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    print(img)
    #img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    print(img.shape)
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    print(img.shape)
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img


# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/37:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

def normalize_01(inp: np.ndarray):
    """Squash image input to the value range [0, 1] (no clipping)"""
    inp_out = (inp - np.min(inp)) / np.ptp(inp)
    return inp_out

def re_normalize(inp: np.ndarray, low: int = 0, high: int = 255):
    """Normalize the data to a certain range. Default: [0-255]"""
    inp_out = bytescale(inp, low=low, high=high)
    return inp_out

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    print(img)
    #img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    print(img.shape)
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    print(img.shape)
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img


# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/38:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

from sklearn.externals._pilutil import bytescale

def normalize_01(inp: np.ndarray):
    """Squash image input to the value range [0, 1] (no clipping)"""
    inp_out = (inp - np.min(inp)) / np.ptp(inp)
    return inp_out

def re_normalize(inp: np.ndarray, low: int = 0, high: int = 255):
    """Normalize the data to a certain range. Default: [0-255]"""
    inp_out = bytescale(inp, low=low, high=high)
    return inp_out

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    print(img)
    #img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    print(img.shape)
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    print(img.shape)
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img


# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/39:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

import sklearn
from sklearn.externals._pilutil import bytescale

def normalize_01(inp: np.ndarray):
    """Squash image input to the value range [0, 1] (no clipping)"""
    inp_out = (inp - np.min(inp)) / np.ptp(inp)
    return inp_out

def re_normalize(inp: np.ndarray, low: int = 0, high: int = 255):
    """Normalize the data to a certain range. Default: [0-255]"""
    inp_out = bytescale(inp, low=low, high=high)
    return inp_out

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    print(img)
    #img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    print(img.shape)
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    print(img.shape)
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img


# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/40:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

from sklearn.externals._pilutil import bytescale

def normalize_01(inp: np.ndarray):
    """Squash image input to the value range [0, 1] (no clipping)"""
    inp_out = (inp - np.min(inp)) / np.ptp(inp)
    return inp_out

def re_normalize(inp: np.ndarray, low: int = 0, high: int = 255):
    """Normalize the data to a certain range. Default: [0-255]"""
    inp_out = bytescale(inp, low=low, high=high)
    return inp_out

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    print(img)
    #img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    print(img.shape)
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    print(img.shape)
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img


# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/41:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

from sklearn.externals._pilutil import bytescale

def normalize_01(inp: np.ndarray):
    """Squash image input to the value range [0, 1] (no clipping)"""
    inp_out = (inp - np.min(inp)) / np.ptp(inp)
    return inp_out

def re_normalize(inp: np.ndarray, low: int = 0, high: int = 255):
    """Normalize the data to a certain range. Default: [0-255]"""
    inp_out = bytescale(inp, low=low, high=high)
    return inp_out

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    print(img)
    #img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    print(img.shape)
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    print(img.shape)
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img


# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
print(output)
155/42:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

from sklearn.externals._pilutil import bytescale

def normalize_01(inp: np.ndarray):
    """Squash image input to the value range [0, 1] (no clipping)"""
    inp_out = (inp - np.min(inp)) / np.ptp(inp)
    return inp_out

def re_normalize(inp: np.ndarray, low: int = 0, high: int = 255):
    """Normalize the data to a certain range. Default: [0-255]"""
    inp_out = bytescale(inp, low=low, high=high)
    return inp_out

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    print(img)
    #img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    print(img.shape)
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    print(img.shape)
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img


# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
print(output.shape)
155/43:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

from sklearn.externals._pilutil import bytescale

def normalize_01(inp: np.ndarray):
    """Squash image input to the value range [0, 1] (no clipping)"""
    inp_out = (inp - np.min(inp)) / np.ptp(inp)
    return inp_out

def re_normalize(inp: np.ndarray, low: int = 0, high: int = 255):
    """Normalize the data to a certain range. Default: [0-255]"""
    inp_out = bytescale(inp, low=low, high=high)
    return inp_out

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    print(img)
    #img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    print(img.shape)
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    print(img.shape)
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img


# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/44:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
155/45:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

from sklearn.externals._pilutil import bytescale

def normalize_01(inp: np.ndarray):
    """Squash image input to the value range [0, 1] (no clipping)"""
    inp_out = (inp - np.min(inp)) / np.ptp(inp)
    return inp_out

def re_normalize(inp: np.ndarray, low: int = 0, high: int = 255):
    """Normalize the data to a certain range. Default: [0-255]"""
    inp_out = bytescale(inp, low=low, high=high)
    return inp_out

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    print(img)
    #img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    print(img.shape)
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    print(img.shape)
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img


# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/46:
import pathlib

model_name =  'carvana_model.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
155/47:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
155/48:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
155/49:
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[1,:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    #image = image.cuda()
    image = image.numpy()
155/50:
def predict(
    img,
    model,
    preprocess,
    postprocess,
    device,
):
    model.eval()
    img = preprocess(img)  # preprocess image
    x = torch.from_numpy(img).to(device)  # to torch, send to device
    with torch.no_grad():
        out = model(x)  # send through model/network

    out_softmax = torch.softmax(out, dim=1)  # perform softmax on outputs
    result = postprocess(out_softmax)  # postprocess outputs

    return result
155/51:
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)


model_name = 'carvana_model.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

from sklearn.externals._pilutil import bytescale

def normalize_01(inp: np.ndarray):
    """Squash image input to the value range [0, 1] (no clipping)"""
    inp_out = (inp - np.min(inp)) / np.ptp(inp)
    return inp_out

def re_normalize(inp: np.ndarray, low: int = 0, high: int = 255):
    """Normalize the data to a certain range. Default: [0-255]"""
    inp_out = bytescale(inp, low=low, high=high)
    return inp_out

# preprocess function
def preprocess(img: np.ndarray):
    print(img.shape)
    print(img)
    #img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]
    img = normalize_01(img)  # linear scaling to range [0-1]
    print(img.shape)
    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]
    img = img.astype(np.float32)  # typecasting to float32
    print(img.shape)
    return img


# postprocess function
def postprocess(img: torch.tensor):
    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel
    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray
    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]
    img = re_normalize(img)  # scale it to the range [0-255]
    return img


# predict the segmentation maps 
output = predict(image, model, preprocess, postprocess, device)
155/52:
# Disable grad
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
155/53:
# Disable grad
import matplotlib.pyplot as plt
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
155/54:
# Disable grad
import matplotlib.pyplot as plt
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
155/55:
# Disable grad
import matplotlib.pyplot as plt
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
155/56:
# Disable grad
import matplotlib.pyplot as plt
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
155/57:
# Disable grad
import matplotlib.pyplot as plt
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
155/58:
# Disable grad
import matplotlib.pyplot as plt
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
155/59:
# Disable grad
import matplotlib.pyplot as plt
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
155/60:
# Disable grad
import matplotlib.pyplot as plt
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
155/61:
# Disable grad
import matplotlib.pyplot as plt
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
155/62:
# Disable grad
import matplotlib.pyplot as plt
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
155/63:
# Disable grad
import matplotlib.pyplot as plt
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
155/64:
# Disable grad
import matplotlib.pyplot as plt
with torch.no_grad():

    # Retrieve item
#     index = 256
#     item = dataset[index]
#     image = item[0]
#     true_target = item[1]
    #path_test = 'projects/auggan/dataset/slices_2d/validation/scans/'
    #test = nib.load(path_test).get_fdata()
    for i, data in enumerate(training_dataloader, 0):
        image,label = data
        image = image[[1],:,:,:]
        print(image.shape)
        if i==0:
            break
    
    # Generate prediction
    image = image.cuda()
    prediction = model(image)
    print(prediction.shape)
    # Predicted class value using argmax
    #predicted_class = np.argmax(prediction)
    
    prediction2 = prediction[:,1,:,:]
    prediction2 = prediction2.reshape(240, 240)
    prediction2 = prediction2.cpu()
    prediction2 = prediction2.numpy()
    plt.imshow(prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    
    prediction = prediction[:,0,:,:]
    prediction = prediction.reshape(240, 240)
    prediction = prediction.cpu()
    prediction = prediction.numpy()
    plt.imshow(prediction+prediction2, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
    print(prediction)
    
    
    # Reshape image
    image = image.reshape(240, 240)
    image = image.cpu()
    image = image.numpy()
    # Show result
    plt.imshow(image, cmap='gray')
    #plt.title(f'Prediction: {predicted_class} - Actual target: {true_target}')
    plt.show()
155/65:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
155/66:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
155/67: type(x)
155/68: x[0,0].shape
155/69: x[0,0].max()
155/70: plt.imshow(x[0,0])
155/71: plt.imshow(x[10,0])
155/72: plt.imshow(x[15,0])
155/73: plt.imshow(x[25,0])
155/74:
plt.imshow(x[25,0])
plt.imshow(y[25])
155/75: y[25].max()
155/76: y[25].min()
155/77: y.max()
155/78:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
155/79:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
155/80: plt.imshow(x[3,0])
155/81:
plt.imshow(x[3,0])
plt.figure()
plt.imshow(y[3])
155/82:
plt.imshow(x[13,0])
plt.figure()
plt.imshow(y[13])
155/83:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
155/84:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
155/85: out.shape
155/86: out.max()
155/87: out.min()
155/88: plt.imshow(out[0,0])
155/89:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
155/90:
import numpy as np
import torch


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target)  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
155/91:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.05)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
155/92:
import pathlib

model_name =  'carvana_model.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
155/93:
with torch.no_grad():

        image,label = next(iter(training_dataloader))
        image = image[1,:,:,:]
        print(image.shape)
    
    # Generate prediction
    #image = image.cuda()
    image = image.numpy()
155/95:
with torch.no_grad():

    image,label = next(iter(training_dataloader))
    image = image[1,:,:,:]
    print(image.shape)
    
    # Generate prediction
    #image = image.cuda()
    image = image.numpy()
155/96:
with torch.no_grad():

    image,label = next(iter(training_dataloader))
#     image = image[1,:,:,:]
    print(image.shape)
#     plt.imshow(image)
    
    # Generate prediction
    #image = image.cuda()
    image = image.numpy()
155/97:
with torch.no_grad():

    image,label = next(iter(training_dataloader))
    image = image[1,0,:,:]
    print(image.shape)
    plt.imshow(image)
    
    # Generate prediction
    #image = image.cuda()
    image = image.numpy()
155/98: image.max()
155/99: image.min()
155/100: label.max
155/101: label.max()
155/102:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[1,0,:,:]

with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)[0]

output.shape
155/103:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[[0],:,:,:]

with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)[0]

output.shape
155/104:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[[0],:,:,:]
image.shape
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)[0]

output.shape
155/105:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[[0],:,:,:]
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)[0]

output.shape
155/106:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[[0],:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)[0]

output.shape
155/107:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[[0],:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)[0]

output.shape
out_prob.shape
155/108:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[[0],:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)[0]

label.shape
155/109:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)[0]
155/110: output.shape
155/111: out.shape
155/112: out_prob.shape
155/113:
print('output shape: '+output.shape)
out_prob.shape
155/114:
print('output shape: '+str(output.shape))
out_prob.shape
155/115:
print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))
155/116:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)
155/117:
print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))
155/118:
print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))
print('label shape: '+str(label.shape))
155/119:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

fig, ax = plt.subplots(3,5)
for i in range(5):
    ax[0,i].imshow(image[i,0])
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,0])
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/120:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

fig, ax = plt.subplots(3,5)
for i in range(5):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,0])
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/121:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

fig, ax = plt.subplots(3,5)
for i in range(5):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,0].cpu())
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/122:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

fig, ax = plt.subplots(3,5, figsize=(17,10))
for i in range(5):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,0].cpu())
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/123:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

fig, ax = plt.subplots(3,5, figsize=(17,10))
for i in range(5):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu())
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/124:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

fig, ax = plt.subplots(4,5, figsize=(17,13))
for i in range(5):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu())
    ax[1,i].set_title('Prediction')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('Pred. Thresh.')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/125:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

fig, ax = plt.subplots(4,5, figsize=(17,13))
for i in range(5):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu())
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[2,i].set_title('Pred. Thresh.')
    ax[3,i].imshow(label[i])
    ax[3,i].set_title('Label')
155/126: out_prob[i,1]+out_prob[i,0]
155/127:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

fig, ax = plt.subplots(4,5, figsize=(17,15))
for i in range(5):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu())
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[2,i].set_title('Pred. Thresh.')
    ax[3,i].imshow(label[i])
    ax[3,i].set_title('Label')
155/128:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

plt.gray()
fig, ax = plt.subplots(4,5, figsize=(17,15))
for i in range(5):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu())
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[2,i].set_title('Pred. Thresh.')
    ax[3,i].imshow(label[i])
    ax[3,i].set_title('Label')
155/129:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(4,numsamples, figsize=(17,15))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Pred. Thresh.')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/130:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(17,15))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Pred. Thresh.')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/131:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(17,-1))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Pred. Thresh.')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/132:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4)
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Pred. Thresh.')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/133:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(20,15))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Pred. Thresh.')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/134:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(500,15))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Pred. Thresh.')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/135:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,35))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Pred. Thresh.')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/136:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,35))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/137:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,40))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/138:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,45))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/139:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.5*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/140:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
155/141:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
155/142:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target) + dice_loss(
                F.softmax(masks_pred, dim=1).float(),
                F.one_hot(true_masks, net.n_classes).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
155/143:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
155/144:
import pathlib

model_name =  'carvana_model_dice.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
155/145:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
155/146:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
155/147:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.5*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/148:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.5*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/149:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.5*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/150:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.5*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/151:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target) + dice_loss(
                F.softmax(masks_pred, dim=1).float(),
                F.one_hot(true_masks, net.n_classes).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
155/152:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
155/153:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target) + dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, net.n_classes).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
155/154:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
155/155:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            loss = self.criterion(out, target) + dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
                loss = self.criterion(out, target)
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
155/156:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
155/157:
import pathlib

model_name =  'carvana_model_dice.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
155/158:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
155/159:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
155/160:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.5*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/161:
# import torch.nn.functional as F
# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.5*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.4)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/162:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=10,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
155/163:
import pathlib

model_name =  'carvana_model_dice_10ep.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
155/164:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
155/165:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
155/166:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.5*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.4)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/167:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.5*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.4)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/168:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.5*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/169:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
155/170:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=2,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
155/171:
import pathlib

model_name =  'carvana_model_dice_2ep.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
155/172:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
155/173:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
155/174:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.5*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/175:
import torch.nn.functional as F
model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.5*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/176:
import torch.nn.functional as F

model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

model_name = 'carvana_model_dice_10ep.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 10
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.5*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/177:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.5*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/178:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.5*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/179:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.5*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/180:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.2*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/181:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.2*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/182:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.2*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/183:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(numsamples, 4, figsize=(15,4.2*numsamples))
for i in range(numsamples):
    ax[i,0].imshow(image[i,0].cpu())
    ax[i,0].set_title('Input')
    ax[i,1].imshow(out_prob[i,1].cpu())
    ax[i,1].set_title('Prediction')
    ax[i,2].imshow(out_prob[i,1].cpu()>0.5)
    ax[i,2].set_title('Prediction Thresholded')
    ax[i,3].imshow(label[i])
    ax[i,3].set_title('Label')
155/184:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(numsamples, 5, figsize=(15,4.2*numsamples))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/185:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(15,4.2*numsamples))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/186:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(15,15))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/187:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(17,10))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/188:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(17,11))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/189:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(17,13))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/190:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(22,11))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/191:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(22,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/192:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(22,13))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/193:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(22,11))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/194:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(22,14))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/195:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(22,11))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/196:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,11))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/197:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('Input')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('Prediction')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('Label')
155/198:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('LABEL')
155/199:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

# model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
# with torch.no_grad():
#     output = model(image)
#     out_prob = F.softmax(output, dim=1)

# print('output shape: '+str(output.shape))
# print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/200:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
155/201:
import pathlib

model_name =  'carvana_model_dice_20ep.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
155/202:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
155/203:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
155/204:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/205:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/206:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/207:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/208:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/209:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/210:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/211:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/212:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/213:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/214:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.ADAM(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
155/215:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
155/216:
import pathlib

model_name =  'carvana_model_dice_20ep_adam.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
155/217:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
155/218:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
155/219:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
# image,label = next(iter(validation_dataloader))
# image = image[:,:,:,:].to(device)
# print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/220:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/221:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/222:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/223:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/224:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/225:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/226:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/227:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/228:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/229:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/230:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/231:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/232:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/233:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/234:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/235:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/236:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/237:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/238:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
155/239:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
156/1: a = np.exp((np.arange(100)-50)**2)
156/2: a = np.exp(-(np.arange(100)-50)**2)
156/3: plt.plot(a)
156/4: a = np.exp(-0.1*(np.arange(100)-50)**2)
156/5: plt.plot(a)
156/6: a = np.exp(-0.01*(np.arange(100)-50)**2)
156/7: plt.plot(a)
156/8: import netCDF4
156/9: pwd
156/10: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-04-14_v04r000.NC'
156/11: l1 = netCDF4.Dataset(file, mode='r')
156/12: from iconfuv.misc import get_br_nights
156/13: get_br_nights?
156/14: brs, brsc,_,_,_,_=get_br_nights(l1)
156/15: len(brs)
156/16: brs[50].shape
156/17: brs[5].shape
156/18: plt.imshow(brs[5][:,10,:], aspect='auto', origin='lower')
156/19: plt.imshow(brs[5][:,10,:].T, aspect='auto', origin='lower')
156/20: plt.colorbar()
156/21: ls
156/22: cd ..
156/23: cd scripts/
156/24: from iconfuv.artifact_removal2 import medfilt3d
156/25: from iconfuv.artifact_removal2 import medfilt3d
156/26: from iconfuv.artifact_removal2 import sliding_min
156/27: from iconfuv.artifact_removal2 import sliding_min
156/28: from iconfuv.artifact_removal2 import sliding_min
156/29: from iconfuv.artifact_removal2 import sliding_min
156/30: from iconfuv.artifact_removal2 import medfilt3d
156/31: br1 = brs[5]
156/32: filt_brfilt = medfilt3d(br, win_size=(6,1,10), full=True)
156/33: filt_brfilt = medfilt3d(br1, win_size=(6,1,10), full=True)
156/34: filt_brfilt = medfilt3d(br1, win_size=(6,1,10), full=True)
156/35: filt,brfilt = medfilt3d(br1, win_size=(6,1,10), full=True)
156/36: np.sum(filt)
156/37: filt.shape
156/38: plt.imshow(filt[3].T, origin='lower', aspect='auto')
156/39: plt.imshow(filt[0].T, origin='lower', aspect='auto')
156/40: plt.figure(); plt.imshow(brfilt[0].T, origin='lower', aspect='auto')
156/41: plt.figure(); plt.imshow(br1[0].T, origin='lower', aspect='auto')
156/42: plt.figure(); plt.plot(br1[0,16,:])
156/43: plt.figure(); plt.plot(br1[:,16,:])
156/44: plt.figure(); plt.plot(br1[:,16,:].T)
156/45: plt.plot(100*filt[0,16,:])
156/46: filt.max()
156/47: np.max(filt)
156/48: filt = filt.astype(np.int())
156/49: filt = filt.astype(np.int)
156/50: np.max(filt)
156/51: plt.figure(); plt.plot(br1[:,16,:].T)
156/52: plt.plot(100*filt[0,16,:])
156/53: np.max(filt[0,16,:])
156/54: np.max(filt[0,15,:])
157/1: from model import load_data
157/2: x,y = load_data()
157/3: x.shape
157/4: y.shape
157/5: plt.imshow(x[10], origin='lower', aspect='auto')
157/6: plt.imshow(x[10], origin='lower', aspect='auto', cmap='jet'); plt.colorbar()
157/7: plt.plot(x[10], np.arange(256), origin='lower')
157/8: plt.plot(x[10,:,:,0], np.arange(256), origin='lower')
157/9: x[10,:,:,0].shape
157/10: plt.plot(x[10,:,:,0], np.arange(256))
157/11: plt.plot(x[10,:,:,0], np.arange(256))
157/12: plt.imshow(x[10], origin='lower', aspect='auto', cmap='jet'); plt.colorbar()
157/13: plt.tight_layout()
157/14: plt.savefig('star2d.png')
157/15: plt.imshow(y[10], origin='lower', aspect='auto', cmap='jet'); plt.colorbar()
157/16: plt.imshow(y[10], origin='lower', aspect='auto', cmap='jet'); plt.colorbar()
157/17: plt.imshow(y[10], origin='lower', aspect='auto', cmap='jet', vmax=x[10].max()); plt.colorbar()
157/18: plt.imshow(y[10], origin='lower', aspect='auto', cmap='jet', vmax=np.max(x[10])); plt.colorbar()
157/19: plt.imshow(y[10], origin='lower', aspect='auto', cmap='jet', vmax=np.nanmax(x[10])); plt.colorbar()
157/20: plt.tight_layout()
157/21: plt.savefig('clean2d.png')
157/22: plt.plot(x[10,:,:,0], np.arange(256))
157/23: plt.savefig('star1d.png')
157/24: plt.plot(y[10,:,:,0], np.arange(256))
157/25: plt.savefig('clean1d.png')
157/26: plt.plot(x[10,:,:,0]-y[10,:,:,0], np.arange(256))
157/27: plt.savefig('staronly1d.png')
158/1: from model import load_data
159/1: from model import load_data
159/2: x,y = load_data()
159/3: x.shape
159/4: cd /home/kamo/resources/icon-fuv/ncfiles/l1/synthetic1/D_LW_new_nS=25_maxA=3e+05_noise=0_smooth=0_v4.30/
159/5: ls
159/6: import glob
159/7: files = glob.glob('*/*[0-1]?.npy')
159/8: files[:100]
159/9: files = files.sort()
159/10: files[:100]
159/11: files = glob.glob('*/*[0-1]?.npy')
159/12: files.sort()
159/13: files[:100]
159/14: ls P0428
160/1: import os
160/2: os.path.join('/home/kamo/','/resources')
160/3: os.path.join('/home/kamo/','resources')
160/4: os.path.join('/home/kamo/','/resours')
160/5: os.path.join('/home/kamo/','resours')
160/6: os.path.join('/home/kamo','resours')
160/7: os.path.join('/home/kamo','resours/')
161/1: from data_loader import BasicDataset
162/1: from data_loader import BasicDataset
162/2: trainset = BasicDataset(data_dir='data/', fold='train')
162/3: trainset = BasicDataset(data_dir='data/', fold='train')
162/4: trainset = BasicDataset(data_dir='data/', fold='train')
162/5: len(trainset)
162/6: amo = os.path.join('data/','train')
162/7: import os
162/8: amo = os.path.join('data/','train')
162/9: amo
162/10: import glob
162/11: glob.glob(amo)
162/12: len(glob.glob(amo+'/*'))
162/13: trainset = BasicDataset(data_dir='data/', fold='train')
162/14: len(trainset)
162/15: trainset = BasicDataset(data_dir='data/', fold='train')
162/16: x,y=next(iter(trainset))
162/17: x,y=next(iter(trainset))
162/18: trainset = BasicDataset(data_dir='./data/', fold='train')
162/19: x,y=next(iter(trainset))
162/20: trainset = BasicDataset(data_dir='/home/kamo/resources/icon-fuv/python3/star_removal/data/', fold='train')
162/21: x,y=next(iter(trainset))
162/22: x,y=next(iter(trainset))
162/23: trainset = BasicDataset(data_dir='/home/kamo/resources/icon-fuv/python3/star_removal/data/', fold='train')
162/24: x,y=next(iter(trainset))
162/25: ipdb.pm()
162/26: trainset = BasicDataset(data_dir='/home/kamo/resources/icon-fuv/python3/star_removal/data/', fold='train')
162/27: x,y=next(iter(trainset))
162/28: x.shape
162/29: y.shape
162/30: plt.imshow(x)
162/31: plt.imshow(x, aspect='auto', origin='lower')
162/32: plt.imshow(y, aspect='auto', origin='lower')
162/33: plt.plot(x, np.arange(256))
162/34: plt.plot(y, np.arange(256))
162/35: import torch
162/36: trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)
162/37: len(trainloader)
162/38: x,y=next(iter(trainloader))
162/39: x.shape
162/40: y.shape
162/41: type(x)
162/42: x.size()
162/43: trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)
162/44: x,y=next(iter(trainloader))
162/45: x.size()
163/1: import torch
163/2: from data_loader import BasicDataset
163/3: trainset = BasicDataset(data_dir='/home/kamo/resources/icon-fuv/python3/star_removal/data/', fold='train')
163/4: trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)
163/5: x,y=next(iter(trainloader))
163/6: x,y=next(iter(trainloader))
163/7: len(trainset)
163/8: trainloader = torch.utils.data.DataLoader(trainset, batch_size=49600, shuffle=True)
163/9: x,y=next(iter(trainloader))
163/10: trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)
163/11: x,y=next(iter(trainloader))
163/12: x.shape
164/1: import torch
164/2: from data_loader import BasicDataset
164/3: trainset = BasicDataset(data_dir='/home/kamo/resources/icon-fuv/python3/star_removal/data/', fold='train')
164/4: trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)
164/5: trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)
164/6: x,y=next(iter(trainloader))
164/7: trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=8)
164/8: x,y=next(iter(trainloader))
166/1: import torch
166/2: from unet import UNet
166/3: from unet import UNet
166/4: x = torch.rand((256,6))
166/5: x = torch.rand((1,1,256,6))
166/6: y = UNet(x)
166/7: y = UNet(x, 1,1,16)
166/8: y = UNet(x, 1,1,16)
166/9: x = torch.rand((1,256,6))
166/10: y = UNet(x, 1,1,16)
166/11: x = torch.rand((1,1,256,6))
166/12: ipdb.pm()
166/13: x = torch.rand((1,1,256,6))
166/14: net = UNet(1,1,16)
166/15: from unet import UNet
166/16: net = UNet(1,1,16)
166/17: net = UNet(1,1,16)
166/18: y = net(x)
167/1: from unet import UNet
167/2: from unet import UNet
167/3: import torch
167/4: x = torch.rand((1,1,256,6))
167/5: net = UNet(1,1,16)
167/6: y = net(x)
167/7: print(net)
167/8: from data_loader import BasicDataset
167/9: trainset = BasicDataset(data_dir='/home/kamo/resources/icon-fuv/python3/star_removal/data/', fold='train')
167/10: trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=8)
167/11: x,y=next(iter(trainloader))
167/12: x.shape
167/13: l=torch.nn.MSELoss(x,y)
167/14: x.shape
167/15: y.shape
167/16: l=torch.nn.MSELoss(x[4],y[4])
167/17: l=torch.nn.MSELoss(x[0,0],y[0,0])
167/18: criter=torch.nn.MSELoss()
167/19: l=criter(x[0,0],y[0,0])
167/20: l=criter(x,y)
167/21: l.shape
167/22: l
167/23: x=x.numpy(); y=y.numpy()
167/24: x.shape
167/25: np.sum(np.isnan(x))
167/26: np.sum(np.isnan(x[0]))
167/27: plt.imshow(x[0,0], origin='lower', aspect='auto')
167/28: plt.imshow(y[0,0], origin='lower', aspect='auto')
167/29: trainloader = torch.utils.data.DataLoader(trainset, batch_size=1000, shuffle=True, num_workers=8)
167/30: x,y=next(iter(trainloader))
167/31: trainloader = torch.utils.data.DataLoader(trainset, batch_size=200, shuffle=True)
167/32: trainloader = torch.utils.data.DataLoader(trainset, batch_size=200, shuffle=True)
167/33: x,y=next(iter(trainloader))
167/34: np.sum(np.isnan(x[0]))
167/35: x=x.numpy(); y=y.numpy()
167/36: np.sum(np.isnan(x[0]))
167/37: np.sum(np.isnan(x))
167/38: np.sum(np.isnan(y))
167/39: trainloader = torch.utils.data.DataLoader(trainset, batch_size=20, shuffle=True)
167/40: trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)
167/41: trainset = BasicDataset(data_dir='/home/kamo/resources/icon-fuv/python3/star_removal/data/', fold='train')
167/42: trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)
167/43: x,y=next(iter(trainloader))
167/44: x,y=next(iter(trainloader))
167/45: x,y=next(iter(trainloader))
167/46: x=x.numpy(); y=y.numpy()
167/47: np.sum(np.isnan(y))
167/48: np.sum(np.isnan(x))
167/49: l=criter(x,y)
167/50: x.shape
167/51: x,y=next(iter(trainloader))
167/52: x.shape
167/53: l=criter(x,y)
167/54: l
167/55: trainloader.batch_size
168/1: %run train.py
168/2: %run train.py
168/3: from unet import UNet
168/4: net = Unet(1,1,16)
168/5: net = UNet(1,1,16)
168/6: import torch
168/7: x = torch.rand(1,1,256,6)
168/8: y=net(x)
168/9: y.shape
168/10: x.shape
168/11: %run train.py
168/12:
t = torch.cuda.get_device_properties(0).total_memory
r = torch.cuda.memory_reserved(0)
a = torch.cuda.memory_allocated(0)
f = r-a  # free inside reserved
168/13: t
168/14: r
168/15: a
168/16: torch.cuda.is_available()
169/1: %run train.py
169/2: %run train.py
169/3: %run train.py
169/4: %run train.py
169/5: len(trainset)
169/6: x,y=next(iter(valloader))
169/7: net.eval()
169/8: out = net(x)
169/9: x.to(device=device, dtype=torch.float)
169/10: y=y.to(device=device, dtype=torch.float)
169/11: out = net(x)
169/12: device
169/13: x=x.to(device=device, dtype=torch.float)
169/14: out = net(x)
169/15: out.shape
169/16: plt.imshow(x[0,0], origin='lower', aspect='auto')
169/17: plt.imshow(x[0,0].numpy(), origin='lower', aspect='auto')
169/18: plt.imshow(x[0,0].cpu(), origin='lower', aspect='auto')
169/19: plt.imshow(y[0,0].cpu(), origin='lower', aspect='auto')
169/20: plt.imshow(out[0,0].cpu(), origin='lower', aspect='auto')
169/21: plt.imshow(out[0,0].cpu().numpy(), origin='lower', aspect='auto')
169/22: x,y=next(iter(valloader))
169/23:
x, y = next(iter(valloader))
x = x.to(device=device, dtype=torch.float)
y = y.to(device=device, dtype=torch.float)
with torch.no_grad():
    out = net(x)

i = 1
fig, ax = plt.subplots(1,3)
ax[0].imshow(x[i,0].cpu(), aspect='auto', origin='lower')
ax[0].set_title('Starry')
ax[1].imshow(y[i,0].cpu(), aspect='auto', origin='lower')
ax[1].set_title('Gold Standard')
ax[2].imshow(out[i,0].cpu(), aspect='auto', origin='lower')
ax[2].set_title('Predicted')
169/24: plt.plot(x[i,0].cpu().T)
169/25: plt.plot(x[i,0].cpu())
169/26: from test import plot_profiles
169/27: from evaluate import plot_profiles
169/28: plot_profiles(net, valloader, np.random.randint(32))
169/29: device
169/30: x,y=next(iter(valloader))
169/31: type(x)
169/32:
with torch.no_grad():
    out=net(x)
169/33: np.random.randint(32)
169/34: np.random.randint(32)
169/35: np.random.randint(32)
169/36: valloader.batch_size
169/37: plot_profiles(net, valloader, valloader.batch_size)
169/38: plot_profiles(net, valloader, valloader.batch_size)
169/39: plot_profiles(net, valloader, valloader.batch_size)
169/40: plot_profiles(net, valloader, np.random.randint(valloader.batch_size))
169/41: plot_profiles(net, valloader, np.random.randint(valloader.batch_size))
169/42: plot_profiles(net, valloader, np.random.randint(valloader.batch_size))
169/43: plot_profiles(net, valloader, np.random.randint(valloader.batch_size))
169/44: %run train.py
169/45: %run train.py
171/1: %run train.py
171/2: %run train.py
171/3: %run train.py
173/1: from iconfuv.misc import get_br_nights
173/2: import netCDF4
173/3: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-04-14_v04r000.NC'
173/4: l1 = netCDF4.Dataset(file, mode='r')
173/5: brs, brsc,_,_,_,_=get_br_nights(l1)
173/6: plt.imshow(brs[5][:,10,:].T, aspect='auto', origin='lower')
173/7: plt.imshow(brs[5][3,:,:].T, aspect='auto', origin='lower')
173/8: brs, brsc,_,_,_,_=get_br_nights(l1, target_mode='day')
173/9: brs, brsc,_,_,_,_=get_br_nights(l1, t='day')
173/10: brs, brsc,_,_,_,_=get_br_nights(l1, target_mode='day')
173/11: from iconfuv.misc import get_br_nights
173/12: brs, brsc,_,_,_,_=get_br_nights(l1, target_mode='day')
173/13: brs, brsc,_,_,_,_=get_br_nights(l1, target_mode='day')
173/14: brs, brsc,_,_,_,_=get_br_nights(l1, target_mode='day')
173/15: from iconfuv.misc import get_br_nights
173/16: brs, brsc,_,_,_,_=get_br_nights(l1, target_mode='day')
173/17: brs, brsc,_,_,_,_=get_br_nights(l1, target_mode='day')
173/18: brs, brsc,_,_,_,_=get_br_nights(l1, target_mode='day')
173/19: brs, brsc,_,_,_,_=get_br_nights(l1, target_mode='day')
173/20: from iconfuv.misc import get_br_nights
173/21: brs, brsc,_,_,_,_=get_br_nights(l1, target_mode='day')
173/22: brs, brsc,_,_,_,_=get_br_nights(l1, target_mode='day')
174/1: import netCDF4
174/2: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-04-14_v04r000.NC'
174/3: l1 = netCDF4.Dataset(file, mode='r')
174/4: from iconfuv.misc import get_br_nights
175/1: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-04-14_v04r000.NC'
175/2: import netCDF4
175/3: l1 = netCDF4.Dataset(file, mode='r')
175/4: brs, brsc,_,_,_,_=get_br_nights(l1, target_mode='day')
175/5: from iconfuv.misc import get_br_nights
175/6: brs, brsc,_,_,_,_=get_br_nights(l1, target_mode='day')
175/7: len(brs)
175/8: plt.imshow(brs[5][3,:,:].T, aspect='auto', origin='lower')
175/9: ^plt.imshow(brs[i][3,:,:].T, aspect='auto', origin='lower')
175/10:
for i in range(len(brs)):
    plt.imshow(brs[i][3,:,:].T, aspect='auto', origin='lower')
    plt.title(i)
    plt.savefig(f'{i}.png')
175/11:
for i in range(len(brs)):
    print(f'{i}.png')
175/12:
for i in range(len(brs)):
    print('{i}.png')
176/1: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-04-14_v04r000.NC'
176/2: import netCDF4
176/3: from iconfuv.misc import get_br_nights
176/4: l1 = netCDF4.Dataset(file, mode='r')
176/5: brs, brsc,_,_,_,_=get_br_nights(l1, target_mode='day')
176/6: fig, ax = plt.subplots(2,1)
176/7:
ax[0].imshow(brs[3][3].T, aspect='auto', origin='lower', cmap='jet')
ax[1].imshow(brs[3][3].T, aspect='auto', origin='lower', cmap='jet', vmax=1e3)
176/8: fig, ax = plt.subplots(2,1, figsize=[6.4,8.4])
176/9:
ax[0].imshow(brs[3][3].T, aspect='auto', origin='lower', cmap='jet')
ax[1].imshow(brs[3][3].T, aspect='auto', origin='lower', cmap='jet', vmax=1e3)
176/10: plt.tight_layout()
177/1: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2020-03-15_v03r003.NC'
177/2: l1 = netCDF4.Dataset(file, mode='r')
177/3: import netCDF4
177/4: l1 = netCDF4.Dataset(file, mode='r')
177/5: l1s = l1
177/6: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/dset1/ICON_L1_FUV_LWP_2020-03-15_v03r003.NC'
177/7: l1l = netCDF4.Dataset(file, mode='r')
177/8: brss, brsc,_,_,_,_=get_br_nights(l1s, target_mode='day')
177/9: from iconfuv.misc import get_br_nights
177/10: brss, brsc,_,_,_,_=get_br_nights(l1s, target_mode='day')
177/11: brsl, brsc,_,_,_,_=get_br_nights(l1l, target_mode='day')
177/12: brsl, brsc,_,_,_,_=get_br_nights(l1l, target_mode='day')
177/13: plt.imshow(brss[5][3,:,:].T, aspect='auto', origin='lower')
177/14: plt.figure(); plt.imshow(brsl[5][3,:,:].T, aspect='auto', origin='lower')
177/15: len(brss)
177/16: len(brsl)
177/17: len(brsl[0])
177/18: brsl[0].shape
177/19: sum([i.shape[1] for i in brss])
177/20: plt.imshow(brss[0][3,:,:].T, aspect='auto', origin='lower')
177/21: plt.imshow(brss[1][3,:,:].T, aspect='auto', origin='lower')
177/22: plt.imshow(brss[0][3,:,:].T, aspect='auto', origin='lower')
177/23: plt.imshow(brss[1][3,:,:].T, aspect='auto', origin='lower')
177/24: plt.figure(); plt.imshow(brsl[0][3,25:335,:].T, aspect='auto', origin='lower')
177/25: l1l.variables.keys()
177/26: print(list(l1l.variables.keys()))
177/27: [print(i) for i in list(l1l.variables.keys())]
177/28: l1l.variables['ICON_L1_FUV_Mode'][:].shape
177/29: l1l.variables['ICON_L1_FUVB_LWP_Chain_ID']
177/30: l1l.variables['ICON_L1_FUVB_LWP_Chain_ID'][:20]
177/31: l1l.variables['ICON_L1_FUVB_LWP_Chain_ID'][500:520]
177/32: import parser
177/33: amo = parser.parse(l1l.variables['ICON_L1_FUVB_LWP_Center_Times'][:][0])
177/34: from dateutil import parser
177/35: amo = parser.parse(l1l.variables['ICON_L1_FUVB_LWP_Center_Times'][:][0])
177/36: amo
177/37: amo1 = parser.parse(l1l.variables['ICON_L1_FUVB_LWP_Center_Times'][:][1])
177/38: amo1-amo2
177/39: amo1-amo
177/40: amo1-amo>12
177/41: import datetime
177/42: amo1-amo>datetime.timedelta(11)
177/43: amo1-amo>datetime.timedelta(13)
177/44: amo1-amo>datetime.timedelta(seconds=11)
177/45: amo1-amo>datetime.timedelta(seconds=12)
177/46: amo1-amo>datetime.timedelta(seconds=13)
177/47: amo1-amo>datetime.timedelta(minutes=1)
177/48: amo1-amo<datetime.timedelta(minutes=1)
177/49: amo = parser.parse(l1l.variables['ICON_L1_FUVB_LWP_Center_Times'][:])
177/50: amo = np.array([parser.parse(i) for i in l1l.variables['ICON_L1_FUVB_LWP_Center_Times'][:]])
177/51: amo[1]
177/52: l1l.variables['ICON_L1_FUVB_LWP_GAIN_DAY'][1]
177/53: l1l.variables['ICON_L1_FUVB_LWP_GAIN_DAY'][:].shape
177/54: l1l.variables['ICON_L1_FUVB_LWP_GAIN_DAY'][:]
178/1: import netCDF4
178/2: from iconfuv.misc import get_br_nights
178/3: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/dset1/ICON_L1_FUV_LWP_2020-03-15_v03r003.NC'
178/4: l1 = netCDF4.Dataset(file, mode='r')
178/5: brs, brsc,_,_,_,_=get_br_nights(l1, target_mode='day')
178/6: len(brs)
178/7: plt.imshow(brss[0][3,:,:].T, aspect='auto', origin='lower')
178/8: plt.imshow(brs[0][3,:,:].T, aspect='auto', origin='lower')
178/9: plt.imshow(brs[0][3,:,:].T, aspect='auto', origin='lower', vmax=500)
178/10: plt.imshow(brs[0][3,:,:].T**0.2, aspect='auto', origin='lower')
178/11: plt.imshow(np.log(brs[0][3,:,:].T+1e2), aspect='auto', origin='lower')
178/12: plt.figure(); plt.imshow(brs[0][3,:,:].T, aspect='auto', origin='lower', vmax=500)
178/13: brs[0][3].max()
178/14: brs[0][3].min()
178/15: plt.imshow(np.log(brs[0][3,:,:].T+1e2), aspect='auto', origin='lower')
178/16: plt.imshow(np.log(brs[0][3,:,:].T+1e3), aspect='auto', origin='lower')
178/17: plt.imshow(np.log(brs[0][3,:,:].T+1e3), aspect='auto', origin='lower')
178/18: plt.imshow(np.log(brs[0][3,:,:].T+1e4), aspect='auto', origin='lower')
178/19: plt.imshow(np.log(brs[0][3,:,:].T+33), aspect='auto', origin='lower')
178/20: plt.imshow(np.log(brs[0][3,:,:].T+1e2), aspect='auto', origin='lower')
178/21: plt.imshow(np.log(brs[0][3,:,:].T+33), aspect='auto', origin='lower')
178/22: plt.imshow(np.log(brs[0][3,:,:].T), aspect='auto', origin='lower')
178/23: plt.imshow(np.log(brs[0][3,:,:].T+10), aspect='auto', origin='lower')
178/24: plt.imshow(np.log(brs[0][3,:,:].T+200), aspect='auto', origin='lower')
178/25: plt.imshow(np.log(brs[0][3,:len(brs[0][3])//4,:].T+200), aspect='auto', origin='lower')
178/26: plt.imshow(np.log10(brs[0][3,:len(brs[0][3])//4,:].T+200), aspect='auto', origin='lower')
178/27: plt.colorbar()
178/28: plt.imshow(np.log10(brs[0][3,:len(brs[0][3])//4,:].T+200), aspect='auto', origin='lower')
178/29: plt.imshow(brs[0][3,:len(brs[0][3])//4,:].T, aspect='auto', origin='lower')
178/30: np.linspace(0,100,4)
178/31: np.linspace(0,100,4, endpoint=False)
178/32: np.linspace(0,100,5)
178/33:         fig, ax = plt.subplots(1,figsize=[6.4,8.4])
178/34: np.arange(5,15)
178/35: import os
178/36: path_dir = '/home/kamo/resources/icon-fuv/ncfiles/l1/'
178/37: os.path.join(path_dir+'dset1')
178/38: os.path.join(path_dir+'/dset1')
178/39: os.path.join(path_dir+'dset1/')
178/40: os.path.join(path_dir,'dset1')
178/41: os.path.join(path_dir,'/dset1')
178/42: os.path.join(path_dir,'dset1')
178/43: os.path.join(path_dir,'dset1','amo')
178/44: os.path.join(path_dir,'dset1/','amo')
178/45: %run profile_extractor.py
178/46: %run profile_extractor.py
178/47: %run profile_extractor.py
178/48: np.arange(5,15, type=np.int)
178/49: np.arange(5,15, type=np.int)
178/50: %run profile_extractor.py
178/51: %run profile_extractor.py
178/52: %run profile_extractor.py
178/53: %run profile_extractor.py
178/54: %run profile_extractor.py
178/55: %run profile_extractor.py
178/56: %run profile_extractor.py
178/57: %run profile_extractor.py
178/58: %run profile_extractor.py
178/59: %run profile_extractor.py
178/60: %run profile_extractor.py
178/61: cd star_network_training/
178/62: ls
178/63: cd ../../star_removal/
178/64: a=1e-3
178/65: print(a)
178/66: %run train.py
178/67: torch
178/68: device
178/69: torch.cuda.is_available()
178/70: %run train.py
178/71: from evaluate import plot_profiles
178/72: plot_profiles(net, valloader, np.random.randint(31))
178/73: import cProfile
178/74: cProfile.run('train.py')
178/75: cProfile.run(train.py)
178/76: %prun train.py
178/77: ls
178/78: cProfile train.py
178/79: import train
178/80: %prun train.main()
178/81: %prun trai
178/82: %prun train
178/83: %prun train.py
178/84: %prun train.__main__
178/85: %prun train.__main__()
178/86: %prun train.main()
178/87: import train
178/88: %prun train.main()
178/89: %prun -s "cumulative" train.main()
178/90: %prun -s cumulative train.main()
178/91: a=np.ones((4,9,9))
178/92: a=np.ones((23,34))
178/93: b=np.ones((23,34))
178/94: c=np.stack(a,b)
178/95: c=np.stack(a,b, axis=0)
178/96: c=np.stack((a,b), axis=0)
178/97: c.shape
178/98: c=np.stack((a,b))
178/99: c.shape
178/100: glob
178/101: ls
178/102: files = glob.glob('data/train/*')
178/103: file = files[4]
178/104: file
178/105: file.split('/')
178/106: from data_loader import data_rewriter_par
178/107: data_rewriter_par()
178/108: data_rewriter_par()
178/109: amo = np.load('data/train2/L1_000_000.npy')
178/110: amo.shape
178/111: x,y = np.load('data/train2/L1_000_000.npy')
178/112: x.shape
178/113: %prun -s cumulative -D run.prof train.main()
178/114: import train
178/115: %prun -s cumulative -D run.prof train.main()
178/116: pool
178/117: %prun -s cumulative train.main()
178/118: %prun -s cumulative train.main()
178/119: %prun -s cumulative train.main()
178/120: %prun -s cumulative train.main()
178/121: %prun -s cumulative train.main()
180/1: import train
180/2: %prun -s cumulative train.main()
180/3: trainset
180/4: %run train.py
180/5: trainloader
180/6: trainloader
180/7: %run train.py
180/8: a=next(iter(trainloader))
180/9: len(a)
180/10: x,y=next(iter(trainloader))
180/11: x.shape
180/12: plt.imshow(x[0,0].cpu())
180/13: plt.imshow(y[0,0].cpu())
180/14: x=x.cpu().to_numpy()
180/15: x=x.cpu().numpy()
180/16: y=y.cpu().numpy()
180/17: np.sum(np.isnan(x))
180/18: x,y=next(iter(trainloader))
180/19: x,y=next(iter(trainloader))
180/20: x=x.cpu().numpy()
180/21: np.sum(np.isnan(x))
180/22: np.allclose(x,y)
180/23: %prun -s cumulative train.main()
180/24: %prun -s cumulative train.main()
180/25: from data_loader import data_rewriter_par
180/26: ls
180/27: data_rewriter_par()
180/28: data_rewriter_par()
180/29: x,y = np.load('data/train2/L1_000_000.npy')[[],:,:]
180/30: x,y = np.load('data/train2/L1_000_000.npy')[[:],:,:]
180/31: x = np.load('data/train2/L1_000_000.npy')[[0],:,:]
180/32: x.shape
180/33: x,y = np.load('data/train2/L1_000_000.npy')[[0,1],:,:]
180/34: x.shape
180/35: x,y = np.load('data/train2/L1_000_000.npy')[np.newaxis]
180/36: %prun -s cumulative train.main()
180/37: %prun -s cumulative train.main()
180/38: %prun -s cumulative train.main()
180/39: %prun -s cumulative train.main()
180/40: %prun -s cumulative train.main()
180/41: %prun -s cumulative train.main()
180/42: %prun -s cumulative train.main()
180/43: %run train.py
180/44: %run train.py
180/45: ipdb.pm()
180/46: %prun -s cumulative train.main()
180/47: %prun -s cumulative train.main()
180/48: %prun -s cumulative train.main()
180/49: %prun -s cumulative train.main()
180/50: %load_ext line_profiler
180/51: %lprun -s cumulative train.main()
180/52: %lprun train.main()
180/53: %lprun -T lprof0 -f train.main()
180/54: print(open('lprof0', 'r').read())
180/55:     trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=4)
180/56: x,y=next(iter(trainloader))
180/57: x,y=next(iter(trainloader))
180/58: trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=32)
180/59: x,y=next(iter(trainloader))
180/60: trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=1)
180/61: x,y=next(iter(trainloader))
180/62: trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=8)
180/63: x,y=next(iter(trainloader))
180/64: trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=1)
180/65: x,y=next(iter(trainloader))
180/66: x,y=next(iter(trainloader))
180/67: x,y=next(iter(trainloader))
180/68:
%%writefile amo.py
import time
t0 = time.time()
for i,data in enumerate(trainloader):
    x,y = data
    if i==20:
        break
print('Elapsed Time: {}'.format(time.time()-t0))
180/69: %run amo.py
180/70: %run amo.py
180/71: %run amo.py
180/72: %run amo.py
180/73: %run amo.py
180/74: len(trainloader)
180/75: %run amo.py
180/76: %run amo.py
180/77: %run amo.py
180/78: %run amo.py
180/79: %run amo.py
180/80: %run amo.py
180/81: %run amo.py
180/82: %run amo.py
180/83: %run amo.py
180/84: %run amo.py
180/85: %run amo.py
180/86: %run amo.py
180/87: %run amo.py
180/88: %run amo.py
180/89: %run amo.py
180/90: %run amo.py
180/91: %run amo.py
180/92: %run amo.py
180/93: %run amo.py
180/94: %run amo.py
180/95: %run amo.py
180/96: %run amo.py
180/97: %run amo.py
180/98: %run train.py
180/99: %run train.py
180/100: %run train.py
180/101: %run train.py
180/102: plot_profiles(net, valloader, np.random.randint(31))
180/103: from evaluate import plot_profiles
180/104: plot_profiles(net, valloader, np.random.randint(31))
181/1: %run train.py
181/2: %run train.py
181/3: import tqdm
181/4: %run train.py
181/5: plt.plot(trainloss)
181/6: plt.show()
181/7: plt.plot(trainloss)
181/8: plt.plot(valloss)
181/9: plt.plot(trainloss)
181/10: plt.plot(valloss)
181/11: from evaluate import plot_profiles
181/12: plot_profiles(net, valloader, np.random.randint(31))
181/13: %run train.py
181/14: %run train.py
181/15: plot_profiles(net, valloader, np.random.randint(31))
181/16: plot_profiles(net, valloader, np.random.randint(31))
181/17: plt.plot(trainloss)
181/18: plt.plot(trainloss)
181/19: plot_profiles(net, valloader, np.random.randint(31))
181/20: plt.plot(valloss)
181/21: from datetime import datetime
181/22: now = datetime.now()
181/23: print(now)
181/24: print(now)
181/25: print(now)
181/26: now.strftime('%d/%m/%Y %H:%M:%S')
181/27: now.strftime('%Y_%m_%d_%H_%M_%S')
181/28: now.strftime('%Y_%m_%d__%H_%M_%S')
181/29: %run train.py
181/30: %run train.py
181/31: %run train.py
181/32: plot_profiles(net, valloader, np.random.randint(31))
181/33: %run train.py
181/34: plot_profiles(net, valloader, np.random.randint(31))
181/35: %run train.py
181/36: %run train.py
181/37: %run train.py
181/38: %run train.py
181/39: %run train.py
181/40: %run train.py
181/41: %run train.py
181/42: %run train.py
181/43: %run train.py
181/44: %run train.py
182/1: %run train.py
182/2: %run train.py
182/3: %run train.py
182/4: %run train.py
182/5: %run train.py
182/6: %run train.py
182/7: %run train.py
182/8: logger.handlers
182/9: logger.filters
182/10: list(map(logger.removeHandler, logger.handlers))
182/11: logger.handlers
182/12: logger.handlers = []
182/13: logger.handlers
182/14:     logger.addHandler(logging.FileHandler(f'saved/{name}/output.log'))
182/15: logger.handlers
182/16: %run train.py
182/17: %run train.py
182/18:     formatter = logging.Formatter('%Y-%m-%d %H:%M:%S')
182/19:     formatter = logging.Formatter('%(asctime)s','%Y-%m-%d %H:%M:%S')
182/20: %run train.py
182/21: %run train.py
182/22: %run train.py
182/23: %run train.py
182/24: %run train.py
182/25: a=True
182/26: f'{a}'
182/27: trainloss
182/28:
plt.figure()
plt.plot(trainloss, label='Training Loss')
plt.plot(valloss, label='Validation Loss')
plt.title('Convergence Plot')
plt.grid(which='both', axis='both')
plt.savefig(f'saved/{name}/convergence_plot.png')
plt.legend()
182/29:
plt.figure()
plt.plot(trainloss, label='Training Loss')
plt.plot(valloss, label='Validation Loss')
plt.title('Convergence Plot')
plt.grid(which='both', axis='both')
plt.savefig(f'saved/{name}/convergence_plot.png')
plt.legend()
182/30:
plt.figure()
plt.plot(trainloss, label='Training Loss')
plt.plot(valloss, label='Validation Loss')
plt.title('Convergence Plot')
plt.grid(which='both', axis='both')
plt.savefig(f'saved/{name}/convergence_plot.png')
plt.legend()
182/31:
plt.figure()
plt.plot(trainloss, label='Training Loss')
plt.plot(valloss, label='Validation Loss')
plt.title('Convergence Plot - Val_min_last={%.2f}, {%.2f}'.format(valloss.min(),valloss[-1]))
plt.grid(which='both', axis='both')
plt.savefig(f'saved/{name}/convergence_plot.png')
plt.legend()
182/32:
plt.figure()
plt.plot(trainloss, label='Training Loss')
plt.plot(valloss, label='Validation Loss')
plt.title('Convergence Plot - Val_min_last={%.2f}, {%.2f}'.format(np.min(valloss),valloss[-1]))
plt.grid(which='both', axis='both')
plt.savefig(f'saved/{name}/convergence_plot.png')
plt.legend()
182/33:
plt.figure()
plt.plot(trainloss, label='Training Loss')
plt.plot(valloss, label='Validation Loss')
plt.title('Convergence Plot - Val_min_last={:.2f}, {:.2f}'.format(np.min(valloss),valloss[-1]))
plt.grid(which='both', axis='both')
plt.savefig(f'saved/{name}/convergence_plot.png')
plt.legend()
182/34:
plt.figure()
plt.plot(trainloss, label='Training Loss')
plt.plot(valloss, label='Validation Loss')
plt.title('Convergence Plot - Val (min,last)=({:.2f}, {:.2f})'.format(np.min(valloss),valloss[-1]))
plt.grid(which='both', axis='both')
plt.savefig(f'saved/{name}/convergence_plot.png')
plt.legend()
182/35:
plt.figure()
plt.plot(trainloss, label='Training Loss')
plt.plot(valloss, label='Validation Loss')
plt.title('Convergence Plot - Val (min,last)=({:.2f}, {:.2f})'.format(np.min(valloss),valloss[-1]))
plt.grid(which='both', axis='both')
plt.savefig(f'saved/{name}/convergence_plot.png')
plt.legend()
182/36:
plt.figure()
plt.plot(trainloss, label='Training Loss')
plt.plot(valloss, label='Validation Loss')
plt.title('Convergence Plot - Val (min,last)=({:.2f}, {:.2f})'.format(np.min(valloss),valloss[-1]))
plt.grid(which='both', axis='both')
plt.savefig(f'saved/{name}/convergence_plot.png')
plt.legend()
182/37: name
182/38:
a='asdddddddddddddddddddddddsaaaaaaaaaaaaaaaaaaaaaaaaa \
adsasd'
182/39: a
182/40: len(trainset)
182/41: %run train.py
182/42: %run train.py
182/43: %run train.py
182/44: import time
182/45: t0 = time.time()
182/46: time.time()-t0
182/47: import datetime
182/48: datetime.timedelta(secs=456)
182/49: datetime.timedelta(sec=456)
182/50: from datetime import datetime
182/51: datetime.timedelta(sec=456)
182/52: datetime.timedelta(secs=456)
182/53: import datatime
182/54: import datetime
182/55: datetime.timedelta(seconds=456)
182/56: str(datetime.timedelta(seconds=456))
182/57: import datetime
182/58: datetime.datetime.now()
182/59: str(datetime.timedelta(seconds=456.123123))
182/60: %run train.py
182/61: %run train.py
182/62: %run train.py
182/63: %run train.py
182/64: plt.plot(valloss)
182/65: plt.show()
182/66: plt.plot(valloss)
182/67: plt.plot(np.log10(valloss))
182/68: plt.plot(np.log10(trainloss))
182/69: plt.semilogy(trainloss)
182/70: plt.semilogy(valloss)
182/71: %run train.py
183/1: import torch
183/2:     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
183/3: from unet import UNet
183/4:
    net = UNet(in_channels=1,
                 out_channels=1,
                 start_filters=NUM_FILT,
                 bilinear=BILINEAR,
                 residual=RESIDUAL).to(device)
183/5:
    NUM_FILT = 32
    LR = 1e-3
    EPOCHS = 30
    RESIDUAL = True
    BATCH_SIZE = 64
    BILINEAR = True
    OPTIMIZER = 'ADAM'
    LOSS = 'MSE'
183/6:
    net = UNet(in_channels=1,
                 out_channels=1,
                 start_filters=NUM_FILT,
                 bilinear=BILINEAR,
                 residual=RESIDUAL).to(device)
183/7: net.load_state_dict(torch.load('saved/nf_32_LR_0.001_EP_15.pth'))
183/8: net.eval()
183/9: a=1_000
183/10: a
183/11: =3
183/12: a=3
183/13: b=a
183/14: a=5
183/15: b
183/16:     valset = BasicDataset(data_dir = './data/', fold='val')
183/17: from data_loader import BasicDataset
183/18:     valset = BasicDataset(data_dir = './data/', fold='val')
183/19:     valloader = DataLoader(valset, batch_size=32, shuffle=False)
183/20: from torch.utils.data import DataLoader
183/21:     valloader = DataLoader(valset, batch_size=32, shuffle=False)
183/22: criterion = torch.nn.MSELoss()
183/23: from evaluate import calculate_valloss
183/24: loss = calculate_valloss(net, valloader, criterion)
183/25: loss = calculate_valloss(net, valloader, criterion)
183/26: loss = calculate_valloss(net, valloader, criterion)
183/27: %run train.py
183/28: from evaluate import plot_profiles
183/29: plot_profiles(net, valloader, np.random.randint(31))
183/30:     valloader = DataLoader(valset, batch_size=32, shuffle=True)
183/31: plot_profiles(net, valloader, np.random.randint(31))
183/32: plot_profiles(net, valloader, np.random.randint(31))
183/33: plot_profiles(net, valloader, np.random.randint(31))
183/34: plot_profiles(net, valloader, np.random.randint(31))
183/35: plot_profiles(net, valloader, np.random.randint(31))
183/36: plot_profiles(net, valloader, np.random.randint(31))
183/37: plot_profiles(net, valloader, np.random.randint(31))
183/38: plot_profiles(net, valloader, np.random.randint(31))
183/39: plot_profiles(net, valloader, np.random.randint(31))
185/1: import golb
185/2: import glob
185/3: f=glob.glob('*/bin')+glob.glob('*/*.bin')
185/4: f
185/5: f=glob.glob('*.bin')+glob.glob('*/*.bin')
185/6: f
185/7: f.sort()
185/8: f
185/9: import fnmatch
185/10: fnmatch.filter(f,'old')
185/11: fnmatch.filter(f,'*old*')
185/12: a=np.zeros((1,3,4))
185/13: len(a)
185/14: a.transpose(1,2,0).shape
185/15: import torch
185/16: ls
185/17: rm amo.bin
185/18: cd ..
185/19: cd ..
185/20: cd star_removal/
185/21: %run evaluate.py
185/22: %run evaluate.py
185/23: %run evaluate.py
185/24: %run evaluate.py
185/25: %run evaluate.py
185/26: pwd
185/27: cd saved/2021_12_06__23_02_02_NF_32_LR_0.0005_EP_3/
185/28: %run evaluate.py
185/29: cd -
185/30: %run evaluate.py
185/31: model_torch
185/32: %run evaluate.py
185/33: %run evaluate.py
185/34: %run evaluate.py
185/35: %run evaluate.py
185/36: ipdb.pm()
185/37: %run evaluate.py
185/38: ipdb.pm()
185/39: %run evaluate.py
185/40: %run evaluate.py
185/41: ipdb.pm()
185/42: %run evaluate.py
185/43: %run evaluate.py
185/44: %run evaluate.py
185/45: l1.close()
185/46: %run evaluate.py
185/47: a
185/48: max(a,1)
185/49: np.max(a,1)
185/50: %run evaluate.py
185/51: %run evaluate.py
186/1: %run evaluate.py
186/2: %run evaluate.py
189/1:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = 'data/celeba'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5),
            (0.5, 0.5, 0.5))])

    # Create the dataset.
    dataset = dset.ImageFolder(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
189/2:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training/scans'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5),
            (0.5, 0.5, 0.5))])

    # Create the dataset.
    dataset = dset.ImageFolder(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
189/3:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training/scans'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5),
            (0.5, 0.5, 0.5))])

    # Create the dataset.
    dataset = dset.ImageFolder(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
189/4:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
189/5:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
191/1:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training/scans'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5),
            (0.5, 0.5, 0.5))])

    # Create the dataset.
    dataset = dset.ImageFolder(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
191/2:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
192/1:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training/scans'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5),
            (0.5, 0.5, 0.5))])

    # Create the dataset.
    dataset = dset.ImageFolder(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
192/2:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
193/1:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training/scans'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5),
            (0.5, 0.5, 0.5))])

    # Create the dataset.
    dataset = dset.ImageFolder(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
193/2:
export MPLBACKEND=TKAgg

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
193/3: export MPLBACKEND=TKAgg
194/1:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training/scans'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5),
            (0.5, 0.5, 0.5))])

    # Create the dataset.
    dataset = dset.ImageFolder(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/2:
export MPLBACKEND=TKAgg

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/3:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/4:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/5:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/6:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5),
            (0.5, 0.5, 0.5))])

    # Create the dataset.
    dataset = dset.ImageFolder(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/7:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/8:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/9:
class MyDataset(Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = image_paths
        self.transform = transform
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        x = Image.open(image_path)
        if self.transform is not None:
            x = self.transform(x)
        return x, y
    
    def __len__(self):
        return len(self.image_paths)
194/10:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = image_paths
        self.transform = transform
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        x = Image.open(image_path)
        if self.transform is not None:
            x = self.transform(x)
        return x, y
    
    def __len__(self):
        return len(self.image_paths)
194/11:
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = image_paths
        self.transform = transform
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        x = Image.open(image_path)
        if self.transform is not None:
            x = self.transform(x)
        return x, y
    
    def __len__(self):
        return len(self.image_paths)
194/12:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training/scans'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5),
            (0.5, 0.5, 0.5))])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/13:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/14:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/15:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(self.root)):
            self.image_paths += glob.glob(os.path.join(self.root, filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        x = Image.open(image_path)
        if self.transform is not None:
            x = self.transform(x)
        return x, y
    
    def __len__(self):
        return len(self.image_paths)
194/16:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training/scans'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5),
            (0.5, 0.5, 0.5))])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/17:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/18:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/19:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training/scans'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        #transforms.Normalize((0.5, 0.5, 0.5),
            (0.5, 0.5, 0.5))])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/20:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training/scans'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        #transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5)
        )])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/21:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training/scans'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        #transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/22:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/23:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/24:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training/scans'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/25:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/26:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/27:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(self.root)):
            self.image_paths += glob.glob(os.path.join(self.root, filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        x = Image.open(image_path)
        if self.transform is not None:
            x = self.transform(x)
        return x
    
    def __len__(self):
        return len(self.image_paths)
194/28:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training/scans'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/29:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/30:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/31:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/32:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        print(b_size)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/33:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(self.root)):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        print(x.shape)
        print(y.shape)
        if self.transform is not None:
            x = self.transform(x)
        return x
    
    def __len__(self):
        return len(self.image_paths)
194/34:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(self.root)):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        print(x.shape)
        print(y.shape)
        if self.transform is not None:
            x = self.transform(x)
        return x
    
    def __len__(self):
        return len(self.image_paths)
194/35:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/36:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/37:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/38:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans')):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        print(x.shape)
        print(y.shape)
        if self.transform is not None:
            x = self.transform(x)
        return x
    
    def __len__(self):
        return len(self.image_paths)
194/39:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        print(x.shape)
        print(y.shape)
        if self.transform is not None:
            x = self.transform(x)
        return x
    
    def __len__(self):
        return len(self.image_paths)
194/40:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/41:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/42:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/43:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        print(x.size)
        print(y.size)
        if self.transform is not None:
            x = self.transform(x)
        return x
    
    def __len__(self):
        return len(self.image_paths)
194/44:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/45:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/46:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/47:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        print(x.size)
        print(y.size)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.expand_dims(np.asarray(x), axis=2)
        print(x.shape)
        
        return x
    
    def __len__(self):
        return len(self.image_paths)
194/48:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/49:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/50:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/51:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        print(x.size)
        print(y.size)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        print(x.shape)
        
        return x
    
    def __len__(self):
        return len(self.image_paths)
194/52:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/53:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/54:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/55:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/56:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        print(x.shape)
        
        return x
    
    def __len__(self):
        return len(self.image_paths)
194/57:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        print(x.shape)
        
        return x
    
    def __len__(self):
        return len(self.image_paths)
194/58:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/59:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/60:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/61:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        print(new.shape)
        
        return x
    
    def __len__(self):
        return len(self.image_paths)
194/62:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/63:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/64:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/65:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        new = PIL.Image.fromarray(numpy.uint8(new))
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
194/66:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        new = PIL.Image.fromarray(numpy.uint8(new))
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
194/67:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/68:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/69:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/70:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        new = Image.fromarray(numpy.uint8(new))
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
194/71:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/72:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/73:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/74:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        new = Image.fromarray(np.uint8(new))
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
194/75:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/76:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/77:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/78:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
194/79:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/80:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/81:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/82:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/83:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/84:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch[:,0,:,:].shape)
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/85:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
sample_batch = sample_batch[:,0,:,:].shape
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/86:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/87:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/88:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        new = np.expand_dims(new, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
194/89:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        new = np.expand_dims(new, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
194/90:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/91:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/92:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/93:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/94:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/95:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/96:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        #y = np.asarray(y)
        #new = np.concatenate((x,y), axis=0)
        new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
194/97:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        #y = np.asarray(y)
        #new = np.concatenate((x,y), axis=0)
        new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
194/98:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/99:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/100:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/101:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        print(real_data.shape)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/102:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        print(real_data.shape)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        print(b_size)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/103:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        print(data.shape)
        real_data = data[0].to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/104:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        #x = np.asarray(x)
        #y = np.asarray(y)
        #new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return x
    
    def __len__(self):
        return len(self.image_paths)
194/105:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/106:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/107:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/108:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        print(data.shape)
        real_data = data[0].to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/109:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/110:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/111:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
195/1: import matplotlib.pyplot as plt
195/2: %matplotlib inline
195/3: plt.plot(np.arange(4))
195/4: %matplotlib
195/5:
%matplotlib
import matplotlib
matplotlib.use('TkAgg')
194/112:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        print(data.shape)
        real_data = data[0].to(device)
        print(real_data.shape)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
196/1:
%matplotlib
import matplotlib
matplotlib.use('TkAgg')
194/113:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        print(data.shape)
        real_data = data.to(device)
        print(real_data.shape)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
196/2: import matplotlib.pyplot as plt
194/114:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        print(data.shape)
        real_data = data.to(device)
        print(real_data.shape)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        print(label.shape)
        output = netD(real_data).view(-1)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
196/3:
import matplotlib
matplotlib.use(?)
196/4:
import matplotlib
matplotlib.use('?')
196/5:
import matplotlib
matplotlib.use('GTK3Agg')
196/6: plt.plot(np.arange(4))
194/115:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        print(data.shape)
        real_data = data.to(device)
        print(real_data.shape)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        print(real_data.shape)
        output = netD(real_data).view(-1)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
196/7:
import matplotlib
matplotlib.use('GTK3Agg')
import matlpotlib.pyplot as plt
196/8:
import matplotlib
matplotlib.use('GTK3Agg')
import matplotlib.pyplot as plt
194/116:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        print(data.shape)
        real_data = data.to(device)
        print(real_data.shape)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        print(real_data.shape)
        output = netD(real_data).view(-1)
        print(output.shape)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
196/9:
import matplotlib
matplotlib.use('GTK3Agg')
matplotlib.use('?')
# import matplotlib.pyplot as plt
196/10:
import matplotlib
matplotlib.use('Qt5Agg')
# matplotlib.use('?')
import matplotlib.pyplot as plt
197/1:
import matplotlib
# matplotlib.use('?')
import matplotlib.pyplot as plt
197/2: plt.plot(np.arange(4))
197/3: plt.close('all')
197/4:
import matplotlib
import matplotlib.pyplot as plt
197/5: plt.close('all')
194/117:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        #x = np.asarray(x)
        #y = np.asarray(y)
        #new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return x
    
    def __len__(self):
        return len(self.image_paths)
194/118:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/119:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/120:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/121:
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
197/6: plt.close('all')
194/122:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/123:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/124:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/125:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/126:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/127:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 64], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/128:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/129:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/130:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/131:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        print(data.shape)
        real_data = data[0].to(device)
        print(real_data.shape)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/132:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        print(data.shape)
        real_data = data[0].to(device)
        print(real_data.shape)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/133:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        print(data.shape)
        real_data = data[0].to(device)
        print(real_data.shape)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        print(output.shape)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/134:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        #transforms.Resize(params['imsize']),
        #transforms.CenterCrop(params['imsize']),
        transforms.Resize(64),
        transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/135:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/136:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/137:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/138:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/139:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/140:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/141:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        print(data.shape)
        real_data = data[0].to(device)
        print(real_data.shape)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        print(output.shape)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/142:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        print(data.shape)
        real_data = data[0].to(device)
        print(real_data.shape)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        print(output.shape)
        output = output.to(torch.float32)
        labels = labels.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/143:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        print(data.shape)
        real_data = data[0].to(device)
        print(real_data.shape)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        print(output.shape)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/144:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/145:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/146:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
194/147:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/148:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/149:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/150:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
194/151:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return x
    
    def __len__(self):
        return len(self.image_paths)
194/152:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        #transforms.Resize(params['imsize']),
        #transforms.CenterCrop(params['imsize']),
        transforms.Resize(64),
        transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/153:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/154:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/155:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/156:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
194/157:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        #transforms.Resize(params['imsize']),
        #transforms.CenterCrop(params['imsize']),
        transforms.Resize(64),
        transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/158:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 1,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/159:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/160:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/161:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/162:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/163:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/164:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/165:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/166:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
194/167:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i[:,:,0],(1,2,0)), animated=True)] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
194/168: print(img_list)
194/169: print(img_list[1].shape)
194/170:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i[0,:,:],(1,2,0)), animated=True)] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
194/171:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)[:,:,0]] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
194/172:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True)] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
194/173:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,1], animated=True)] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
194/174:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,1], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
194/175:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/176:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/177:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/178:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/179:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/180:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/181:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/182:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/183:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
194/184:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
194/185:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        #transforms.Resize(64),
        #transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/186:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/187:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/188:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/189:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/190:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/191:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/192:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/193:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/194:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/195:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/196:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/197:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/198:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/199:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/200:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/201:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/202:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/203:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/204:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/205:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/206:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/207:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/208:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/209:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/210:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/211:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/212:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,1,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/213:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/214:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/215:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/216:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/217:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/218:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/219:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/220:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/221:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/222:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/223:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/224:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/225:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/226:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/227:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/228:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/229:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/230:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/231:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/232:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/233:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/234:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/235:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/236:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/237:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/238:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/239:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/240:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/241:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/242:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/243:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/244:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/245:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/246:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/247:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/248:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
198/1: %run evaluate.py
198/2: %run evaluate.py
198/3: %run evaluate.py
198/4: %run evaluate.py
198/5: plt.close('all')
198/6: %run evaluate.py
198/7: plt.close('all')
198/8: model_torch
198/9: import os
198/10: os.path.join(model_torch,'../')
198/11: %run evaluate.py
198/12: plt.close('all')
198/13: %run evaluate.py
198/14: %run evaluate.py
198/15: %run evaluate.py
198/16: %run evaluate.py
198/17: %run evaluate.py
194/249:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/250:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/251:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/252:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/253:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/254:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/255:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/256:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/257:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
199/1: %run evaluate.py
194/258:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
194/259:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        #transforms.Resize(64),
        #transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/260:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/261:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
194/262:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
194/263:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
194/264:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        #transforms.Resize(64),
        #transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/265:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/266:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/267:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/268:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/269:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/270:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/271:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/272: print(img_list[1].shape)
194/273:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
200/1: import torch
200/2: a=torch.randn((4,4))
200/3: a
200/4: import torch.nn as nn
200/5: a=a.view(1,1,4,4)
200/6: a
200/7: c1 = nn.ConvTranspose2d(1,1,4,2,1)
200/8: b=c1(a)
200/9: b.shape
200/10: a=torch.randn((1,1,24,24))
200/11: b=c1(a)
200/12: b.shape
200/13: c2 = nn.ConvTranspose2d(1,1,4,2,0)
200/14: c2(a).shape
200/15: 240/16
200/16: c2 = nn.ConvTranspose2d(1,1,3,2,1)
200/17: c2(b).shape
200/18: a=torch.randn((1,1,8,8))
200/19: c2(a).shape
200/20: c1 = nn.Conv2d(1,1,4,2,1)
200/21: c1(a).shape
200/22: a=torch.randn((1,1,15,15))
200/23: c1 = nn.Conv2d(1,1,3,2,1)
200/24: c1(a).shape
194/274:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
194/275:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        #transforms.Resize(64),
        #transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/276:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/277:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/278:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/279:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/280:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/281: %debug
194/282:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/283:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/284:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/285:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/286:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 32, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/287:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/288:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data[0].to(device)
        real_data = real_data.unsqueeze(0)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
194/289: print(img_list[1].shape)
194/290:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
194/291: model = torch.load('model/model_epoch_90.pth')
194/292:
# model = torch.load('model/model_epoch_90.pth')
type(model)
194/293:
# model = torch.load('model/model_epoch_90.pth')
model.keys()
194/294: type(model['generator'])
194/295:
# model = torch.load('model/model_epoch_90.pth')
netG = Generator(params).to(device)
netG.load_state_dict(torch.load(model['generator']))
194/296:
# model = torch.load('model/model_epoch_90.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
194/297:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        #transforms.Resize(64),
        #transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(len(dataset))

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/298:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 32, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
194/299:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
194/300:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        #transforms.Resize(64),
        #transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print('Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
194/301: real_data.size
194/302: real_data.size()
194/303: real_data.unsqueeze(0).size()
194/304: real_data.size()
194/305: data.size()
194/306:
noise=torch.randn(1,100,1,1)
with torch.no_grad():
    out = netG(noise)
194/307:
noise=torch.randn(1,100,1,1, device=device)
with torch.no_grad():
    out = netG(noise)
194/308: out.shape
194/309:
num_images = 10
noise=torch.randn(num_images,100,1,1, device=device)
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
194/310:
# num_images = 10
# noise=torch.randn(num_images,100,1,1, device=device)
# with torch.no_grad():
#     out = netG(noise)
fig, ax = plt.subplots(num_images,2, figsize=(15,5*num_images))
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
194/311:
# num_images = 10
# noise=torch.randn(num_images,100,1,1, device=device)
# with torch.no_grad():
#     out = netG(noise)
fig, ax = plt.subplots(num_images,2, figsize=(15,3*num_images))
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
194/312:
# num_images = 10
# noise=torch.randn(num_images,100,1,1, device=device)
# with torch.no_grad():
#     out = netG(noise)
fig, ax = plt.subplots(num_images,2, figsize=(15,8*num_images))
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
194/313:
# num_images = 10
# noise=torch.randn(num_images,100,1,1, device=device)
# with torch.no_grad():
#     out = netG(noise)
fig, ax = plt.subplots(num_images,2, figsize=(15,8*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
194/314:
# num_images = 10
# noise=torch.randn(num_images,100,1,1, device=device)
# with torch.no_grad():
#     out = netG(noise)
fig, ax = plt.subplots(num_images,2, figsize=(10,8*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
194/315:
# num_images = 10
# noise=torch.randn(num_images,100,1,1, device=device)
# with torch.no_grad():
#     out = netG(noise)
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
194/316:
# num_images = 10
# noise=torch.randn(num_images,100,1,1, device=device)
# with torch.no_grad():
#     out = netG(noise)
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,0].set_title('Image')
    ax[i,1].set_title('Label')
194/317:
num_images = 10
noise=torch.randn(num_images,100,1,1, device=device)
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,0].set_title('Image')
    ax[i,1].set_title('Label')
194/318:
num_images = 10
noise=torch.randn(num_images,100,1,1, device=device)
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,0].set_title('Image')
    ax[i,1].set_title('Label')
194/319:
x,y=next(iter(dataloader))
x.shape
194/320:
x=next(iter(dataloader))
x.shape
194/321:
num_images = 10
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
194/322:
xx = x.to_device(device)
xx.shape
194/323:
xx = x.to(device)
xx.shape
194/324:
xx = x.to(device)
xx.unsqueeze(0)shape
194/325:
xx = x.to(device)
xx.unsqueeze(0).shape
205/1: print('a')
205/2:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/3:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        #transforms.Resize(64),
        #transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print('Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/4:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 32, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/5:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
205/6:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        #transforms.Resize(64),
        #transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/7:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 32, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/8:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        #transforms.Resize(64),
        #transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/9:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 32, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/10:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[0].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
205/11:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)

# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
sample_batch = sample_batch[:,0,:,:]
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(
    sample_batch[:].to(device)[ : 240], padding=2, normalize=True).cpu(), (1, 2, 0)))

plt.show()
205/12:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(sample_batch[i,0].cpu())
    ax[i,1].imshow(sample_batch[i,1].cpu())
    ax[i,0].set_title('Image')
    ax[i,1].set_title('Label')
205/13:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(10,5))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/14:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(15,5))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/15:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(20,5))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/16:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,5))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/17:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/18:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/19:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/20:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 32, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/21:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/22:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
205/23:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        import ipdb; ipdb.set_trace()
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
205/24:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in range(params['nepochs']):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
205/25:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
205/26:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
205/27:
model = torch.load('model/model_epoch_10.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
205/28:
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
205/29:
num_images = 10
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
205/30:
num_images = 50
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
205/31:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/32:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/33:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/34:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
205/35:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/36:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/37:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
205/38:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/39:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        #transforms.Resize(64),
        #transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/40:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/41:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/42:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
205/43:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
205/44:
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
205/45:
num_images = 50
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
205/46:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
205/47:
model = torch.load('model/model_epoch_10.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
205/48:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
205/49:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/50:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
205/51:
model = torch.load('model/model_epoch_18.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
205/52:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
205/53:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/54:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/55:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        #transforms.Resize(64),
        #transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/56:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/57:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/58:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
205/59:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/60:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        #transforms.Resize(64),
        #transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/61:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/62:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/63:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
205/64:
# model = torch.load('model/model_epoch_18.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
205/65:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
205/66:
model = torch.load('model/model_epoch_10.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
205/67:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
205/68:
model = torch.load('model/model_epoch_16.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
205/69:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
205/70:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/71:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/72:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        #transforms.Resize(64),
        #transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/73:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/74:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/75:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
205/76:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/77:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        #transforms.Resize(64),
        #transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/78:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/79:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/80:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
205/81:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/82:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        #transforms.Resize(64),
        #transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/83:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0005,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/84:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/85:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
205/86:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/87:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        #transforms.Resize(64),
        #transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/88:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0005,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/89:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/90:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
205/91:
model = torch.load('model/model_epoch_16.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
205/92:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
205/93:
model = torch.load('model/model_epoch_16.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
205/94:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
205/95:
# model = torch.load('model/model_epoch_16.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
205/96:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
205/97:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/98:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/99:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.CenterCrop(params['imsize']),
        #transforms.Resize(64),
        #transforms.CenterCrop(64),
        transforms.ToTensor(),
        transforms.Normalize(0.5,0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/100:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/101:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/102:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
206/1: np.min(np.arange(6),2)
206/2: np.min(np.arange(6,1),2)
205/103:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
205/104:
# model = torch.load('model/model_epoch_16.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
205/105:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
205/106:
model = torch.load('model/model_epoch_50.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
205/107:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
205/108:
xx = x.to(device)
xx.unsqueeze(0).shape
205/109: out.shape
205/110: out.mean(dim=(0,2,3))
205/111: out.max(dim=(0,2,3))
205/112: out.maximum(dim=(0,2,3))
205/113: out.mean(dim=(0,2,3))
205/114: x.mean(dim=(0,2,3))
205/115:
plt.imshow(x[0,0])
plt.colorbar()
205/116:
plt.imshow(x[0,1])
plt.colorbar()
205/117:
plt.imshow(x[0,5])
plt.colorbar()
205/118:
plt.imshow(x[5,1])
plt.colorbar()
205/119:
plt.imshow(x[9,1])
plt.colorbar()
205/120:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data[0].mean(dim=(0,2,3))
traindata_std = data[0].std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/121: data.size()
205/122:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/123:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.CenterCrop(params['imsize']),
                        transforms.ToTensor()
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/124:
model = torch.load('model/model_epoch_80.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
205/125:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
205/126:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/127:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.CenterCrop(params['imsize']),
                        transforms.ToTensor()
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/128:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
#         transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=traindata_mean,std=traindata_std)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/129:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/130:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/131:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/132:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.CenterCrop(params['imsize']),
                        transforms.ToTensor()
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/133:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
#         transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=traindata_mean,std=traindata_std)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/134:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/135:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/136: %debug
205/137:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor(),
                        transforms.Normalize(mean=traindata_mean,std=traindata_std)
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/138:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor(),
                        transforms.Normalize(mean=traindata_mean,std=traindata_std)
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/139:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        if self.transform is not None:
            new = self.transform(new)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/140:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor(),
                        transforms.Normalize(mean=traindata_mean,std=traindata_std)
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/141:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        new = np.concatenate((x,y), axis=0)
        if self.transform is not None:
            new = self.transform(new)
        new = np.asarray(new)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/142:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor(),
                        transforms.Normalize(mean=traindata_mean,std=traindata_std)
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/143:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        new = np.concatenate((x,y), axis=0)
        if self.transform is not None:
            new = self.transform(new)
        new = np.asarray(new)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/144:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor(),
                        transforms.Normalize(mean=traindata_mean,std=traindata_std)
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/145:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        new = np.concatenate((x,y), axis=0)
        new = Image.fromarray(np.uint8(new))
        if self.transform is not None:
            new = self.transform(new)
        new = np.asarray(new)
        #new = np.expand_dims(x, axis=0)
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/146:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor(),
                        transforms.Normalize(mean=traindata_mean,std=traindata_std)
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/147:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        import ipdb; ipdb.set_trace()
        new = np.concatenate((x,y), axis=0)
        new = Image.fromarray(np.uint8(new))
        if self.transform is not None:
            new = self.transform(new)
        new = np.asarray(new)
        #new = np.expand_dims(x, axis=0)
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/148:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor(),
                        transforms.Normalize(mean=traindata_mean,std=traindata_std)
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/149:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/150:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        import ipdb; ipdb.set_trace()
        if self.transform is not None:
            x = self.transform(x)
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/151:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor(),
#                         transforms.Normalize(mean=traindata_mean,std=traindata_std)
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/152:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor(),
#                         transforms.Normalize(mean=traindata_mean,std=traindata_std)
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/153:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
                        transforms.ToTensor(),
#                         transforms.Normalize(mean=traindata_mean,std=traindata_std)
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/154:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
                        transforms.ToTensor(),
#                         transforms.Normalize(mean=traindata_mean,std=traindata_std)
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
206/3: from PIL import Image
206/4: import torch
206/5: import torchvision.transforms as transforms
206/6: a = np.ones((240,240,2))
206/7: b = Image.fromarray(a)
206/8: b = Image.fromarray(a.astype(np.uint8))
206/9: c=transforms.ToTensor(b)
206/10: c=transforms.ToTensor()
206/11: c=c(b)
206/12: c.shape
206/13: b.shape
206/14: np.array(b).shape
205/155:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = np.array(Image.open(image_path))
        y = np.array(Image.open(label_path))
        y[y>1] = 1
        new = Image.fromarray(np.stack((x,y),axis=2))
        if self.transform is not None:
            new = self.transform(new)
#         new = np.array(new)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/156:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
                        transforms.ToTensor(),
#                         transforms.Normalize(mean=traindata_mean,std=traindata_std)
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/157:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor(),
#                         transforms.Normalize(mean=traindata_mean,std=traindata_std)
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/158:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor(),
                        transforms.Normalize(mean=traindata_mean,std=traindata_std)
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/159:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/160:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
#         transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=traindata_mean,std=traindata_std)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/161:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/162:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/163:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/164:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/165:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/166:
%matplotlib interactive
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/167:
%matplotlib notebook
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/168:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = np.array(Image.open(image_path))
        y = np.array(Image.open(label_path))
        y[y>1] = 1
        new = Image.fromarray(np.stack((x,y),axis=2))
        if self.transform is not None:
            new = self.transform(new)
#         new = np.array(new)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/169:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/170:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
#         transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=traindata_mean,std=traindata_std)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/171:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/172:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/173:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/174:
import os
import glob
import torch
from PIL import Image
from torch.utils import data
%matplotlib inline


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = np.array(Image.open(image_path))
        y = np.array(Image.open(label_path))
        y[y>1] = 1
        new = Image.fromarray(np.stack((x,y),axis=2))
        if self.transform is not None:
            new = self.transform(new)
#         new = np.array(new)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/175:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
#         transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=traindata_mean,std=traindata_std)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/176:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/177:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/178:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/179:
import os
import glob
import torch
from PIL import Image
from torch.utils import data
%matplotlib inline


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = np.array(Image.open(image_path))
        y = np.array(Image.open(label_path))
        y[y>1] = 1
        new = Image.fromarray(np.stack((x,y),axis=2))
        if self.transform is not None:
            new = self.transform(new)
        new = np.array(new)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/180:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/181:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
#         transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=traindata_mean,std=traindata_std)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/182:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/183:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/184:
import os
import glob
import torch
from PIL import Image
from torch.utils import data
%matplotlib inline


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = np.array(Image.open(image_path))
        y = np.array(Image.open(label_path))
        y[y>1] = 1
        new = Image.fromarray(np.stack((x,y),axis=2))
        if self.transform is not None:
            new = self.transform(new)
        new = np.array(new)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/185:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/186:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
#         transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=traindata_mean,std=traindata_std)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/187:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/188:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/189:
import os
import glob
import torch
from PIL import Image
from torch.utils import data
%matplotlib inline


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = np.array(Image.open(image_path))
        y = np.array(Image.open(label_path))
#         y[y>1] = 1
        new = Image.fromarray(np.stack((x,y),axis=2))
        if self.transform is not None:
            new = self.transform(new)
        new = np.array(new)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/190:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/191:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
#         transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=traindata_mean,std=traindata_std)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/192:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/193:
import os
import glob
import torch
from PIL import Image
from torch.utils import data
%matplotlib inline


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = np.array(Image.open(image_path))
        y = np.array(Image.open(label_path))
#         y[y>1] = 1
        new = Image.fromarray(np.stack((x,y),axis=2))
        if self.transform is not None:
            new = self.transform(new)
        new = np.array(new)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/194:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
#         transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=traindata_mean,std=traindata_std)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/195:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/196:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/197:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/198:
import os
import glob
import torch
from PIL import Image
from torch.utils import data
%matplotlib inline


class MyDataset(data.Dataset):
    def __init__(self, root, transform=None):
        self.image_paths = []
        self.label_paths = []
        self.transform = transform
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = np.asarray(Image.open(image_path))
        y = np.asarray(Image.open(label_path))
#         y[y>1] = 1
        new = Image.fromarray(np.stack((x,y),axis=2))
        if self.transform is not None:
            new = self.transform(new)
        new = np.asarray(new)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/199:
dataset = MyDataset(root=root, 
                    transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
                   )
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/200:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform = transforms.Compose([
        transforms.Resize(params['imsize']),
#         transforms.CenterCrop(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=traindata_mean,std=traindata_std)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/201:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/202:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/203:
transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/204:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform_image is not None:
            x = self.transform(x)
        if self.transform_label is not None:
            y = self.transform(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/205:
transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/206:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/207:
transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/208:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=traindata_mean[0],std=traindata_std[0])
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=traindata_mean[1],std=traindata_std[1])
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform=transform)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/209:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=traindata_mean[0],std=traindata_std[0])
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=traindata_mean[1],std=traindata_std[1])
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/210:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/211:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/212:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
205/213:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
205/214:
# model = torch.load('model/model_epoch_80.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
205/215:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
205/216:
plt.imshow(x[9,1])
plt.colorbar()
205/217:
plt.imshow(x[19,1])
plt.colorbar()
205/218:
plt.imshow(x[0,1])
plt.colorbar()
205/219:
plt.imshow(x[2,1])
plt.colorbar()
205/220:
plt.imshow(x[2,8])
plt.colorbar()
205/221:
for i in range(20):
    plt.imshow(x[i,1])
    plt.colorbar()
205/222:
for i in range(20):
    plt.figure()
    plt.imshow(x[i,1])
    plt.colorbar()
205/223:
for i in range(20):
    plt.figure()
    plt.imshow(x[i,0])
    plt.colorbar()
205/224:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/225:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/226:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
205/227:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        y = np.asarray(y)
        y[y>1]=1
        y = Image.fromarray(np.uint8(y))
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/228:
transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/229:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        y = np.array(y)
        y[y>1]=1
        y = Image.fromarray(np.uint8(y))
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/230:
transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/231:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=traindata_mean[0],std=traindata_std[0])
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=traindata_mean[1],std=traindata_std[1])
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/232:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/233:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/234:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
205/235:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/236:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/237:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/238:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
205/239:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
205/240:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        y = np.array(y)
        y[y>0.5]=255
        y = Image.fromarray(np.uint8(y))
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/241:
transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/242:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/243:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/244:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/245:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        y = np.array(y)
        y[y>0.5]=255
        y = Image.fromarray(np.uint8(y))
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/246:
transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/247:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/248:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/249:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/250:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
205/251: sample_batch[0,1].max()
205/252: sample_batch[0,1].min()
205/253: sample_batch[0,1]
205/254:
a=np.array(sample_batch[0,1])
np.hist()
205/255:
a=np.array(sample_batch[0,1])
np.hist()
205/256:
a=np.array(sample_batch[0,1])
np.hist(a)
205/257:
a=np.array(sample_batch[0,1])
np.histogram(a)
205/258:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/259:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
205/260:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
205/261:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        y = np.array(y)
        y[y>0.5]=255
        y = Image.fromarray(np.uint8(y))
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/262:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/263:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/264:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/265:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
205/266:
a=np.array(sample_batch[0,1])
np.histogram(a)
205/267:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
205/268:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        y = np.array(y)
        y[y>0.5]=255
        y[y<=0.5]=0
        y = Image.fromarray(np.uint8(y))
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/269:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/270:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/271:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/272:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
205/273:
a=np.array(sample_batch[0,1])
np.histogram(a)
205/274:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        y = np.array(y)
#         y[y>0.5]=255
#         y[y<=0.5]=0
        y = Image.fromarray(np.uint8(y))
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/275:
transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/276:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
205/277:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
205/278:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
205/279:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
205/280:
a=np.array(sample_batch[0,1])
np.histogram(a)
205/281:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
205/282:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        y = np.array(y)
        import ipdb; ipdb.set_trace()
#         y[y>0.5]=255
#         y[y<=0.5]=0
        y = Image.fromarray(np.uint8(y))
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/283:
transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
205/284:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        y = np.array(y)
        import ipdb; ipdb.set_trace()
        y[y>0.5]=255.0
        y[y<=0.5]=0.0
        y = Image.fromarray(np.uint8(y))
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
205/285:
transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
206/15: a=3
208/1:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        y = np.array(y)
#         import ipdb; ipdb.set_trace()
        y[y>0.5]=255.0
        y[y<=0.5]=0.0
        y = Image.fromarray(np.uint8(y))
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/2:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/3:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/4:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/5:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/6:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
208/7:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        y = np.array(y)
#         import ipdb; ipdb.set_trace()
        y[y>0.5]=255.0
        y[y<=0.5]=0.0
        y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/8:
transform=transforms.Compose([
                        transforms.Resize(params['imsize']),
                        transforms.ToTensor()
                    ])
dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=len(dataset),
        shuffle=True)
data = next(iter(dataloader))
traindata_mean = data.mean(dim=(0,2,3))
traindata_std = data.std(dim=(0,2,3))
print('mean: {}'.format(traindata_mean.numpy()))
print('std: {}'.format(traindata_std.numpy()))
208/9:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/10:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/11:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/12:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/13:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/14:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        y = np.array(y)
#         import ipdb; ipdb.set_trace()
        y[y>0.5]=255.0
        y[y<=0.5]=0.0
        y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/15:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
208/16:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/17:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/18:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/19:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/20:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/21:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
        y[y>0.5]=255.0
        y[y<=0.5]=0.0
        y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/22:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
208/23:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/24:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/25:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/26:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/27:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/28:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
        y[y>0.5]=255.0
        y[y<=0.5]=0.0
        y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/29:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/30:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/31:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/32:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/33:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/34:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/35:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/36:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/37:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/38:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/39:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
        y[y>0.5]=255.0
        y[y<=0.5]=0.0
        y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/40:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
208/41:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/42:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/43:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/44:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/45:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/46:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/47:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
208/48:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
208/49:
# model = torch.load('model/model_epoch_80.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
208/50:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
208/51:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
        y[y>0.5]=255.0
        y[y<=0.5]=0.0
        y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/52:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
208/53:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/54:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/55:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/56:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/57:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/58:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
208/59:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
208/60:
# model = torch.load('model/model_epoch_80.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
208/61:
# model = torch.load('model/model_epoch_80.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
208/62:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
208/63:
for i in range(20):
    plt.figure()
    plt.imshow(x[i,0])
    plt.colorbar()
208/64:
for i in range(20):
    plt.figure()
    plt.imshow(x[i,1])
    plt.colorbar()
208/65:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
#         y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/66:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
208/67:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/68:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/69:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/70:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
#         y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/71:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
208/72:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/73:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/74:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/75:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/76:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/77:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/78:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/79:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
208/80:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/81:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/82:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/83:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/84:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/85:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/86:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
208/87:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/88:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/89:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/90:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/91:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/92:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
208/93:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/94:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
208/95:
# model = torch.load('model/model_epoch_80.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
208/96:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
208/97:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/98:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/99:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
208/100:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/101:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
208/102:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/103:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
208/104:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/105:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/106:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/107:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
208/108:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/109:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
208/110:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
#         y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/111:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
208/112:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/113:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/114:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/115:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
208/116:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/117:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
212/1: %run evaluate.py
212/2: %run evaluate.py
212/3: %run evaluate.py
208/118:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
208/119:
# model = torch.load('model/model_epoch_80.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
208/120:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
208/121:
model = torch.load('model/model_epoch_2.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
208/122:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
208/123:
model = torch.load('model/model_epoch_4.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
208/124:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
208/125:
for i in range(20):
    plt.figure()
    plt.imshow(x[i,1])
    plt.colorbar()
208/126:
for i in range(20):
    plt.figure()
    plt.imshow(x[i,0])
    plt.colorbar()
208/127:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/128:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
208/129:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/130:
model = torch.load('model/model_epoch_8.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
208/131:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
208/132:
model = torch.load('model/model_epoch_16.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
208/133:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
208/134:
# model = torch.load('model/model_epoch_20.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
208/135:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
208/136:
for i in range(20):
    plt.figure()
    plt.imshow(x[i,0])
    plt.colorbar()
208/137:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
#         y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/138:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
208/139:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/140:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/141:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/142:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/143:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
208/144:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/145:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
208/146:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/147:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/148:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/149:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
208/150:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/151:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
208/152:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
208/153:
# model = torch.load('model/model_epoch_20.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
208/154:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
208/155:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/156:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/157:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/158:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/159:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/160:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
208/161:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
208/162:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
208/163:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/164:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
208/165:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/166:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/167:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/168:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
208/169:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/170:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
212/4: %run evaluate.py
212/5: %run evaluate.py
208/171:
# model = torch.load('model/model_epoch_20.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
208/172:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
208/173:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
208/174:
model = torch.load('model/model_epoch_14.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
208/175:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
212/6: torch.tanh
208/176:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/177:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
208/178:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/179:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/180:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/181:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
208/182:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/183:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
208/184:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
208/185:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
208/186:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
208/187:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/188:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
208/189:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/190:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 16,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/191:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/192:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
208/193:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/194:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/195:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
208/196:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/197:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/198:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/199:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/200:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
208/201:
model = torch.load('model/model_epoch_14.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
208/202:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
208/203:
# model = torch.load('model/model_epoch_14.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
208/204:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
212/7: a=torch.randn(3,5,5)
212/8: a.unsqueeze(1).shape
208/205:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
208/206:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
208/207:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/208:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
208/209:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/210:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/211:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/212:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/213:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/214:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
208/215:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
212/9: a/shape
212/10: a.shape
212/11: a[:,[2]].shape
208/216:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
208/217:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
208/218:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
208/219:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 128, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
208/220:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
208/221:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
208/222:
a=np.array(sample_batch[0,1])
np.histogram(a)
208/223:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
213/1:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
213/2:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
213/3:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
213/4:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 128, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
213/5:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
213/6:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
213/7:
a=np.array(sample_batch[0,1])
np.histogram(a)
213/8:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
213/9:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
213/10:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
213/11:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
213/12:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
213/13:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
213/14:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
213/15:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
213/16:
a=np.array(sample_batch[0,1])
np.histogram(a)
213/17:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
213/18:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
213/19:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
213/20:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
213/21:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
213/22:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
213/23:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.00002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
213/24:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
213/25:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
213/26:
a=np.array(sample_batch[0,1])
np.histogram(a)
213/27:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
212/12: torch.sigmoid
213/28:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
213/29:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
213/30:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
213/31:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.00002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
213/32:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
213/33:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
213/34:
a=np.array(sample_batch[0,1])
np.histogram(a)
213/35:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
213/36:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
213/37:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
213/38:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
213/39:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
213/40:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
213/41:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
213/42:
a=np.array(sample_batch[0,1])
np.histogram(a)
213/43:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
213/44:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
213/45:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
213/46:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
213/47:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
seed = 369
random.seed(seed)
torch.manual_seed(seed)
print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
213/48:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
213/49:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
213/50:
a=np.array(sample_batch[0,1])
np.histogram(a)
213/51:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
213/52:
# model = torch.load('model/model_epoch_14.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
213/53:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
213/54:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
213/55:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
213/56:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
213/57:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
213/58:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
213/59:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
213/60:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
213/61:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
213/62:
a=np.array(sample_batch[0,1])
np.histogram(a)
213/63:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
213/64:
# model = torch.load('model/model_epoch_14.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
213/65:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
213/66:
model = torch.load('model/model_epoch_14.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
213/67:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
213/68:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
213/69:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
213/70: plt.plot(G_losses)
213/71:
plt.plot(G_losses)
plt.ylim([0,2])
213/72:
model = torch.load('model/model_epoch_10.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
213/73:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
213/74:
for i in range(20):
    plt.figure()
    plt.imshow(x[i,0])
    plt.colorbar()
213/75:
for i in range(20):
    plt.figure()
    plt.imshow(out[i,0])
    plt.colorbar()
213/76:
for i in range(20):
    plt.figure()
    plt.imshow(out[i,0].cpu())
    plt.colorbar()
213/77:
for i in range(20):
    plt.figure()
    plt.imshow(out[i,1].cpu())
    plt.colorbar()
213/78:
model = torch.load('model/model_epoch_10.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
213/79:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
213/80:
# model = torch.load('model/model_epoch_10.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
213/81:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
213/82:
for i in range(20):
    plt.figure()
    plt.imshow(out[i,1].cpu())
    plt.colorbar()
213/83:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
213/84:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
213/85:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
213/86:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 200,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
213/87:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
213/88:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
213/89:
a=np.array(sample_batch[0,1])
np.histogram(a)
213/90:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr']*2, betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
212/13: %run evaluate.py
212/14: %run evaluate.py
213/91:
model = torch.load('model/model_epoch_16.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
213/92:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
213/93:
num_images = 30
noise=torch.randn(num_images,params['nz'],1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
213/94:
model = torch.load('model/model_epoch_8.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
213/95:
num_images = 30
noise=torch.randn(num_images,params['nz'],1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
213/96:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
213/97:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
213/98:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
213/99:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 50,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
213/100:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
213/101:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
213/102:
a=np.array(sample_batch[0,1])
np.histogram(a)
213/103:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr']*4, betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
213/104:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr']*4, betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
212/15: %run evaluate.py
213/105:
model = torch.load('model/model_epoch_8.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
213/106:
num_images = 30
noise=torch.randn(num_images,params['nz'],1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
213/107:
model = torch.load('model/model_epoch_14.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
213/108:
num_images = 30
noise=torch.randn(num_images,params['nz'],1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
213/109:
model = torch.load('model/model_epoch_4.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
213/110:
num_images = 30
noise=torch.randn(num_images,params['nz'],1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
213/111:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
213/112:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
213/113:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
213/114:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 6,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
213/115:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
213/116:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
213/117:
a=np.array(sample_batch[0,1])
np.histogram(a)
213/118:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr']*4, betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
213/119:
# model = torch.load('model/model_epoch_4.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
213/120:
num_images = 30
noise=torch.randn(num_images,params['nz'],1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
213/121:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
213/122:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
213/123:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
213/124:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 6,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
213/125:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
213/126:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
213/127:
a=np.array(sample_batch[0,1])
np.histogram(a)
213/128:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
212/16: a=['a',('a','b')]
212/17: a[0]
212/18: a[1]
212/19: a=['a',('a',1)]
212/20: a[1]
212/21: a=['a',(1)]
212/22: a[1]
212/23: a=['a',(1,)]
212/24: a[1]
212/25: a[1][0]
212/26: %run evaluate.py
213/129:
# model = torch.load('model/model_epoch_4.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
213/130:
num_images = 30
noise=torch.randn(num_images,params['nz'],1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
214/1:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
214/2:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
214/3:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
214/4:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 6,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
214/5:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
214/6:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
214/7:
a=np.array(sample_batch[0,1])
np.histogram(a)
214/8:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
214/9:
# model = torch.load('model/model_epoch_4.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
214/10:
num_images = 30
noise=torch.randn(num_images,params['nz'],1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
214/11:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
214/12:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
214/13:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
214/14:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
214/15:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
214/16:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
214/17:
a=np.array(sample_batch[0,1])
np.histogram(a)
214/18:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
214/19:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
214/20:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
214/21:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
214/22:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
214/23:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
214/24:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
214/25:
a=np.array(sample_batch[0,1])
np.histogram(a)
214/26:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
214/27:
model = torch.load('model/model_epoch_30.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
214/28:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
214/29:
model = torch.load('model/model_epoch_60.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
214/30:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
214/31:
model = torch.load('model/model_epoch_20.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
214/32:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
211/1:
import nibabel as nib
import numpy as np
import matplotlib
matplotlib.use('TKAgg')
import matplotlib.pyplot as plt
from IPython.display import clear_output
%matplotlib inline
211/2:
import os
import cv2
211/3: flair = nib.load('dataset/training/BraTS20_Training_001/BraTS20_Training_001_flair.nii.gz').get_fdata()
211/4:
print(flair.shape)
plt.imshow(flair[:,:,50], cmap='gray')
211/5: label = nib.load('dataset/training/BraTS20_Training_185/BraTS20_Training_185_seg.nii.gz').get_fdata()
211/6:
print(label.shape)

label = label != 0
label = label.astype(int)

plt.imshow(label[:,:,50], cmap='gray')
211/7:
print(label.shape)

label = label > 1
label = label.astype(int)

plt.imshow(label[:,:,50], cmap='gray')
211/8:
print(label.shape)

label = label > 1
label = label.astype(int)

plt.imshow(label[:,:,50], cmap='gray')
211/9:
print(label.shape)

# label = label > 1
label = label.astype(int)

plt.imshow(label[:,:,50], cmap='gray')
211/10: label = nib.load('dataset/training/BraTS20_Training_185/BraTS20_Training_185_seg.nii.gz').get_fdata()
211/11:
print(label.shape)

# label = label > 1
label = label.astype(int)

plt.imshow(label[:,:,50], cmap='gray')
211/12: label = nib.load('dataset/training/BraTS20_Training_185/BraTS20_Training_185_seg.nii.gz').get_fdata()
211/13:
print(label.shape)

# label = label > 1
label = label.astype(int)

plt.imshow(label[:,:,50], cmap='gray')
211/14:
print(label.shape)

# label = label > 1
label = label.astype(int)

plt.imshow(label[:,:,50], cmap='gray')
plt.colorbar()
211/15:
print(label.shape)

# label = label > 1
label = label.astype(int)
label[label>1]=1

plt.imshow(label[:,:,50], cmap='gray')
plt.colorbar()
211/16:
print(label.shape)

# label = label > 1
label = np.array(label)
label[label>1]=1

plt.imshow(label[:,:,50], cmap='gray')
plt.colorbar()
211/17:
print(label.shape)

# label = label > 1
label = np.array(label)
label[label>1]=1

plt.imshow(label[:,:,50], cmap='gray')
plt.colorbar()
211/18:
print(label.shape)

# label = label > 1
label = np.array(label)
label[label>1]=1

plt.imshow(label[:,:,5], cmap='gray')
plt.colorbar()
211/19:
print(label.shape)

# label = label > 1
label = np.array(label)
label[label>1]=1

plt.imshow(label[:,:,15], cmap='gray')
plt.colorbar()
211/20:
print(label.shape)

# label = label > 1
label = np.array(label)
label[label>1]=1

plt.imshow(label[:,:,25], cmap='gray')
plt.colorbar()
211/21:
print(label.shape)

# label = label > 1
label = np.array(label)
label[label>1]=1

plt.imshow(label[:,:,55], cmap='gray')
plt.colorbar()
211/22:
print(label.shape)

# label = label > 1
label = np.array(label)
label[label>1]=1

plt.imshow(label[:,:,35], cmap='gray')
plt.colorbar()
211/23:
print(label.shape)

# label = label > 1
label = np.array(label)
label[label>1]=1

plt.imshow(label[:,:,115], cmap='gray')
plt.colorbar()
211/24:
print(label.shape)

# label = label > 1
label = np.array(label)
label[label>1]=1

plt.imshow(label[:,:,78], cmap='gray')
plt.colorbar()
211/25:
print(label.shape)

# label = label > 1
label = np.array(label)
label[label>1]=1

plt.imshow(label[:,:,100], cmap='gray')
plt.colorbar()
211/26:
print(label.shape)

# label = label > 1
label = np.array(label)
label[label>1]=1

plt.imshow(label[:,:,100], cmap='gray')
plt.colorbar()
print(np.sum(label[:,:,100]))
211/27:
print(label.shape)

# label = label > 1
label = np.array(label)
label[label>1]=1

plt.imshow(label[:,:,120], cmap='gray')
plt.colorbar()
print(np.sum(label[:,:,100]))
211/28:
print(label.shape)

# label = label > 1
label = np.array(label)
label[label>1]=1

plt.imshow(label[:,:,110], cmap='gray')
plt.colorbar()
print(np.sum(label[:,:,100]))
211/29:
print(label.shape)

# label = label > 1
label = np.array(label)
label[label>1]=1

plt.imshow(label[:,:,110], cmap='gray')
plt.colorbar()
print(np.sum(label[:,:,110]))
211/30:
print(label.shape)

# label = label > 1
label = np.array(label).astype(uint8)
label[label>1]=1

plt.imshow(label[:,:,110], cmap='gray')
plt.colorbar()
print(np.sum(label[:,:,110]))
211/31:
print(label.shape)

# label = label > 1
label = np.array(label).astype(np.uint8)
label[label>1]=1

plt.imshow(label[:,:,110], cmap='gray')
plt.colorbar()
print(np.sum(label[:,:,110]))
211/32:
def labels_nii2jpg(input_path, output_root):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    label = nib.load(label_path).get_fdata()
    label = np.array(label)
    label = (label > 0)
    label[label>1]=1
    #label = label.astype(bool).astype(int)
    
    
    
    for i in range(label.shape[2]):
        filename = os.path.join(output_root,label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        if tumor_only:
            if np.sum(label_img>100)
                cv2.imwrite(filename, label_img)
        else:
            cv2.imwrite(filename, label_img)
211/33:
for i, path in enumerate(os.listdir(training_root)):
    if i<300:
        scans_labels_nii2jpg(os.path.join(training_root,path),'projects/auggan/dataset/slices_2d/training/')
    elif i<369:
        scans_labels_nii2jpg(os.path.join(training_root,path),'projects/auggan/dataset/slices_2d/validation/')
211/34:
training_root = 'projects/auggan/dataset/training/'
validation_root = 'projects/auggan/dataset/validation/'
211/35:
for i, path in enumerate(os.listdir(training_root)):
    if i<300:
        scans_labels_nii2jpg(os.path.join(training_root,path),'projects/auggan/dataset/slices_2d/training/')
    elif i<369:
        scans_labels_nii2jpg(os.path.join(training_root,path),'projects/auggan/dataset/slices_2d/validation/')
211/36: pwd
211/37:
for i, path in enumerate(os.listdir(training_root)):
    if i<300:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/training/')
    elif i<369:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/validation/')
211/38:
training_root = '/home/kamo/projects/auggan/dataset/training/'
validation_root = '/home/kamo/projects/auggan/dataset/validation/'
211/39:
for i, path in enumerate(os.listdir(training_root)):
    if i<300:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/training/')
    elif i<369:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/validation/')
211/40:
def scans_labels_nii2jpg(input_path, output_root, tumor_only=False):
    try:
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    
    scan_path = os.path.join(input_path, folder_name + '_flair.nii.gz')
    scan = nib.load(scan_path).get_fdata()
    scan = (scan/scan.max())*255
    scan = scan.astype(np.uint8)
    
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    
    label = nib.load(label_path).get_fdata()
    label = np.array(label)
    label[label>1]=1
    #label = label.astype(bool).astype(int)
    
    
    for i in range(label.shape[2]):
        filename_scans = os.path.join(output_root+'scans',label_num+'_'+str(i)+'.jpg')
        filename_labels = os.path.join(output_root+'labels',label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        scan_img = scan[:,:,i]
        if tumor_only:
            if np.sum(label_img>100):
                cv2.imwrite(filename_scans, scan_img)
                cv2.imwrite(filename_labels, label_img)
        else:
            cv2.imwrite(filename_scans, scan_img)
            cv2.imwrite(filename_labels, label_img)
211/41:
for i, path in enumerate(os.listdir(training_root)):
    if i<300:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/training/')
    elif i<369:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/validation/')
211/42: i
211/43:
for i, path in enumerate(os.listdir(training_root)):
    print(i)
    if i<300:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/training/')
    elif i<369:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/validation/')
211/44: %debug
211/45: glob
211/46:
import glob
glob.glob(training_root+'/Br*')
211/47:
import glob
glob.glob(training_root+'/Br*').sort()
211/48:
import glob
print(glob.glob(training_root+'/Br*').sort())
211/49:
import glob
a=glob.glob(training_root+'/Br*')
a.sort()
a
211/50:
files = glob.glob(training_root+'/Br')
files.sort()
for i, path in enumerate(files):
    print(i)
    if i<300:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/training/')
    elif i<369:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/validation/')
211/51:
files = glob.glob(training_root+'/Br')
files.sort()
for i, path in enumerate(files):
    print(i)
    if i<300:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/training/')
    elif i<369:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/validation/')
211/52:
files = glob.glob(training_root+'/Br*')
files.sort()
for i, path in enumerate(files):
    print(i)
    if i<300:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/training/')
    elif i<369:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/validation/')
214/33:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
214/34:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
214/35:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
214/36:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
214/37:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
214/38:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
214/39:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
214/40:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
211/53:
def scans_labels_nii2jpg(input_path, output_root, tumor_only=False):
    try:
        os.mkdir(output_root+'scans')
        os.mkdir(output_root+'labels')
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    
    scan_path = os.path.join(input_path, folder_name + '_flair.nii.gz')
    scan = nib.load(scan_path).get_fdata()
    scan = (scan/scan.max())*255
    scan = scan.astype(np.uint8)
    
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    
    label = nib.load(label_path).get_fdata()
    label = np.array(label)
    label[label>1]=1
    #label = label.astype(bool).astype(int)
    
    
    for i in range(label.shape[2]):
        filename_scans = os.path.join(output_root+'scans',label_num+'_'+str(i)+'.jpg')
        filename_labels = os.path.join(output_root+'labels',label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        scan_img = scan[:,:,i]
        if tumor_only:
            if np.sum(label_img>100):
                cv2.imwrite(filename_scans, scan_img)
                cv2.imwrite(filename_labels, label_img)
        else:
            cv2.imwrite(filename_scans, scan_img)
            cv2.imwrite(filename_labels, label_img)
211/54:
def scans_labels_nii2jpg(input_path, output_root, tumor_only=True):
    try:
        os.mkdir(output_root+'scans')
        os.mkdir(output_root+'labels')
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    
    scan_path = os.path.join(input_path, folder_name + '_flair.nii.gz')
    scan = nib.load(scan_path).get_fdata()
    scan = (scan/scan.max())*255
    scan = scan.astype(np.uint8)
    
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    
    label = nib.load(label_path).get_fdata()
    label = np.array(label)
    label[label>1]=1
    #label = label.astype(bool).astype(int)
    
    
    for i in range(label.shape[2]):
        filename_scans = os.path.join(output_root+'scans',label_num+'_'+str(i)+'.jpg')
        filename_labels = os.path.join(output_root+'labels',label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        scan_img = scan[:,:,i]
        if tumor_only:
            if np.sum(label_img>100):
                cv2.imwrite(filename_scans, scan_img)
                cv2.imwrite(filename_labels, label_img)
        else:
            cv2.imwrite(filename_scans, scan_img)
            cv2.imwrite(filename_labels, label_img)
211/55:
files = glob.glob(training_root+'/Br*')
files.sort()
for i, path in enumerate(files):
    print(i)
    if i<300:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/training/')
    elif i<369:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/validation/')
214/41:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
214/42:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
214/43:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
214/44:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
214/45:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
215/1:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
215/2:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
215/3:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
215/4:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
215/5:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
211/56:
def scans_labels_nii2jpg(input_path, output_root, tumor_only=True):
    try:
        os.mkdir(output_root+'scans')
        os.mkdir(output_root+'labels')
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    
    scan_path = os.path.join(input_path, folder_name + '_flair.nii.gz')
    scan = nib.load(scan_path).get_fdata()
    scan = (scan/scan.max())*255
    scan = scan.astype(np.uint8)
    
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    
    label = nib.load(label_path).get_fdata()
    label = np.array(label)
    label[label>1]=1
    #label = label.astype(bool).astype(int)
    
    
    for i in range(label.shape[2]):
        filename_scans = os.path.join(output_root+'scans',label_num+'_'+str(i)+'.jpg')
        filename_labels = os.path.join(output_root+'labels',label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        scan_img = scan[:,:,i]
        import ipdb; ipdb.set_trace()
        if tumor_only:
            if np.sum(label_img>100):
                cv2.imwrite(filename_scans, scan_img)
                cv2.imwrite(filename_labels, label_img)
        else:
            cv2.imwrite(filename_scans, scan_img)
            cv2.imwrite(filename_labels, label_img)
211/57:
files = glob.glob(training_root+'/Br*')
files.sort()
for i, path in enumerate(files):
    print(i)
    if i<300:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/training/')
    elif i<369:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/validation/')
211/58:
def scans_labels_nii2jpg(input_path, output_root, tumor_only=True):
    try:
        os.mkdir(output_root+'scans')
        os.mkdir(output_root+'labels')
        os.makedirs(output_root)
    except:
        pass
    
    folder_name = input_path.split('/')[-1]
    label_num = folder_name.split('_')[2]
    
    scan_path = os.path.join(input_path, folder_name + '_flair.nii.gz')
    scan = nib.load(scan_path).get_fdata()
    scan = (scan/scan.max())*255
    scan = scan.astype(np.uint8)
    
    label_path = os.path.join(input_path, folder_name + '_seg.nii.gz')
    
    label = nib.load(label_path).get_fdata()
    label = np.array(label)
    label[label>1]=1
    #label = label.astype(bool).astype(int)
    
    
    for i in range(label.shape[2]):
        filename_scans = os.path.join(output_root+'scans',label_num+'_'+str(i)+'.jpg')
        filename_labels = os.path.join(output_root+'labels',label_num+'_'+str(i)+'.jpg')
        label_img = label[:,:,i]
        scan_img = scan[:,:,i]
        if tumor_only:
            if np.sum(label_img)>100:
                cv2.imwrite(filename_scans, scan_img)
                cv2.imwrite(filename_labels, label_img)
        else:
            cv2.imwrite(filename_scans, scan_img)
            cv2.imwrite(filename_labels, label_img)
211/59:
files = glob.glob(training_root+'/Br*')
files.sort()
for i, path in enumerate(files):
    print(i)
    if i<300:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/training/')
    elif i<369:
        scans_labels_nii2jpg(os.path.join(training_root,path),'/home/kamo/projects/auggan/dataset/slices_2d/validation/')
215/6:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
215/7:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
215/8:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
215/9:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 100,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
215/10:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
215/11:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
215/12:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
215/13:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
215/14:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
215/15:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
215/16:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
215/17:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
215/18:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
215/19:
a=np.array(sample_batch[0,1])
np.histogram(a)
215/20:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
212/27: br_torch.shape
212/28: date
212/29: %run evaluate.py
212/30: date
212/31: date[1,0]
212/32: date[1][0]
212/33: %run evaluate.py
212/34: %run evaluate.py
212/35: %run evaluate.py
212/36: %run evaluate.py
215/21:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
215/22:
# model = torch.load('model/model_epoch_20.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
215/23:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
215/24:
model = torch.load('model/model_epoch_20.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
215/25:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
215/26:
model = torch.load('model/model_epoch_10.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
215/27:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
215/28:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
215/29:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
215/30:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
215/31:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
215/32:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
215/33:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
215/34:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
215/35:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
215/36:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         y = np.asarray(y).copy()
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
#         y = Image.fromarray(y)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
215/37:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
215/38:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
215/39:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
215/40:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
215/41:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
215/42:
a=np.array(sample_batch[0,1])
np.histogram(a)
215/43:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
212/37: %run evaluate.py
212/38: %run evaluate.py
212/39: %run evaluate.py
215/44:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
215/45:
model = torch.load('model/model_epoch_10.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
215/46:
model = torch.load('model/model_epoch_20.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
215/47:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
215/48:
# model = torch.load('model/model_epoch_20.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
215/49:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
215/50:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        x = np.array(x)
        x /= np.max(x)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        x = Image.fromarray(x)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
215/51:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
215/52:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
215/53:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
215/54:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
215/55:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
        x = np.array(x)
        x = x / np.max(x)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        x = Image.fromarray(x)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
215/56:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
215/57:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
215/58:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
215/59:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
215/60:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
215/61:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
215/62:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
215/63:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
215/64:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        x = Image.fromarray(x)
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        x = x / np.max(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
215/65:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
215/66:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
215/67:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
215/68:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
215/69:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        x = x / np.max(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
215/70:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
215/71:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
215/72:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
215/73:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
215/74:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
215/75:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
215/76:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
215/77:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        x = x / np.max(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
215/78:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
215/79:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
215/80:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
215/81:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
215/82:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
215/83:
a=np.array(sample_batch[0,1])
np.histogram(a)
215/84:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
215/85:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
215/86:
# model = torch.load('model/model_epoch_20.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
215/87:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
215/88:
model = torch.load('model/model_epoch_14.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
215/89:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
215/90:
model = torch.load('model/model_epoch_10.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
215/91:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
215/92:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
#         y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
215/93:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
215/94:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
215/95:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
215/96:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
215/97:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
215/98:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
215/99:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
215/100:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
215/101:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
215/102:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
215/103:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,1].cpu())
    plt.colorbar()
215/104:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
215/105:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
215/106:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
215/107:
model = torch.load('model/model_epoch_10.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
215/108:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
215/109:
model = torch.load('model/model_epoch_6.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
215/110:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
215/111:
model = torch.load('model/model_epoch_16.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
215/112:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
215/113:
# model = torch.load('model/model_epoch_16.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
215/114:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
215/115:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
215/116:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
215/117:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
215/118:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 32,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 32, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
215/119:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
215/120:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
215/121:
a=np.array(sample_batch[0,1])
np.histogram(a)
215/122:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
215/123:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
215/124:
# model = torch.load('model/model_epoch_16.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
215/125:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
215/126:
model = torch.load('model/model_epoch_12.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
215/127:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
215/128:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
215/129:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
215/130:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
215/131:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 128, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
215/132:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
215/133:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
215/134:
a=np.array(sample_batch[0,1])
np.histogram(a)
215/135:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
215/136:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
215/137:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
215/138:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
215/139:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 128, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0001,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
215/140:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
215/141:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
215/142:
a=np.array(sample_batch[0,1])
np.histogram(a)
215/143:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
218/1:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
218/2:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
218/3:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
218/4:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 128, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0001,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
218/5:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
218/6:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
218/7:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
218/8:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 128, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0001,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
219/1:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
219/2:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
219/3:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
219/4:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 128, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0001,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
219/5:
import os
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
219/6:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
219/7:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
219/8:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 128, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0001,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
219/9:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 128, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0001,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
219/10:
import os
%matplotlib inline
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
219/11:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
219/12:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
219/13:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 128, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0001,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
219/14:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/15:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
219/16:
a=np.array(sample_batch[0,1])
np.histogram(a)
219/17:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
219/18:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
219/19:
# model = torch.load('model/model_epoch_12.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/20:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/21:
import os
%matplotlib inline
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>0]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
219/22:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
219/23:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
#         transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
219/24:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
219/25:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/26:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
219/27:
a=np.array(sample_batch[0,1])
np.histogram(a)
219/28:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
219/29:
import os
%matplotlib inline
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
219/30:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
219/31:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
219/32:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 32,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
219/33:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/34:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
219/35:
a=np.array(sample_batch[0,1])
np.histogram(a)
219/36:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
219/37:
model = torch.load('model/model_epoch_8.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/38:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/39:
import os
%matplotlib inline
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
219/40:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
219/41:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
219/42:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
219/43:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/44:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
219/45:
a=np.array(sample_batch[0,1])
np.histogram(a)
219/46:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
219/47:
import os
%matplotlib inline
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
219/48:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
219/49:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
219/50:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 50,# Number of training epochs.
    'lr' : 0.0001,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
219/51:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/52:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
219/53:
a=np.array(sample_batch[0,1])
np.histogram(a)
219/54:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
219/55:
plt.plot(G_losses)
plt.ylim([0,2])
219/56:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
219/57:
# model = torch.load('model/model_epoch_8.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/58:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/59:
# model = torch.load('model/model_epoch_8.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/60:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/61:
model = torch.load('model/model_epoch_16.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/62:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/63:
model = torch.load('model/model_epoch_6.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/64:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/65:
model = torch.load('model/model_epoch_10.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/66:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/67:
model = torch.load('model/model_epoch_12.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/68:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/69:
model = torch.load('model/model_epoch_14.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/70:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/71:
model = torch.load('model/model_epoch_16.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/72:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/73:
model = torch.load('model/model_epoch_18.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/74:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/75:
model = torch.load('model/model_epoch_20.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/76:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/77:
model = torch.load('model/model_epoch_46.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/78:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/79:
model = torch.load('model/model_epoch_40.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/80:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/81:
model = torch.load('model/model_epoch_30.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/82:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/83:
model = torch.load('model/model_epoch_20.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/84:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/85:
model = torch.load('model/model_epoch_14.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/86:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/87:
import os
%matplotlib inline
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
219/88:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
219/89:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
219/90:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 240,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 50,# Number of training epochs.
    'lr' : 0.0001,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
219/91:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/92:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
219/93:
a=np.array(sample_batch[0,1])
np.histogram(a)
219/94:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model240_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model240_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
219/95:
model = torch.load('model/model_epoch_0.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/96:
model = torch.load('model/model240_epoch_0.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/97:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/98:
import os
%matplotlib inline
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
219/99:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
219/100:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
219/101:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 32, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 30,# Number of training epochs.
    'lr' : 0.0001,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
219/102:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/103:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
219/104:
a=np.array(sample_batch[0,1])
np.histogram(a)
219/105:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
219/106:
model = torch.load('model/model_epoch_8.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/107:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/108:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/109:
model = torch.load('model/model_epoch_10.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/110:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/111:
model = torch.load('model/model_epoch_6.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/112:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/113:
model = torch.load('model/model_epoch_4.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/114:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/115:
model = torch.load('model/model_epoch_10.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/116:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/117:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
219/118:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/119:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
219/120:
a=np.array(sample_batch[0,1])
np.histogram(a)
219/121:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
219/122:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
219/123:
# model = torch.load('model/model_epoch_10.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/124:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/125:
model = torch.load('model/model_epoch_6.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/126:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/127:
import os
%matplotlib inline
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
219/128:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
219/129:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
219/130:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 32, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 10,# Number of training epochs.
    'lr' : 0.0001,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
219/131:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/132:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
219/133:
a=np.array(sample_batch[0,1])
np.histogram(a)
219/134:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
219/135:
# Animation showing the improvements of the generator.
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0))[:,:,0], animated=True, cmap='gray')] for i in img_list]
anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
plt.show()
anim.save('celeba.gif', dpi=80, writer='imagemagick')
219/136:
# model = torch.load('model/model_epoch_6.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/137:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/138:
model = torch.load('model/model_epoch_8.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/139:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/140:
import os
%matplotlib inline
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
219/141:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
219/142:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
219/143:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 128, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
219/144:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/145:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
219/146:
a=np.array(sample_batch[0,1])
np.histogram(a)
219/147:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
219/148:
# model = torch.load('model/model_epoch_8.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/149:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/150:
model = torch.load('model/model_epoch_14.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/151:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/152:
model = torch.load('model/model_epoch_10.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/153:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/154:
model = torch.load('model/model_epoch_6.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/155:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/156:
import os
%matplotlib inline
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
219/157:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
219/158:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
219/159:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 128,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
219/160:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/161:
for i in range(num_images):
    plt.figure()
    plt.imshow(sample_batch[i,0].cpu())
    plt.colorbar()
219/162:
a=np.array(sample_batch[0,1])
np.histogram(a)
219/163:


# Create the generator.
netG = Generator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netG.apply(weights_init)
# Print the model.
print(netG)

# Create the discriminator.
netD = Discriminator(params).to(device)
# Apply the weights_init() function to randomly initialize all
# weights to mean=0.0, stddev=0.2
netD.apply(weights_init)
# Print the model.
print(netD)
netD.eval()

# Binary Cross Entropy loss function.
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, params['nz'], 1, 1, device=device)

real_label = 1
fake_label = 0

# Optimizer for the discriminator.
optimizerD = optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))
# Optimizer for the generator.
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], 0.999))

# Stores generated images as training progresses.
img_list = []
# Stores generator losses during training.
G_losses = []
# Stores discriminator losses during training.
D_losses = []

iters = 0

print("Starting Training Loop...")
print("-"*25)

for epoch in tqdm(range(params['nepochs'])):
    for i, data in enumerate(dataloader, 0):
        # Transfer data tensor to GPU/CPU (device)
        real_data = data.to(device)
        # Get batch size. Can be different from params['nbsize'] for last batch in epoch.
        b_size = real_data.size(0)
        
        # Make accumalated gradients of the discriminator zero.
        netD.zero_grad()
        # Create labels for the real data. (label=1)
        label = torch.full((b_size, ), real_label, device=device)
        output = netD(real_data).view(-1)
        output = output.to(torch.float32)
        label = label.to(torch.float32)
        errD_real = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_real.backward()
        D_x = output.mean().item()
        
        # Sample random data from a unit normal distribution.
        noise = torch.randn(b_size, params['nz'], 1, 1, device=device)
        # Generate fake data (images).
        fake_data = netG(noise)
        # Create labels for fake data. (label=0)
        label.fill_(fake_label  )
        # Calculate the output of the discriminator of the fake data.
        # As no gradients w.r.t. the generator parameters are to be
        # calculated, detach() is used. Hence, only gradients w.r.t. the
        # discriminator parameters will be calculated.
        # This is done because the loss functions for the discriminator
        # and the generator are slightly different.
        output = netD(fake_data.detach()).view(-1)
        errD_fake = criterion(output, label)
        # Calculate gradients for backpropagation.
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        # Net discriminator loss.
        errD = errD_real + errD_fake
        # Update discriminator parameters.
        optimizerD.step()
        
        # Make accumalted gradients of the generator zero.
        netG.zero_grad()
        # We want the fake data to be classified as real. Hence
        # real_label are used. (label=1)
        label.fill_(real_label)
        # No detach() is used here as we want to calculate the gradients w.r.t.
        # the generator this time.
        output = netD(fake_data).view(-1)
        errG = criterion(output, label)
        # Gradients for backpropagation are calculated.
        # Gradients w.r.t. both the generator and the discriminator
        # parameters are calculated, however, the generator's optimizer
        # will only update the parameters of the generator. The discriminator
        # gradients will be set to zero in the next iteration by netD.zero_grad()
        errG.backward()

        D_G_z2 = output.mean().item()
        # Update generator parameters.
        optimizerG.step()

        # Check progress of training.
        if i%50 == 0:
            print(torch.cuda.is_available())
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, params['nepochs'], i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save the losses for plotting.
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on a fixed noise.
        if (iters % 100 == 0) or ((epoch == params['nepochs']-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_data = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake_data, padding=2, normalize=True))

        iters += 1

    # Save the model.
    if epoch % params['save_epoch'] == 0:
        torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_epoch_{}.pth'.format(epoch))

# Save the final trained model.
torch.save({
            'generator' : netG.state_dict(),
            'discriminator' : netD.state_dict(),
            'optimizerG' : optimizerG.state_dict(),
            'optimizerD' : optimizerD.state_dict(),
            'params' : params
            }, 'model/model_final.pth')

# Plot the training losses.
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
219/164:
# model = torch.load('model/model_epoch_6.pth')
model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/165:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/166:
model = torch.load('model/model_epoch_16.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/167:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/168:
model = torch.load('model/model_epoch_12.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/169:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/170:
model = torch.load('model/model_epoch_6.pth')
# model = torch.load('model/model_final.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/171:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/172:
# model = torch.load('model/model_epoch_6.pth')
# model = torch.load('model/model_final.pth')
model = torch.load('model/model64_best.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/173:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
219/174:
# model = torch.load('model/model_epoch_6.pth')
# model = torch.load('model/model_final.pth')
model = torch.load('model/model64_best.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/175:
# model = torch.load('model/model_epoch_6.pth')
# model = torch.load('model/model_final.pth')
model = torch.load('model/model64_best.pth')
netG = Generator(params).to(device)
netG.load_state_dict(model['generator'])
netG.eval()
219/176:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu())
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/177:
for i in range(20):
    plt.figure()
    plt.imshow(out[i,1].cpu())
    plt.colorbar()
219/178:
for i in range(20):
    plt.figure()
    plt.imshow(out[i,0].cpu())
    plt.colorbar()
216/1:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
216/2:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))


print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
216/3:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
216/4:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
216/5:
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
216/6:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
216/7:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
216/8:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
216/9:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i,0].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
216/10:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
216/11:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
216/12:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
221/1:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
221/2:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
221/3:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
221/4:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
221/5:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
221/6:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
222/1:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
219/179:
import os
%matplotlib inline
import glob
import torch
from PIL import Image
from torch.utils import data


class MyDataset(data.Dataset):
    def __init__(self, root, transform_image=None, transform_label=None):
        self.image_paths = []
        self.label_paths = []
        self.transform_image = transform_image
        self.transform_label = transform_label
        self.root = root
        
        for i,filename in enumerate(os.listdir(os.path.join(self.root, 'scans'))):
            self.image_paths += glob.glob(os.path.join(self.root, 'scans' , filename))
            self.label_paths += glob.glob(os.path.join(self.root, 'labels' , filename))
        
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        x = Image.open(image_path)
        y = Image.open(label_path)
#         import ipdb; ipdb.set_trace()
#         y[y>0.5]=255.0
#         y[y<=0.5]=0.0
        if self.transform_image is not None:
            x = self.transform_image(x)
        if self.transform_label is not None:
            y = self.transform_label(y)
        x = np.asarray(x)
        y = np.asarray(y)
        y[y>-1]=1
        new = np.concatenate((x,y), axis=0)
        #new = np.expand_dims(x, axis=0)
        #new = Image.fromarray(np.uint8(new))
        
        
        return new
    
    def __len__(self):
        return len(self.image_paths)
219/180:
# transform=transforms.Compose([
#                         transforms.Resize(params['imsize']),
#                         transforms.ToTensor()
#                     ])
# dataset = MyDataset(root=root, transform_image=transform, transform_label=transform)
# dataloader = torch.utils.data.DataLoader(dataset,
#         batch_size=len(dataset),
#         shuffle=True)
# data = next(iter(dataloader))
# traindata_mean = data.mean(dim=(0,2,3))
# traindata_std = data.std(dim=(0,2,3))
# print('mean: {}'.format(traindata_mean.numpy()))
# print('std: {}'.format(traindata_std.numpy()))
219/181:
import torch
import torchvision.transforms as transforms
import torchvision.datasets as dset

# Directory containing the data.
root = '../dataset/slices_2d/training'

def get_celeba(params):
    """
    Loads the dataset and applies proproccesing steps to it.
    Returns a PyTorch DataLoader.
    """
    # Data proprecessing.
    transform_image = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])
    transform_label = transforms.Compose([
        transforms.Resize(params['imsize']),
        transforms.ToTensor(),
        transforms.Normalize(mean=0.5,std=0.5)
    ])

    # Create the dataset.
    dataset = MyDataset(root=root, transform_image=transform_image, transform_label=transform_label)
    print(f'Dataset consists of {len(dataset)} images')

    # Create the dataloader.
    dataloader = torch.utils.data.DataLoader(dataset,
        batch_size=params['bsize'],
        shuffle=True)

    return dataloader
219/182:
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.utils as vutils
import numpy as np
import tkinter
import matplotlib
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import random

from dcgan import weights_init, Generator, Discriminator

# Set random seed for reproducibility.
# seed = 369
# random.seed(seed)
# torch.manual_seed(seed)
# print("Random Seed: ", seed)

# Parameters to define the model.
params = {
    "bsize" : 128,# Batch size during training.
    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.
    'nc' : 2,# Number of channles in the training images. For coloured images this is 3.
    'nz' : 100,# Size of the Z latent vector (the input to the generator).
    'ngf' : 64,# Size of feature maps in the generator. The depth will be multiples of this.
    'ndf' : 64, # Size of features maps in the discriminator. The depth will be multiples of this.
    'nepochs' : 20,# Number of training epochs.
    'lr' : 0.0002,# Learning rate for optimizers
    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer
    'save_epoch' : 2}# Save step.

# Use GPU is available else use CPU.
device = torch.device("cuda:0" if(torch.cuda.is_available()) else "cpu")
print(device, " will be used.\n")
219/183:
%matplotlib inline
# Get the data.
dataloader = get_celeba(params)
num_images = 5
# Plot the training images.
sample_batch = next(iter(dataloader))
print(sample_batch.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(sample_batch[i,0].cpu())
    ax[1,i].imshow(sample_batch[i,1].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/2:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/3:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
222/4:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/5:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
222/6:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
# %matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
222/7:
%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
222/8:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/9:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
222/10:
%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self, index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
222/11:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/12:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
222/13:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/14:
transform_image = transforms.Compose([
    transforms.Resize(params['imsize']),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
222/15:
import torch
import torchvision.transforms as transforms
transform_image = transforms.Compose([
    transforms.Resize(params['imsize']),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
222/16:
import torch
import torchvision.transforms as transforms
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
222/17:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/18:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/19:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= self.transform(x)
            y= self.transform(y)
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
222/20:
import torch
import torchvision.transforms as transforms
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
222/21:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/22:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
222/23:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/24:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= self.transform(Image.fromarray(np.uint8(x))
            y= self.transform(Image.fromarray(np.uint8(y))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
222/25:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= self.transform(Image.fromarray(np.uint8(x)))
            y= self.transform(Image.fromarray(np.uint8(y)))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
222/26:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
222/27:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/28:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
222/29:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
222/30:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/31:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/32:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
222/33:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
222/34:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/35:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/36:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
222/37:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/38:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
222/39:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
222/40:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/41:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/42:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i,0].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/43:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i,0].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
222/44:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i,0].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/184: out
219/185: out.shape
219/186: amo=np.array(out.cpu())
219/187:
amo=np.array(out.cpu())
amo.shape
219/188:
amo=np.array(out.cpu())
amo[0,0].max()
219/189:
amo=np.array(out.cpu())
amo[0,1].max()
219/190:
amo=np.array(out.cpu())
amo.shape
219/191:
amo=np.array(out.cpu())
amo[0,0].max()
219/192:
amo=np.array(out.cpu())
amo[1,0].max()
219/193:
amo=np.array(out.cpu())
amo[2,0].max()
219/194:
amo=np.array(out.cpu())
amo[3,0].max()
219/195:
amo=np.array(out.cpu())
amo[:,0].max()
219/196:
amo=np.array(out.cpu())
amo[:,0].min()
219/197:
amo=np.array(out.cpu())
amo = amo/2 + 0.5
amo = amo.astype(uint8)
amo[0,0].max()
219/198:
amo=np.array(out.cpu())
amo = amo/2 + 0.5
amo = amo.astype(npuint8)
amo[0,0].max()
219/199:
amo=np.array(out.cpu())
amo = amo/2 + 0.5
amo = amo.astype(np.uint8)
amo[0,0].max()
219/200:
amo=np.array(out.cpu())
amo = amo/2 + 0.5
amo = amo.astype(np.uint8)
amo[0,0].min()
219/201:
amo=np.array(out.cpu())
amo = (amo/2 + 0.5)*255
amo = amo.astype(np.uint8)
amo[0,0].min()
219/202:
amo=np.array(out.cpu())
amo = (amo/2. + 0.5)*255
amo = amo.astype(np.uint8)
amo[0,0].min()
219/203:
amo=np.array(out.cpu())
amo = (amo/2. + 0.5)*255
amo = amo.astype(np.uint8)
amo[1,0].min()
219/204:
amo=np.array(out.cpu())
amo = (amo/2. + 0.5)*255
amo = amo.astype(np.uint8)
amo[0,0].max()
219/205:
amo=np.array(out.cpu())
amo = (amo/2. + 0.5)*255
amo = amo.astype(np.uint8)
amo[1,0].max()
219/206:
amo=np.array(out.cpu())
amo = (amo/2. + 0.5)*255
amo = amo.astype(np.uint8)
amo[2,0].max()
219/207:
amo=np.array(out.cpu())
amo = (amo/2. + 0.5)*255
amo = amo.astype(np.uint8)
amo[3,0].max()
219/208:
for i in range(20):
    plt.figure()
    plt.imshow(out[i,1].cpu())
    plt.colorbar()
219/209:
for i in range(20):
    plt.figure()
    plt.imshow(out[i,1].cpu()>0)
    plt.colorbar()
219/210:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu()>0)
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
222/45:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        #x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
222/46:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
222/47:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i,0].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/211:
amo=np.array(out.cpu())
amo[:,1] = amo[:,1]>0 
amo = (amo/2. + 0.5)*255
amo = amo.astype(np.uint8)
amo[3,0].max()
222/48:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
222/49:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
223/1:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        #x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
219/212:
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu()>0)
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
223/2:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        #x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
219/213:
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(amo[i,0])
    ax[i,1].imshow(amo[i,1]
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/214:
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(amo[i,0])
    ax[i,1].imshow(amo[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/215:
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(amo[i,0])
    ax[i,1].imshow(amo[i,1])
    plt.colorbar()
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/216:
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    i1=ax[i,0].imshow(amo[i,0])
    i2=ax[i,1].imshow(amo[i,1])
    i1.colorbar()
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/217:
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(amo[i,0])
    ax[i,1].imshow(amo[i,1])
    fig.colorbar(ax=ax[i,0])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/218:
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    i1=ax[i,0].imshow(amo[i,0])
    i2=ax[i,1].imshow(amo[i,1])
    fig.colorbar(i1,ax=ax[i,0])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
223/3:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
219/219:
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    i1=ax[i,0].imshow(amo[i,0])
    i2=ax[i,1].imshow(amo[i,1])
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
223/4:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
223/5:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
223/6:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
223/7:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        #x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
223/8:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
223/9:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i,0].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
223/10:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
223/11:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
223/12:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
223/13:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
223/14:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
219/220:
amo=np.array(out.cpu())
amo[:,1] = amo[:,1]>0 
amo = (amo/2. + 0.5)
amo[:,0] *= 255
amo = amo.astype(np.uint8)
amo[3,0].max()
219/221:
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    i1=ax[i,0].imshow(amo[i,0])
    i2=ax[i,1].imshow(amo[i,1])
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
223/15:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                print(target.shape)
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
223/16:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            print(target.shape)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
223/17:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
223/18:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            #print(target.shape)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
223/19:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
223/20:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
223/21:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
224/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        #x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
224/2:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
224/3:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i,0].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
224/4:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
224/5:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
224/6:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
224/7:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
224/8:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
224/9:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            print(x.shape)
            print(y.shape)
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
224/10:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
225/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        #x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
225/2:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
225/3:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i,0].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
225/4:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
225/5:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
225/6:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
225/7:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            print(x.shape)
            print(y.shape)
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
225/8:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
226/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
226/2:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
226/3:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i,0].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
226/4:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
226/5:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
226/6:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
226/7:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            print(x.shape)
            print(y.shape)
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
226/8:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
226/9:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        print(y.shape)
        #y = np.squeeze()
        #y = y.unsqueeze(0)
        return x, y
219/222: '{:04d}'.format(3)
226/10:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
226/11:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/223: '{:05d}'.format(3)
219/224: '{:05d}'.format(13254)
226/12:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
226/13:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        print(y.shape)
        #y = np.squeeze()
        #y = y.unsqueeze(0)
        return x, y
226/14:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
226/15:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
226/16:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
226/17:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        print(y.shape)
        y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
226/18:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
226/19:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
226/20:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        #x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
226/21:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
226/22:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
226/23:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
226/24:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
226/25:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
226/26:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            print(x.shape)
            print(y.shape)
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
226/27:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
227/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        #x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
227/2:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
227/3:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
227/4:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
227/5:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
227/6:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
227/7:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            print(x.shape)
            print(y.shape)
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
227/8:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
228/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        #x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
228/2:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
228/3:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
228/4:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
228/5:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
228/6:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
228/7:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            print(x.shape)
            print(y.shape)
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
228/8:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
228/9:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        #x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
228/10:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
228/11:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/225:
import cv2
data_path = '/home/kamo/projects/auggan/dataset/slices_2d/training/'
num_images = 3
bsize = 100
for i in range(num_images//bsize):
    print(f'Batch {i+1}/{num_images//bsize}')
    noise = torch.randn(bsize,100,1,1, device=device)
    out = netG(noise)
    amo=np.array(out.cpu())
    amo[:,1] = amo[:,1]>0 #binarize the segmentations
    amo = (amo/2. + 0.5) # normalize everything back to [0,1] from [-1,1]
    amo[:,0] *= 255 # scale the brain images to [0,255], keep labels as (0,1)
    amo = amo.astype(np.uint8)
    for j in range(bsize):
        scanpath = data_path+'scans/gan_{:05d}.jpg'.format(i*bsize+j+1)
        labelpath = data_path+'labels/gan_{:05d}.jpg'.format(i*bsize+j+1)
        cv2.imwrite(scanpath, amo[i,0])
        cv2.imwrite(labelpath, amo[i,1])
228/12:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
228/13:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
228/14:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
228/15:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
228/16:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
219/226:
from skimage.io import imread
xx = imread(data_path+'scans/gan_00001.jpg')
plt.imshow(xx)
plt.colorbar()
219/227:
import cv2
data_path = '/home/kamo/projects/auggan/dataset/slices_2d/training/'
num_images = 200
bsize = 100
for i in range(num_images//bsize):
    print(f'Batch {i+1}/{num_images//bsize}')
    noise = torch.randn(bsize,100,1,1, device=device)
    out = netG(noise)
    amo=np.array(out.cpu())
    amo[:,1] = amo[:,1]>0 #binarize the segmentations
    amo = (amo/2. + 0.5) # normalize everything back to [0,1] from [-1,1]
    amo[:,0] *= 255 # scale the brain images to [0,255], keep labels as (0,1)
    amo = amo.astype(np.uint8)
    for j in range(bsize):
        scanpath = data_path+'scans/gan_{:05d}.jpg'.format(i*bsize+j+1)
        labelpath = data_path+'labels/gan_{:05d}.jpg'.format(i*bsize+j+1)
        cv2.imwrite(scanpath, amo[i,0])
        cv2.imwrite(labelpath, amo[i,1])
219/228:
import cv2
data_path = '/home/kamo/projects/auggan/dataset/slices_2d/training/'
num_images = 200
bsize = 100
for i in range(num_images//bsize):
    print(f'Batch {i+1}/{num_images//bsize}')
    noise = torch.randn(bsize,100,1,1, device=device)
    out = netG(noise)
    amo=out.cpu().detach().numpy()
    amo[:,1] = amo[:,1]>0 #binarize the segmentations
    amo = (amo/2. + 0.5) # normalize everything back to [0,1] from [-1,1]
    amo[:,0] *= 255 # scale the brain images to [0,255], keep labels as (0,1)
    amo = amo.astype(np.uint8)
    for j in range(bsize):
        scanpath = data_path+'scans/gan_{:05d}.jpg'.format(i*bsize+j+1)
        labelpath = data_path+'labels/gan_{:05d}.jpg'.format(i*bsize+j+1)
        cv2.imwrite(scanpath, amo[i,0])
        cv2.imwrite(labelpath, amo[i,1])
219/229:
from skimage.io import imread
xx = imread(data_path+'scans/gan_00001.jpg')
plt.imshow(xx)
plt.colorbar()
219/230:
from skimage.io import imread
xx = imread(data_path+'scans/gan_00002.jpg')
plt.imshow(xx)
plt.colorbar()
228/17:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
228/18:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
228/19:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
229/1:
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data
%matplotlib inline


class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
219/231:
from skimage.io import imread
xx = imread(data_path+'scans/gan_00002.jpg')
yy = imread(data_path+'labels/gan_00002.jpg')
fig, ax = plt.subplots(2, figsize=(10,5*num_images))
plt.gray()
i1=ax[0].imshow(amo[0])
i2=ax[1].imshow(amo[1])
fig.colorbar(i1,ax=ax[0])
fig.colorbar(i2,ax=ax[1])
ax[0].set_title('GAN Image')
ax[1].set_title('GAN Label')
229/2:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
229/3:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
229/4:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
229/5:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
229/6:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
229/7:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
219/232:
from skimage.io import imread
xx = imread(data_path+'scans/gan_00002.jpg')
yy = imread(data_path+'labels/gan_00002.jpg')
fig, ax = plt.subplots(2, figsize=(10,5*num_images))
plt.gray()
i1=ax[0].imshow(xx)
i2=ax[1].imshow(yy)
fig.colorbar(i1,ax=ax[0])
fig.colorbar(i2,ax=ax[1])
ax[0].set_title('GAN Image')
ax[1].set_title('GAN Label')
229/8:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            print(x.shape)
            print(y.shape)
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
229/9:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
219/233: xx.shape
219/234: yy.shape
219/235:
from skimage.io import imread
xx = imread(data_path+'scans/gan_00002.jpg')
yy = imread(data_path+'labels/gan_00002.jpg')
fig, ax = plt.subplots(2, figsize=(10,10))
plt.gray()
i1=ax[0].imshow(xx)
i2=ax[1].imshow(yy)
fig.colorbar(i1,ax=ax[0])
fig.colorbar(i2,ax=ax[1])
ax[0].set_title('GAN Image')
ax[1].set_title('GAN Label')
219/236:
from skimage.io import imread
xx = imread(data_path+'scans/gan_00002.jpg')
yy = imread(data_path+'labels/gan_00002.jpg')
fig, ax = plt.subplots(1,2, figsize=(10,10))
plt.gray()
i1=ax[0].imshow(xx)
i2=ax[1].imshow(yy)
fig.colorbar(i1,ax=ax[0])
fig.colorbar(i2,ax=ax[1])
ax[0].set_title('GAN Image')
ax[1].set_title('GAN Label')
219/237:
from skimage.io import imread
xx = imread(data_path+'scans/gan_00002.jpg')
yy = imread(data_path+'labels/gan_00002.jpg')
fig, ax = plt.subplots(1,2, figsize=(10,5))
plt.gray()
i1=ax[0].imshow(xx)
i2=ax[1].imshow(yy)
fig.colorbar(i1,ax=ax[0])
fig.colorbar(i2,ax=ax[1])
ax[0].set_title('GAN Image')
ax[1].set_title('GAN Label')
219/238:
from skimage.io import imread
xx = imread(data_path+'scans/gan_00002.jpg')
yy = imread(data_path+'labels/gan_00002.jpg')
fig, ax = plt.subplots(1,2, figsize=(10,4))
plt.gray()
i1=ax[0].imshow(xx)
i2=ax[1].imshow(yy)
fig.colorbar(i1,ax=ax[0])
fig.colorbar(i2,ax=ax[1])
ax[0].set_title('GAN Image')
ax[1].set_title('GAN Label')
219/239:
from skimage.io import imread

xx = imread(data_path+'scans/gan_00022.jpg')
yy = imread(data_path+'labels/gan_00022.jpg')
fig, ax = plt.subplots(1,2, figsize=(10,4))
plt.gray()
i1=ax[0].imshow(xx)
i2=ax[1].imshow(yy)
fig.colorbar(i1,ax=ax[0])
fig.colorbar(i2,ax=ax[1])
ax[0].set_title('GAN Image')
ax[1].set_title('GAN Label')
219/240:
from skimage.io import imread

xx = imread(data_path+'scans/gan_00222.jpg')
yy = imread(data_path+'labels/gan_00222.jpg')
fig, ax = plt.subplots(1,2, figsize=(10,4))
plt.gray()
i1=ax[0].imshow(xx)
i2=ax[1].imshow(yy)
fig.colorbar(i1,ax=ax[0])
fig.colorbar(i2,ax=ax[1])
ax[0].set_title('GAN Image')
ax[1].set_title('GAN Label')
219/241:
from skimage.io import imread

xx = imread(data_path+'scans/gan_00112.jpg')
yy = imread(data_path+'labels/gan_00112.jpg')
fig, ax = plt.subplots(1,2, figsize=(10,4))
plt.gray()
i1=ax[0].imshow(xx)
i2=ax[1].imshow(yy)
fig.colorbar(i1,ax=ax[0])
fig.colorbar(i2,ax=ax[1])
ax[0].set_title('GAN Image')
ax[1].set_title('GAN Label')
219/242:
from skimage.io import imread

xx = imread(data_path+'scans/gan_00132.jpg')
yy = imread(data_path+'labels/gan_00132.jpg')
fig, ax = plt.subplots(1,2, figsize=(10,4))
plt.gray()
i1=ax[0].imshow(xx)
i2=ax[1].imshow(yy)
fig.colorbar(i1,ax=ax[0])
fig.colorbar(i2,ax=ax[1])
ax[0].set_title('GAN Image')
ax[1].set_title('GAN Label')
219/243:
import cv2
data_path = '/home/kamo/projects/auggan/dataset/slices_2d/training/'
num_images = 20000
bsize = 100
for i in range(num_images//bsize):
    print(f'Batch {i+1}/{num_images//bsize}')
    noise = torch.randn(bsize,100,1,1, device=device)
    out = netG(noise)
    amo=out.cpu().detach().numpy()
    amo[:,1] = amo[:,1]>0 #binarize the segmentations
    amo = (amo/2. + 0.5) # normalize everything back to [0,1] from [-1,1]
    amo[:,0] *= 255 # scale the brain images to [0,255], keep labels as (0,1)
    amo = amo.astype(np.uint8)
    for j in range(bsize):
        scanpath = data_path+'scans/gan_{:05d}.jpg'.format(i*bsize+j+1)
        labelpath = data_path+'labels/gan_{:05d}.jpg'.format(i*bsize+j+1)
        cv2.imwrite(scanpath, amo[i,0])
        cv2.imwrite(labelpath, amo[i,1])
230/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
230/2:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
230/3:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
230/4:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
219/244:
from skimage.io import imread

xx = imread(data_path+'scans/gan_00132.jpg')
yy = imread(data_path+'labels/gan_00132.jpg')
fig, ax = plt.subplots(1,2, figsize=(10,4))
plt.gray()
i1=ax[0].imshow(xx)
i2=ax[1].imshow(yy)
fig.colorbar(i1,ax=ax[0])
fig.colorbar(i2,ax=ax[1])
ax[0].set_title('GAN Image')
ax[1].set_title('GAN Label')
230/5:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/245:
from skimage.io import imread

xx = imread(data_path+'scans/gan_00133.jpg')
yy = imread(data_path+'labels/gan_00133.jpg')
fig, ax = plt.subplots(1,2, figsize=(10,4))
plt.gray()
i1=ax[0].imshow(xx)
i2=ax[1].imshow(yy)
fig.colorbar(i1,ax=ax[0])
fig.colorbar(i2,ax=ax[1])
ax[0].set_title('GAN Image')
ax[1].set_title('GAN Label')
219/246:
from skimage.io import imread

xx = imread(data_path+'scans/gan_00134.jpg')
yy = imread(data_path+'labels/gan_00134.jpg')
fig, ax = plt.subplots(1,2, figsize=(10,4))
plt.gray()
i1=ax[0].imshow(xx)
i2=ax[1].imshow(yy)
fig.colorbar(i1,ax=ax[0])
fig.colorbar(i2,ax=ax[1])
ax[0].set_title('GAN Image')
ax[1].set_title('GAN Label')
219/247:
from skimage.io import imread
num_images=10
xx = imread(data_path+'scans/gan_00134.jpg')
yy = imread(data_path+'labels/gan_00134.jpg')
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images)
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/248:
from skimage.io import imread
num_images=10
xx = imread(data_path+'scans/gan_00134.jpg')
yy = imread(data_path+'labels/gan_00134.jpg')
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/249:
from skimage.io import imread
num_images=10
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    jj = np.random.randint(100)
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/250:
from skimage.io import imread
num_images=10
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(100)
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/251:
from skimage.io import imread
num_images=10
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(99)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/252:
import cv2
data_path = '/home/kamo/projects/auggan/dataset/slices_2d/training/'
num_images = 20000
bsize = 100
for i in range(num_images//bsize):
    print(f'Batch {i+1}/{num_images//bsize}')
    noise = torch.randn(bsize,100,1,1, device=device)
    out = netG(noise)
    amo=out.cpu().detach().numpy()
    amo[:,1] = amo[:,1]>=0 #binarize the segmentations
    amo = (amo/2. + 0.5) # normalize everything back to [0,1] from [-1,1]
    amo[:,0] *= 255 # scale the brain images to [0,255], keep labels as (0,1)
    amo = amo.astype(np.uint8)
    for j in range(bsize):
        scanpath = data_path+'scans/gan_{:05d}.jpg'.format(i*bsize+j+1)
        labelpath = data_path+'labels/gan_{:05d}.jpg'.format(i*bsize+j+1)
        cv2.imwrite(scanpath, amo[j,0])
        cv2.imwrite(labelpath, amo[j,1])
219/253:
from skimage.io import imread
num_images=10
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
230/6:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
230/7:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
230/8:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
230/9:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
230/10:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
230/11:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
230/12:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/254:
from skimage.io import imread
num_images=10
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
230/13:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
230/14:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        x = x / 255.
        
        # Preprocessing
        if self.transform is not None:
            x, y = self.transform(x, y)

        # Typecasting
        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        x = np.expand_dims(x, 0)
        #y = y.unsqueeze(0)
        return x, y
230/15:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
230/16:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
230/17:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
230/18:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
230/19:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
230/20:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            print(x.shape)
            print(y.shape)
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
230/21:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
230/22:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
230/23:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
230/24:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
230/25:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
230/26:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
230/27:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
219/255:
import cv2
data_path = '/home/kamo/projects/auggan/dataset/slices_2d/training_gan/'
num_images = 20000
bsize = 100
for i in range(num_images//bsize):
    print(f'Batch {i+1}/{num_images//bsize}')
    noise = torch.randn(bsize,100,1,1, device=device)
    out = netG(noise)
    amo=out.cpu().detach().numpy()
    amo[:,1] = amo[:,1]>=0 #binarize the segmentations
    amo[:,0] = (amo[:,0]/2. + 0.5)*255 # normalize images back to [0,255] from [-1,1]
    amo = amo.astype(np.uint8)
    for j in range(bsize):
        scanpath = data_path+'scans/gan_{:05d}.jpg'.format(i*bsize+j+1)
        labelpath = data_path+'labels/gan_{:05d}.jpg'.format(i*bsize+j+1)
        cv2.imwrite(scanpath, amo[j,0])
        cv2.imwrite(labelpath, amo[j,1])
231/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
231/2:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
231/3:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
219/256:
from skimage.io import imread
num_images=10
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
231/4:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
231/5:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
231/6:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
231/7:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
231/8:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            print(x.shape)
            print(y.shape)
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
219/257:
from skimage.io import imread
num_images=10
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
231/9:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
231/10:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
231/11:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
231/12:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
231/13:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
231/14:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
219/258:
amo=np.array(out.cpu())
amo[:,1] = amo[:,1]>0 
amo = (amo/2. + 0.5)
amo[:,0] *= 255
amo = amo.astype(np.uint8)
amo[3,0].max()
231/15:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
232/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
219/259:
amo=out.cpu().detach().numpy()
amo[:,1] = amo[:,1]>0 
amo = (amo/2. + 0.5)
amo[:,0] *= 255
amo = amo.astype(np.uint8)
amo[3,0].max()
232/2:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
232/3:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
232/4:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
232/5:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
219/260:
amo=out.cpu().detach().numpy()
amo[:,1] = amo[:,1]>0 
amo = (amo/2. + 0.5)
amo[:,0] *= 255
amo = amo.astype(np.uint8)
amo[:,1].max()
232/6:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
232/7:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            print(x.shape)
            print(y.shape)
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
232/8:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
219/261:
noise = torch.randn(bsize,100,1,1, device=device)
amo = netG(noise)
amo=amo.cpu().detach().numpy()
amo[:,1] = amo[:,1]>0 
amo = (amo/2. + 0.5)
amo[:,0] *= 255
amo = amo.astype(np.uint8)
amo[:,1].max()
219/262:
noise = torch.randn(bsize,100,1,1, device=device)
amo = netG(noise)
amo=amo.cpu().detach().numpy()
amo[:,1] = amo[:,1]>0 
amo = (amo/2. + 0.5)
amo[:,0] *= 255
amo = amo.astype(np.uint8)
amo[:,1].max()
219/263:
noise = torch.randn(bsize,100,1,1, device=device)
amo = netG(noise)
amo=amo.cpu().detach().numpy()
amo[:,1] = amo[:,1]>0 
amo = (amo/2. + 0.5)
amo[:,0] *= 255
amo = amo.astype(np.uint8)
amo[:,1].max()
219/264:
noise = torch.randn(bsize,100,1,1, device=device)
amo = netG(noise)
amo=amo.cpu().detach().numpy()
amo[:,1] = amo[:,1]>0 
amo = (amo/2. + 0.5)
amo[:,0] *= 255
amo = amo.astype(np.uint8)
amo[:,1].max()
219/265:
noise = torch.randn(bsize,100,1,1, device=device)
amo = netG(noise)
amo=amo.cpu().detach().numpy()
amo[:,1] = amo[:,1]>0 
amo = (amo/2. + 0.5)
amo[:,0] *= 255
amo = amo.astype(np.uint8)
amo[:,1].max()
219/266:
noise = torch.randn(bsize,100,1,1, device=device)
amo = netG(noise)
amo=amo.cpu().detach().numpy()
amo[:,1] = amo[:,1]>0 
amo = (amo/2. + 0.5)
amo[:,0] *= 255
amo = amo.astype(np.uint8)
amo[:,1].max()
219/267:
noise = torch.randn(bsize,100,1,1, device=device)
amo = netG(noise)
amo=amo.cpu().detach().numpy()
amo[:,1] = amo[:,1]>0 
amo = (amo/2. + 0.5)
amo[:,0] *= 255
amo = amo.astype(np.uint8)
amo[:,1].max()
219/268:
noise = torch.randn(bsize,100,1,1, device=device)
amo = netG(noise)
amo=amo.cpu().detach().numpy()
amo[:,1] = amo[:,1]>0 
amo = (amo/2. + 0.5)
amo[:,0] *= 255
amo = amo.astype(np.uint8)
amo[:,1].max()
219/269:
noise = torch.randn(bsize,100,1,1, device=device)
amo = netG(noise)
amo=amo.cpu().detach().numpy()
amo[:,1] = amo[:,1]>0 
amo = (amo/2. + 0.5)
amo[:,0] *= 255
amo = amo.astype(np.uint8)
amo[:,1].max()
219/270:
noise = torch.randn(bsize,100,1,1, device=device)
amo = netG(noise)
amo=amo.cpu().detach().numpy()
amo[:,1] = amo[:,1]>0 
amo = (amo/2. + 0.5)
amo[:,0] *= 255
amo = amo.astype(np.uint8)
amo[:,1].max()
219/271:
noise = torch.randn(bsize,100,1,1, device=device)
amo = netG(noise)
amo=amo.cpu().detach().numpy()
amo[:,1] = amo[:,1]>0 
amo[:,0] = (amo[:,0]/2. + 0.5)*255
amo = amo.astype(np.uint8)
amo[:,1].max()
219/272:
noise = torch.randn(bsize,100,1,1, device=device)
amo = netG(noise)
amo=amo.cpu().detach().numpy()
amo[:,1] = amo[:,1]>0 
amo[:,0] = (amo[:,0]/2. + 0.5)*255
amo = amo.astype(np.uint8)
np.histaogram(amo[:,1])
219/273:
noise = torch.randn(bsize,100,1,1, device=device)
amo = netG(noise)
amo=amo.cpu().detach().numpy()
amo[:,1] = amo[:,1]>0 
amo[:,0] = (amo[:,0]/2. + 0.5)*255
amo = amo.astype(np.uint8)
np.histogram(amo[:,1])
219/274:
noise = torch.randn(bsize,100,1,1, device=device)
amo = netG(noise)
amo=amo.cpu().detach().numpy()
amo[:,1] = amo[:,1]>0 
amo[:,0] = (amo[:,0]/2. + 0.5)*255
amo = amo.astype(np.uint8)
np.histogram(amo[:,1])
219/275:
noise = torch.randn(bsize,100,1,1, device=device)
amo = netG(noise)
amo=amo.cpu().detach().numpy()
amo[:,1] = amo[:,1]>=0 
amo[:,0] = (amo[:,0]/2. + 0.5)*255
amo = amo.astype(np.uint8)
np.histogram(amo[:,1])
219/276:
noise = torch.randn(bsize,100,1,1, device=device)
amo = netG(noise)
amo=amo.cpu().detach().numpy()
amo[:,1] = amo[:,1]>=0 
amo[:,0] = (amo[:,0]/2. + 0.5)*255
amo = amo.astype(np.uint8)
np.histogram(amo[:,1])
219/277:
noise = torch.randn(bsize,100,1,1, device=device)
amo = netG(noise)
amo=amo.cpu().detach().numpy()
amo[:,1] = amo[:,1]>=0 
amo[:,0] = (amo[:,0]/2. + 0.5)*255
amo = amo.astype(np.uint8)
np.histogram(amo[:,1])
219/278:
import cv2
data_path = '/home/kamo/projects/auggan/dataset/slices_2d/training_gan/'
num_images = 20000
bsize = 100
for i in range(num_images//bsize):
    print(f'Batch {i+1}/{num_images//bsize}')
    noise = torch.randn(bsize,100,1,1, device=device)
    out = netG(noise)
    amo=out.cpu().detach().numpy()
    amo[:,1] = (amo[:,1]>=0) #binarize the segmentations
    amo[:,:] = (amo[:,:]/2. + 0.5)*255 # normalize images back to [0,255] from [-1,1]
    amo = amo.astype(np.uint8)
    for j in range(bsize):
        scanpath = data_path+'scans/gan_{:05d}.jpg'.format(i*bsize+j+1)
        labelpath = data_path+'labels/gan_{:05d}.jpg'.format(i*bsize+j+1)
        cv2.imwrite(scanpath, amo[j,0])
        cv2.imwrite(labelpath, amo[j,1])
219/279:
from skimage.io import imread
num_images=10
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/280:
from skimage.io import imread
num_images=10
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/281:
from skimage.io import imread
num_images=10
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/282:
from skimage.io import imread
num_images=10
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
232/9:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
232/10:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
232/11:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
233/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
233/2:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
233/3:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
233/4:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
233/5:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    #if torch.cuda.is_available():
     #   model.cuda()

print(f'Out: {out.shape}')
233/6:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
233/7:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            print(x.shape)
            print(y.shape)
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
233/8:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
233/9:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
233/10:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
233/11:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
233/12:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
233/13:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
233/14:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
233/15:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
233/16:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            print(x.shape)
            print(y.shape)
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                print(target.shape)
                print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
233/17:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
233/18:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            print(x.shape)
            print(y.shape)
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)

            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
233/19:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
233/20:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            print(x.shape)
            print(y.shape)
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            print("flag")
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
233/21:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
233/22:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            print(x.shape)
            print(y.shape)
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            print("flag")
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels, relaxed=True).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
233/23:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
233/24:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
233/25:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            print(x.shape)
            print(y.shape)
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            print("flag")
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                #F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
233/26:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
234/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
234/2:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
234/3:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
234/4:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
234/5:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    #if torch.cuda.is_available():
     #   model.cuda()

print(f'Out: {out.shape}')
234/6:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
234/7:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            print(x.shape)
            print(y.shape)
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            print("flag")
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
234/8:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
234/9:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
234/10:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            
            print(target.shape)
            print(model.out_channels)
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            print("flag")
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
234/11:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
234/12:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
235/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
235/2:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
235/3:
training_dataset = SegmentationDataSet(dataset='training',transform=None)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
235/4:
validation_dataset = SegmentationDataSet(dataset='validation',transform=None)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
235/5:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    #if torch.cuda.is_available():
     #   model.cuda()

print(f'Out: {out.shape}')
235/6:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
235/7:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            
            print(target.shape)
            print(model.out_channels)
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            print("flag")
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
235/8:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
235/9:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
235/10:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
235/11:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
235/12:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
235/13:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
236/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
236/2:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
236/3:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
236/4:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
236/5:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
236/6:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
236/7:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
236/8:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
236/9:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
236/10:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    #if torch.cuda.is_available():
     #   model.cuda()

print(f'Out: {out.shape}')
236/11:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            
            print(target.shape)
            print(model.out_channels)
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            print("flag")
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
236/12:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
237/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            print(y)
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            print(y)
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
237/2:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
237/3:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/4:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            print(y)
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            print("SA")
            print(y)
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
237/5:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/6:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
237/7:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    #if torch.cuda.is_available():
     #   model.cuda()

print(f'Out: {out.shape}')
237/8:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
237/9:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            
            print(target.shape)
            print(model.out_channels)
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            print("flag")
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
237/10:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            
            print(target.shape)
            print(model.out_channels)
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels, ).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            print("flag")
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
237/11:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            
            print(target.shape)
            print(model.out_channels)
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            print("flag")
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
237/12:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
237/13:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
237/14:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
237/15:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/16:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
237/17:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    #if torch.cuda.is_available():
     #   model.cuda()

print(f'Out: {out.shape}')
237/18:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            
            print(target.shape)
            print(model.out_channels)
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            print("flag")
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
237/19:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            
            print(target.shape)
            print(model.out_channels)
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels, relaxed=True).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            print("flag")
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
237/20:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
237/21:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            print(y)
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            print("SA")
            print(y)
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
237/22:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
237/23:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/24:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            print(y)
            y= np.uint8(np.array(self.transform(Image.fromarray(np.uint8(y)))))
            print("SA")
            print(y)
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
237/25:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
237/26:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/27:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            print(y)
            y= np.uint8(np.array(self.transform(Image.fromarray(np.uint8(y)))))
            print(y.max)
            print("SA")
            print(y)
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
237/28:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
237/29:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/30:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            print(y)
            y= np.uint8(np.array(self.transform(Image.fromarray(np.uint8(y)))))
            print(np.max(y))
            print("SA")
            print(y)
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
237/31:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
237/32:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/33:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            print(y)
            y= np.uint8(np.array(self.transform(Image.fromarray(np.uint8(y)))))
            print(np.amax(y))
            print("SA")
            print(y)
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
237/34:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/35:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/36:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            print(y)
            print(np.amax(y))
            y= np.uint8(np.array(self.transform(Image.fromarray(np.uint8(y)))))
            print(np.amax(y))
            print("SA")
            print(y)
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
237/37:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
237/38:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/39:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
237/40:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/41:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            print(y)
            print(np.amin(y))
            y= np.uint8(np.array(self.transform(Image.fromarray(np.uint8(y)))))
            print(np.amin(y))
            print("SA")
            print(y)
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
237/42:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
237/43:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/44:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            print(y)
            print(np.unique(y))
            y= np.uint8(np.array(self.transform(Image.fromarray(np.uint8(y)))))
            print(np.unique(y))
            print("SA")
            print(y)
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
237/45:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/46:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            print(y)
            print(np.unique(y))
            y= np.uint8(np.array(self.transform(Image.fromarray(np.uint8(y)))))
            print(np.unique(y))
            print("SA")
            print(y)
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
237/47:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
237/48:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/49:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/50:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            print(y)
            print(np.unique(y))
            y= np.uint8(np.array(self.transform(Image.fromarray(np.uint8(y)))))
            print(np.unique(y))
            print("SA")
            print(y)
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
237/51:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            print(y)
            print(np.unique(y))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            print(np.unique(y))
            print("SA")
            print(y)
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
237/52:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5,std=0.5)
    ])
237/53:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/54:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            print(y)
            print(np.unique(y))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            print(np.unique(y))
            print("SA")
            print(y)
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
237/55:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
237/56:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/57:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            print(y)
            print(np.unique(y))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            print(np.unique(y))
            print("SA")
            print(y)
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
237/58:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            print(y)
            print(np.unique(y))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            print(np.unique(y))
            print("SA")
            print(y)
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
237/59:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
237/60:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
237/61:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
238/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):

            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
        for i,folder_name in enumerate(os.listdir(self.label_root)):

            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
238/2:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
238/3:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
238/4:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
238/5:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    #if torch.cuda.is_available():
     #   model.cuda()

print(f'Out: {out.shape}')
238/6:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            
            print(target.shape)
            print(model.out_channels)
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels, relaxed=True).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            print("flag")
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
238/7:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
238/8:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            
            print(target.shape)
            print(model.out_channels)
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            print("flag")
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
238/9:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
238/10:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            
            #print(target.shape)
            #print(model.out_channels)
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
238/11:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
238/12:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=20,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
238/13:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            
            #print(target.shape)
            #print(model.out_channels)
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
238/14:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            
            #print(target.shape)
            #print(model.out_channels)
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
238/15:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=3,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
238/16:
import pathlib

model_name =  'carvana_model_64_dice_3ep_adam.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
238/17:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
238/18:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
238/19:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
238/20:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
238/21:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=10,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
238/22:
import pathlib

model_name =  'carvana_model_64_dice_10ep_adam.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
238/23:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
238/24:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
238/25:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
239/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training' or self.dataset == 'training_gan':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
            
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
            
        if self.dataset == 'training_gan':
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/scans')):
                self.img_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/scans', folder_name))
                
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/labels')):
                self.label_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/labels', folder_name))
                
        
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
239/2:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
239/3:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
239/4:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/5:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/6:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/7:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/8:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/9:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/10:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training' or self.dataset == 'training_gan':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
            
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
            
        if self.dataset == 'training_gan':
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/scans')):
                self.img_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/scans', folder_name))
                
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/labels')):
                self.label_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/labels', folder_name))
                
        
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]
        
        print(input_ID)

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
239/11:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
239/12:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/13:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/14:
training_dataset = SegmentationDataSet(dataset='training_gan',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/15:
training_dataset = SegmentationDataSet(dataset='training_gan',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/16:
training_dataset = SegmentationDataSet(dataset='training_gan',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/17:
training_dataset = SegmentationDataSet(dataset='training_gan',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/18:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training' or self.dataset == 'training_gan':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
            
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
            
        if self.dataset == 'training_gan':
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/scans')):
                self.img_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/scans', folder_name))
                
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/labels')):
                self.label_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/labels', folder_name))
                
        
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]
        
        print(input_ID)

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        print(y)
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
239/19:
training_dataset = SegmentationDataSet(dataset='training_gan',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/20:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training' or self.dataset == 'training_gan':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
            
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
            
        if self.dataset == 'training_gan':
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/scans')):
                self.img_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/scans', folder_name))
                
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/labels')):
                self.label_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/labels', folder_name))
                
        
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]
        
        print(input_ID)

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        print(np.unique(y))
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
239/21:
training_dataset = SegmentationDataSet(dataset='training_gan',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/22:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training' or self.dataset == 'training_gan':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
            
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
            
        if self.dataset == 'training_gan':
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/scans')):
                self.img_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/scans', folder_name))
                
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/labels')):
                self.label_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/labels', folder_name))
                
        
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]
        
        print(input_ID)

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        print(x)
        print(np.unique(y))
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
239/23:
training_dataset = SegmentationDataSet(dataset='training_gan',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/24:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training' or self.dataset == 'training_gan':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
            
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
            
        if self.dataset == 'training_gan':
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/scans')):
                self.img_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/scans', folder_name))
                
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/labels')):
                self.label_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/labels', folder_name))
                
        
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]
        
        print(input_ID)

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        y = y.astype(bool).astype(int)
        print(np.amax(x))
        print(np.unique(y))
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
239/25:
training_dataset = SegmentationDataSet(dataset='training_gan',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/26:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training' or self.dataset == 'training_gan':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
            
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
            
        if self.dataset == 'training_gan':
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/scans')):
                self.img_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/scans', folder_name))
                
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/labels')):
                self.label_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/labels', folder_name))
                
        
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]
        
        print(input_ID)

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        print(np.unique(y))
        y = y.astype(bool).astype(int)
        print(np.unique(y))
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
239/27:
training_dataset = SegmentationDataSet(dataset='training_gan',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/28:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training' or self.dataset == 'training_gan':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
            
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
            
        if self.dataset == 'training_gan':
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/scans')):
                self.img_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/scans', folder_name))
                
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/labels')):
                self.label_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/labels', folder_name))
                
        
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]
        
        if target_ID.startswith('dataset/slices_2d/training_gan') :
            print("Sa")
        
        print(input_ID)

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        print(np.unique(y))
        y = y.astype(bool).astype(int)
        print(np.unique(y))
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
239/29:
training_dataset = SegmentationDataSet(dataset='training_gan',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/30:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training' or self.dataset == 'training_gan':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
            
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
            
        if self.dataset == 'training_gan':
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/scans')):
                self.img_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/scans', folder_name))
                
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/labels')):
                self.label_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/labels', folder_name))
                
        
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]
        
        if target_ID.startswith('dataset/slices_2d/training_gan') :
    
        
        print(input_ID)

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        
        if target_ID.startswith('dataset/slices_2d/training_gan'):
            y = (y >= 220) * y
        
        print(np.unique(y))
        y = y.astype(bool).astype(int)
        print(np.unique(y))
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
239/31:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training' or self.dataset == 'training_gan':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
            
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
            
        if self.dataset == 'training_gan':
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/scans')):
                self.img_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/scans', folder_name))
                
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/labels')):
                self.label_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/labels', folder_name))
                
        
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]
        
        
        print(input_ID)

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        
        if target_ID.startswith('dataset/slices_2d/training_gan'):
            y = (y >= 220) * y
        
        print(np.unique(y))
        y = y.astype(bool).astype(int)
        print(np.unique(y))
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
239/32:
training_dataset = SegmentationDataSet(dataset='training_gan',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
239/33:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training' or self.dataset == 'training_gan':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
            
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
            
        if self.dataset == 'training_gan':
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/scans')):
                self.img_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/scans', folder_name))
                
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/labels')):
                self.label_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/labels', folder_name))
                
        
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]
        
        
        print(input_ID)

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        
        if target_ID.startswith('dataset/slices_2d/training_gan'):
            y = (y >= 220) * y
        
        y = y.astype(bool).astype(int)
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
240/1:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
240/2:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training' or self.dataset == 'training_gan':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
            
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
            
        if self.dataset == 'training_gan':
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/scans')):
                self.img_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/scans', folder_name))
                
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/labels')):
                self.label_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/labels', folder_name))
                
        
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]
        
        
        print(input_ID)

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        
        if target_ID.startswith('dataset/slices_2d/training_gan'):
            y = (y >= 220) * y
        
        y = y.astype(bool).astype(int)
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
240/3:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
240/4:
training_dataset = SegmentationDataSet(dataset='training_gan',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
240/5:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training' or self.dataset == 'training_gan':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
            
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
            
        if self.dataset == 'training_gan':
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/scans')):
                self.img_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/scans', folder_name))
                
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/labels')):
                self.label_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/labels', folder_name))
                
        
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]
        

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        
        if target_ID.startswith('dataset/slices_2d/training_gan'):
            y = (y >= 220) * y
        
        y = y.astype(bool).astype(int)
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
240/6:
training_dataset = SegmentationDataSet(dataset='training_gan',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
240/7:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
240/8:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    #if torch.cuda.is_available():
     #   model.cuda()

print(f'Out: {out.shape}')
240/9:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            
            #print(target.shape)
            #print(model.out_channels)
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
240/10:
import ipywidgets
# device
if torch.cuda.is_available():
    #device = torch.device('cuda')
    device = torch.device('cpu')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=10,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
240/11:
import pathlib

model_name =  'carvana_model_64_dice_10ep_adam_gan.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
240/12:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
240/13:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
240/14:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
240/15:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
240/16:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
240/17:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
240/18:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
240/19: out_prob[i,1]+out_prob[i,0]
240/20:
print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))
print('label shape: '+str(label.shape))
240/21:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training' or self.dataset == 'training_gan':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
            
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
            
        if self.dataset == 'training_gan':
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/scans')):
                self.img_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/scans', folder_name))
                
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/labels')):
                self.label_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/labels', folder_name))
                
        
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]
        

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        
        if target_ID.startswith('dataset/slices_2d/training_gan'):
            y = (y >= 220) * y
        
        y = y.astype(bool).astype(int)
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
241/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training' or self.dataset == 'training_gan':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
            
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
            
        if self.dataset == 'training_gan':
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/scans')):
                self.img_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/scans', folder_name))
                
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/labels')):
                self.label_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/labels', folder_name))
                
        
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]
        

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        
        if target_ID.startswith('dataset/slices_2d/training_gan'):
            y = (y >= 220) * y
        
        y = y.astype(bool).astype(int)
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
241/2:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
241/3:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
241/4:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
241/5:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    #if torch.cuda.is_available():
     #   model.cuda()

print(f'Out: {out.shape}')
242/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training' or self.dataset == 'training_gan':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
            
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
            
        if self.dataset == 'training_gan':
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/scans')):
                self.img_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/scans', folder_name))
                
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/labels')):
                self.label_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/labels', folder_name))
                
        
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]
        

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        
        if target_ID.startswith('dataset/slices_2d/training_gan'):
            y = (y >= 220) * y
        
        y = y.astype(bool).astype(int)
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
242/2:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
242/3:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
242/4:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
242/5:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
242/6:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
242/7:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
242/8:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            
            #print(target.shape)
            #print(model.out_channels)
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
242/9:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=5,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
242/10:
import pathlib

model_name =  'carvana_model_64_dice_5ep_adam_gan.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
242/11:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
242/12:
import pathlib

model_name =  'carvana_model_64_dice_5ep_adam.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
242/13:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
242/14:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
242/15:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
242/16:
training_dataset = SegmentationDataSet(dataset='trainingÜ',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
243/1:
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import os
import glob
import torch
from skimage.io import imread
from torch.utils import data



class SegmentationDataSet(data.Dataset):
    def __init__(self,
                 dataset,
                 transform=None
                 ):
        self.img_path = []
        self.label_path = []
        self.dataset = dataset
        if self.dataset == 'training' or self.dataset == 'training_gan':
            self.img_root = 'dataset/slices_2d/training/scans'
            self.label_root = 'dataset/slices_2d/training/labels'
        elif self.dataset == 'validation':
            self.img_root = 'dataset/slices_2d/validation/scans'
            self.label_root = 'dataset/slices_2d/validation/labels'
        
        self.transform = transform
        self.inputs_dtype = torch.float32
        self.targets_dtype = torch.long
        
        for i,folder_name in enumerate(os.listdir(self.img_root)):
            self.img_path += glob.glob(os.path.join(self.img_root, folder_name))
            
        for i,folder_name in enumerate(os.listdir(self.label_root)):
            self.label_path += glob.glob(os.path.join(self.label_root, folder_name))
            
        if self.dataset == 'training_gan':
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/scans')):
                self.img_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/scans', folder_name))
                
            for i,folder_name in enumerate(os.listdir('dataset/slices_2d/training_gan/labels')):
                self.label_path += glob.glob(os.path.join('dataset/slices_2d/training_gan/labels', folder_name))
                
        
        self.img_path = sorted(self.img_path)
        self.label_path = sorted(self.label_path)

    def __len__(self):
        return len(self.img_path)

    def __getitem__(self,
                    index: int):
        # Select the sample
        input_ID = self.img_path[index]
        target_ID = self.label_path[index]
        

        # Load input and target
        x, y = imread(input_ID), imread(target_ID)
        
        if target_ID.startswith('dataset/slices_2d/training_gan'):
            y = (y >= 220) * y
        
        y = y.astype(bool).astype(int)
        # Scale images between 0 to 1.
        
        
        # Preprocessing
        if self.transform is not None:
            x= np.array(self.transform(Image.fromarray(np.uint8(x))))
            y= np.array(self.transform(Image.fromarray(np.uint8(y))))
            y *= 255
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            y = np.squeeze(y, axis=0)
            
        else:
            x = x / 255.
            x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
            x = np.expand_dims(x, 0)
            

        # Typecasting
        #x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)
        #x = np.expand_dims(x, 0)
        #y = np.squeeze(y, axis=0)
        #y = y.unsqueeze(0)
        return x, y
243/2:
import torch
import torchvision.transforms as transforms
from PIL import Image
transform_image = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    #transforms.Normalize(mean=0.5,std=0.5)
    ])
243/3:
training_dataset = SegmentationDataSet(dataset='training_gan',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
243/4:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
243/5:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
243/6:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
243/7:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            
            #print(target.shape)
            #print(model.out_channels)
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
243/8:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=5,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
243/9:
import pathlib

model_name =  'carvana_model_64_dice_5ep_adam.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
243/10:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
243/11:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
243/12:
import pathlib

model_name =  'carvana_model_64_dice_5ep_adam_gan.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
243/13:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
243/14:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
243/15:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
243/16:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
243/17:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
243/18:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    #print(x[i,0].shape)
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
243/19:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
243/20:
#from BraTs.pytorch.models.unet import UNet

#model = UNet(drop_rate = 0.1)

from unet import UNet
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2)

x = torch.randn(size=(1, 1, 512, 512), dtype=torch.float32)
with torch.no_grad():
    out = model(x)
    if torch.cuda.is_available():
        model.cuda()

print(f'Out: {out.shape}')
243/21:
from torchsummary import summary
summary = summary(model, (1, 512, 512))
243/22:
import numpy as np
import torch
import torch.nn.functional as F
from dice_score import dice_loss


class Trainer:
    def __init__(self,
                 model: torch.nn.Module,
                 device: torch.device,
                 criterion: torch.nn.Module,
                 optimizer: torch.optim.Optimizer,
                 training_DataLoader: torch.utils.data.Dataset,
                 validation_DataLoader: torch.utils.data.Dataset = None,
                 lr_scheduler: torch.optim.lr_scheduler = None,
                 epochs: int = 100,
                 epoch: int = 0,
                 notebook: bool = False
                 ):

        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.training_DataLoader = training_DataLoader
        self.validation_DataLoader = validation_DataLoader
        self.device = device
        self.epochs = epochs
        self.epoch = epoch
        self.notebook = notebook

        self.training_loss = []
        self.validation_loss = []
        self.learning_rate = []

    def run_trainer(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        progressbar = trange(self.epochs, desc='Progress')
        for i in progressbar:
            """Epoch counter"""
            self.epoch += 1  # epoch counter

            """Training block"""
            self._train()

            """Validation block"""
            if self.validation_DataLoader is not None:
                self._validate()

            """Learning rate scheduler block"""
            if self.lr_scheduler is not None:
                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':
                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss
                else:
                    self.lr_scheduler.batch()  # learning rate scheduler step
        return self.training_loss, self.validation_loss, self.learning_rate

    def _train(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.train()  # train mode
        train_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            self.optimizer.zero_grad()  # zerograd the parameters
            out = self.model(input)  # one forward pass
            
            #print(target.shape)
            #print(model.out_channels)
#             loss = self.criterion(out, target) + dice_loss(
            loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
            loss_value = loss.item()
            train_losses.append(loss_value)
            print("Training Loss: " + str(i) + " : " + str(loss_value))
            loss.backward()  # one backward pass
            self.optimizer.step()  # update the parameters

            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar

        self.training_loss.append(np.mean(train_losses))
        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])

        batch_iter.close()

    def _validate(self):

        if self.notebook:
            from tqdm.notebook import tqdm, trange
        else:
            from tqdm import tqdm, trange

        self.model.eval()  # evaluation mode
        valid_losses = []  # accumulate the losses here
        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),
                          leave=False)

        for i, (x, y) in batch_iter:
            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
            with torch.no_grad():
                out = self.model(input)
#                 loss = self.criterion(out, target) + dice_loss(
                #print(target.shape)
                #print(model.out_channels)
                loss = dice_loss(
                F.softmax(out, dim=1).float(),
                F.one_hot(target, model.out_channels).permute(0, 3, 1, 2).float(),
                multiclass=True
            )  # calculate loss
                loss_value = loss.item()
                valid_losses.append(loss_value)
                print("Validation Loss: " + str(i) + " : " + str(loss_value))

                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')

        self.validation_loss.append(np.mean(valid_losses))

        batch_iter.close()
243/23:
import ipywidgets
# device
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    torch.device('cpu')

# model
model = UNet(in_channels=1,
             out_channels=2,
             n_blocks=4,
             start_filters=32,
             activation='relu',
             normalization='batch',
             conv_mode='same',
             dim=2).to(device)

# criterion
criterion = torch.nn.CrossEntropyLoss()

# optimizer
# optimizer = torch.optim.SGD(model.parameters(), lr=0.03)
optimizer = torch.optim.Adam(model.parameters(), lr=0.03)

# trainer
trainer = Trainer(model=model,
                  device=device,
                  criterion=criterion,
                  optimizer=optimizer,
                  training_DataLoader=training_dataloader,
                  validation_DataLoader=validation_dataloader,
                  lr_scheduler=None,
                  epochs=5,
                  epoch=0,
                  notebook=True)

# start training
training_losses, validation_losses, lr_rates = trainer.run_trainer()
243/24:
import pathlib

model_name =  'carvana_model_64_dice_5ep_adam.pt'
torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)
243/25:
def plot_training(training_losses,
                  validation_losses,
                  learning_rate,
                  gaussian=True,
                  sigma=2,
                  figsize=(8, 6)
                  ):
    """
    Returns a loss plot with training loss, validation loss and learning rate.
    """

    import matplotlib.pyplot as plt
    from matplotlib import gridspec
    from scipy.ndimage import gaussian_filter

    list_len = len(training_losses)
    x_range = list(range(1, list_len + 1))  # number of x values

    fig = plt.figure(figsize=figsize)
    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)

    subfig1 = fig.add_subplot(grid[0, 0])
    subfig2 = fig.add_subplot(grid[0, 1])

    subfigures = fig.get_axes()

    for i, subfig in enumerate(subfigures, start=1):
        subfig.spines['top'].set_visible(False)
        subfig.spines['right'].set_visible(False)

    if gaussian:
        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)
        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)

        linestyle_original = '.'
        color_original_train = 'lightcoral'
        color_original_valid = 'lightgreen'
        color_smooth_train = 'red'
        color_smooth_valid = 'green'
        alpha = 0.25
    else:
        linestyle_original = '-'
        color_original_train = 'red'
        color_original_valid = 'green'
        alpha = 1.0

    # Subfig 1
    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',
                 alpha=alpha)
    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',
                 alpha=alpha)
    if gaussian:
        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)
        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)
    subfig1.title.set_text('Training & validation loss')
    subfig1.set_xlabel('Epoch')
    subfig1.set_ylabel('Loss')

    subfig1.legend(loc='upper right')

    # Subfig 2
    subfig2.plot(x_range, learning_rate, color='black')
    subfig2.title.set_text('Learning rate')
    subfig2.set_xlabel('Epoch')
    subfig2.set_ylabel('LR')
    

    return fig
243/26:
%matplotlib inline
fig = plot_training(training_losses,
                   validation_losses,
                   lr_rates,
                   gaussian=True,
                   sigma=1,
                   figsize=(10,4))
fig.show()
243/27:
import torch.nn.functional as F

# model = UNet(in_channels=1,
#              out_channels=2,
#              n_blocks=4,
#              start_filters=32,
#              activation='relu',
#              normalization='batch',
#              conv_mode='same',
#              dim=2).to(device)

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    #     ax[i,1].imshow(out_prob[i,1].cpu())
#     ax[i,1].set_title('Prediction')
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
219/283: print("sa")
219/284:
num_images = 30
noise=torch.randn(num_images,100,1,1, device=device)
x = next(iter(dataloader))
with torch.no_grad():
    out = netG(noise)
fig, ax = plt.subplots(num_images,4, figsize=(20,5*num_images))
plt.gray()
for i in range(num_images):
    ax[i,0].imshow(out[i,0].cpu())
    ax[i,1].imshow(out[i,1].cpu()>0)
    ax[i,2].imshow(x[i,0])
    ax[i,3].imshow(x[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
    ax[i,2].set_title('Real Image')
    ax[i,3].set_title('Real Label')
219/285:
from skimage.io import imread
num_images=10
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/286:
from skimage.io import imread
num_images=10
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/287:
from skimage.io import imread, imsave
num_images=10
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    if i==0:
        imsave(data_path, xx)
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/288:
from skimage.io import imread
num_images=10
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
243/28:
import torch.nn.functional as F

# model_name = 'carvana_model_dice_10ep.pt'
# model_weights = torch.load(pathlib.Path.cwd() / model_name)

# model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
243/29:
import torch.nn.functional as F

model_name = 'carvana_model_64_dice_5ep_adam.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
243/30:
import torch.nn.functional as F

model_name = 'carvana_model_64_dice_5ep_adam.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

numsamples = 5
plt.gray()
fig, ax = plt.subplots(3, numsamples, figsize=(21,12))
for i in range(numsamples):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
243/31:
import torch.nn.functional as F

model_name = 'carvana_model_64_dice_5ep_adam.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

model_name2 = 'carvana_model_64_dice_5ep_adam_gan.pt'
model_weights2 = torch.load(pathlib.Path.cwd() / model_name2)

model.load_state_dict(model_weights2)

model.eval()
#image,label = next(iter(validation_dataloader))
#image = image[:,:,:,:].to(device)
#print(image.shape)
with torch.no_grad():
    output2 = model(image)
    out_prob2 = F.softmax(output2, dim=1)


numsamples = 5
plt.gray()
fig, ax = plt.subplots(4, numsamples, figsize=(21,12))
for i in range(numsamples):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[1,i].imshow(out_prob2[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(label[i])
    ax[2,i].set_title('GROUND TRUTH')
243/32:
import torch.nn.functional as F

model_name = 'carvana_model_64_dice_5ep_adam.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

model_name2 = 'carvana_model_64_dice_5ep_adam_gan.pt'
model_weights2 = torch.load(pathlib.Path.cwd() / model_name2)

model.load_state_dict(model_weights2)

model.eval()
#image,label = next(iter(validation_dataloader))
#image = image[:,:,:,:].to(device)
#print(image.shape)
with torch.no_grad():
    output2 = model(image)
    out_prob2 = F.softmax(output2, dim=1)


numsamples = 5
plt.gray()
fig, ax = plt.subplots(4, numsamples, figsize=(21,12))
for i in range(numsamples):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(out_prob2[i,1].cpu()>0.5)
    ax[2,i].set_title('PREDICTION')
    ax[3,i].imshow(label[i])
    ax[3,i].set_title('GROUND TRUTH')
243/33:
import torch.nn.functional as F

model_name = 'carvana_model_64_dice_5ep_adam.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

model_name2 = 'carvana_model_64_dice_5ep_adam_gan.pt'
model_weights2 = torch.load(pathlib.Path.cwd() / model_name2)

model.load_state_dict(model_weights2)

model.eval()
#image,label = next(iter(validation_dataloader))
#image = image[:,:,:,:].to(device)
#print(image.shape)
with torch.no_grad():
    output2 = model(image)
    out_prob2 = F.softmax(output2, dim=1)


numsamples = 5
plt.gray()
fig, ax = plt.subplots(4, numsamples, figsize=(21,12))
for i in range(numsamples):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(out_prob2[i,1].cpu()>0.5)
    ax[2,i].set_title('PREDICTION')
    ax[3,i].imshow(label[i])
    ax[3,i].set_title('GROUND TRUTH')
243/34:
import torch.nn.functional as F

model_name = 'carvana_model_64_dice_5ep_adam.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

model_name2 = 'carvana_model_64_dice_5ep_adam_gan.pt'
model_weights2 = torch.load(pathlib.Path.cwd() / model_name2)

model.load_state_dict(model_weights2)

model.eval()
#image,label = next(iter(validation_dataloader))
#image = image[:,:,:,:].to(device)
#print(image.shape)
with torch.no_grad():
    output2 = model(image)
    out_prob2 = F.softmax(output2, dim=1)


numsamples = 5
plt.gray()
fig, ax = plt.subplots(4, numsamples, figsize=(21,14))
for i in range(numsamples):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(out_prob2[i,1].cpu()>0.5)
    ax[2,i].set_title('PREDICTION')
    ax[3,i].imshow(label[i])
    ax[3,i].set_title('GROUND TRUTH')
243/35:
import torch.nn.functional as F

model_name = 'carvana_model_64_dice_5ep_adam.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

model_name2 = 'carvana_model_64_dice_5ep_adam_gan.pt'
model_weights2 = torch.load(pathlib.Path.cwd() / model_name2)

model.load_state_dict(model_weights2)

model.eval()
#image,label = next(iter(validation_dataloader))
#image = image[:,:,:,:].to(device)
#print(image.shape)
with torch.no_grad():
    output2 = model(image)
    out_prob2 = F.softmax(output2, dim=1)


numsamples = 5
plt.gray()
fig, ax = plt.subplots(4, numsamples, figsize=(21,15))
for i in range(numsamples):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(out_prob2[i,1].cpu()>0.5)
    ax[2,i].set_title('PREDICTION')
    ax[3,i].imshow(label[i])
    ax[3,i].set_title('GROUND TRUTH')
243/36:
import torch.nn.functional as F

model_name = 'carvana_model_64_dice_5ep_adam.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

model_name2 = 'carvana_model_64_dice_5ep_adam_gan.pt'
model_weights2 = torch.load(pathlib.Path.cwd() / model_name2)

model.load_state_dict(model_weights2)

model.eval()
#image,label = next(iter(validation_dataloader))
#image = image[:,:,:,:].to(device)
#print(image.shape)
with torch.no_grad():
    output2 = model(image)
    out_prob2 = F.softmax(output2, dim=1)


numsamples = 5
plt.gray()
fig, ax = plt.subplots(4, numsamples, figsize=(21,16))
for i in range(numsamples):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(out_prob2[i,1].cpu()>0.5)
    ax[2,i].set_title('PREDICTION')
    ax[3,i].imshow(label[i])
    ax[3,i].set_title('GROUND TRUTH')
243/37:
import torch.nn.functional as F

model_name = 'carvana_model_64_dice_5ep_adam.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

model_name2 = 'carvana_model_64_dice_5ep_adam_gan.pt'
model_weights2 = torch.load(pathlib.Path.cwd() / model_name2)

model.load_state_dict(model_weights2)

model.eval()
#image,label = next(iter(validation_dataloader))
#image = image[:,:,:,:].to(device)
#print(image.shape)
with torch.no_grad():
    output2 = model(image)
    out_prob2 = F.softmax(output2, dim=1)


numsamples = 5
plt.gray()
fig, ax = plt.subplots(4, numsamples, figsize=(21,16))
for i in range(numsamples):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(out_prob2[i,1].cpu()>0.5)
    ax[2,i].set_title('PREDICTION')
    ax[3,i].imshow(label[i])
    ax[3,i].set_title('GROUND TRUTH')
243/38:
import torch.nn.functional as F

model_name = 'carvana_model_64_dice_5ep_adam.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

model_name2 = 'carvana_model_64_dice_5ep_adam_gan.pt'
model_weights2 = torch.load(pathlib.Path.cwd() / model_name2)

model.load_state_dict(model_weights2)

model.eval()
#image,label = next(iter(validation_dataloader))
#image = image[:,:,:,:].to(device)
#print(image.shape)
with torch.no_grad():
    output2 = model(image)
    out_prob2 = F.softmax(output2, dim=1)


numsamples = 5
plt.gray()
fig, ax = plt.subplots(4, numsamples, figsize=(21,16))
for i in range(numsamples):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(out_prob2[i,1].cpu()>0.5)
    ax[2,i].set_title('PREDICTION')
    ax[3,i].imshow(label[i])
    ax[3,i].set_title('GROUND TRUTH')
243/39:
import torch.nn.functional as F

model_name = 'carvana_model_64_dice_5ep_adam.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

model_name2 = 'carvana_model_64_dice_5ep_adam_gan.pt'
model_weights2 = torch.load(pathlib.Path.cwd() / model_name2)

model.load_state_dict(model_weights2)

model.eval()
#image,label = next(iter(validation_dataloader))
#image = image[:,:,:,:].to(device)
#print(image.shape)
with torch.no_grad():
    output2 = model(image)
    out_prob2 = F.softmax(output2, dim=1)


numsamples = 5
plt.gray()
fig, ax = plt.subplots(4, numsamples, figsize=(21,16))
for i in range(numsamples):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(out_prob2[i,1].cpu()>0.5)
    ax[2,i].set_title('PREDICTION')
    ax[3,i].imshow(label[i])
    ax[3,i].set_title('GROUND TRUTH')
243/40:
import torch.nn.functional as F

model_name = 'carvana_model_64_dice_5ep_adam.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

model_name2 = 'carvana_model_64_dice_5ep_adam_gan.pt'
model_weights2 = torch.load(pathlib.Path.cwd() / model_name2)

model.load_state_dict(model_weights2)

model.eval()
#image,label = next(iter(validation_dataloader))
#image = image[:,:,:,:].to(device)
#print(image.shape)
with torch.no_grad():
    output2 = model(image)
    out_prob2 = F.softmax(output2, dim=1)


numsamples = 5
plt.gray()
fig, ax = plt.subplots(4, numsamples, figsize=(21,16))
for i in range(numsamples):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(out_prob2[i,1].cpu()>0.5)
    ax[2,i].set_title('PREDICTION')
    ax[3,i].imshow(label[i])
    ax[3,i].set_title('GROUND TRUTH')
243/41:
import torch.nn.functional as F

model_name = 'carvana_model_64_dice_5ep_adam.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

model_name2 = 'carvana_model_64_dice_5ep_adam_gan.pt'
model_weights2 = torch.load(pathlib.Path.cwd() / model_name2)

model.load_state_dict(model_weights2)

model.eval()
#image,label = next(iter(validation_dataloader))
#image = image[:,:,:,:].to(device)
#print(image.shape)
with torch.no_grad():
    output2 = model(image)
    out_prob2 = F.softmax(output2, dim=1)


numsamples = 5
plt.gray()
fig, ax = plt.subplots(4, numsamples, figsize=(21,16))
for i in range(numsamples):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(out_prob2[i,1].cpu()>0.5)
    ax[2,i].set_title('PREDICTION')
    ax[3,i].imshow(label[i])
    ax[3,i].set_title('GROUND TRUTH')
243/42:
import torch.nn.functional as F

model_name = 'carvana_model_64_dice_5ep_adam.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

model_name2 = 'carvana_model_64_dice_5ep_adam_gan.pt'
model_weights2 = torch.load(pathlib.Path.cwd() / model_name2)

model.load_state_dict(model_weights2)

model.eval()
#image,label = next(iter(validation_dataloader))
#image = image[:,:,:,:].to(device)
#print(image.shape)
with torch.no_grad():
    output2 = model(image)
    out_prob2 = F.softmax(output2, dim=1)


numsamples = 5
plt.gray()
fig, ax = plt.subplots(4, numsamples, figsize=(21,16))
for i in range(numsamples):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(out_prob2[i,1].cpu()>0.5)
    ax[2,i].set_title('PREDICTION')
    ax[3,i].imshow(label[i])
    ax[3,i].set_title('GROUND TRUTH')
243/43:
import torch.nn.functional as F

model_name = 'carvana_model_64_dice_5ep_adam.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

model_name2 = 'carvana_model_64_dice_5ep_adam_gan.pt'
model_weights2 = torch.load(pathlib.Path.cwd() / model_name2)

model.load_state_dict(model_weights2)

model.eval()
#image,label = next(iter(validation_dataloader))
#image = image[:,:,:,:].to(device)
#print(image.shape)
with torch.no_grad():
    output2 = model(image)
    out_prob2 = F.softmax(output2, dim=1)


numsamples = 5
plt.gray()
fig, ax = plt.subplots(4, numsamples, figsize=(21,16))
for i in range(numsamples):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION')
    ax[2,i].imshow(out_prob2[i,1].cpu()>0.5)
    ax[2,i].set_title('PREDICTION')
    ax[3,i].imshow(label[i])
    ax[3,i].set_title('GROUND TRUTH')
243/44:
import torch.nn.functional as F

model_name = 'carvana_model_64_dice_5ep_adam.pt'
model_weights = torch.load(pathlib.Path.cwd() / model_name)

model.load_state_dict(model_weights)

model.eval()
image,label = next(iter(validation_dataloader))
image = image[:,:,:,:].to(device)
print(image.shape)
with torch.no_grad():
    output = model(image)
    out_prob = F.softmax(output, dim=1)

print('output shape: '+str(output.shape))
print('out_prob shape: '+str(out_prob.shape))

model_name2 = 'carvana_model_64_dice_5ep_adam_gan.pt'
model_weights2 = torch.load(pathlib.Path.cwd() / model_name2)

model.load_state_dict(model_weights2)

model.eval()
#image,label = next(iter(validation_dataloader))
#image = image[:,:,:,:].to(device)
#print(image.shape)
with torch.no_grad():
    output2 = model(image)
    out_prob2 = F.softmax(output2, dim=1)


numsamples = 5
plt.gray()
fig, ax = plt.subplots(4, numsamples, figsize=(21,16))
for i in range(numsamples):
    ax[0,i].imshow(image[i,0].cpu())
    ax[0,i].set_title('INPUT')
    ax[1,i].imshow(out_prob[i,1].cpu()>0.5)
    ax[1,i].set_title('PREDICTION WITHOUT GAN')
    ax[2,i].imshow(out_prob2[i,1].cpu()>0.5)
    ax[2,i].set_title('PREDICTION WITH GAN')
    ax[3,i].imshow(label[i])
    ax[3,i].set_title('GROUND TRUTH')
219/289:
from skimage.io import imread
num_images=10
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/290:
from skimage.io import imread
num_images=5
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/291:
from skimage.io import imread
num_images=5
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/292:
from skimage.io import imread
num_images=5
fig, ax = plt.subplots(num_images,2, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/293:
from skimage.io import imread
num_images=5
fig, ax = plt.subplots(2,num_images, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[i,0].imshow(xx)
    i2=ax[i,1].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[i,0].set_title('GAN Image')
    ax[i,1].set_title('GAN Label')
219/294:
from skimage.io import imread
num_images=5
fig, ax = plt.subplots(2,num_images, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[0,i].imshow(xx)
    i2=ax[1,i].imshow(yy)
    fig.colorbar(i1,ax=ax[i,0])
    fig.colorbar(i2,ax=ax[i,1])
    ax[0,i].set_title('GAN Image')
    ax[1,i].set_title('GAN Label')
219/295:
from skimage.io import imread
num_images=5
fig, ax = plt.subplots(2,num_images, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[0,i].imshow(xx)
    i2=ax[1,i].imshow(yy)
    fig.colorbar(i1,ax=ax[0,i])
    fig.colorbar(i2,ax=ax[1,i])
    ax[0,i].set_title('GAN Image')
    ax[1,i].set_title('GAN Label')
219/296:
from skimage.io import imread
num_images=5
fig, ax = plt.subplots(2,num_images, figsize=(10,5*num_images))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[0,i].imshow(xx)
    i2=ax[1,i].imshow(yy)
    #fig.colorbar(i1,ax=ax[0,i])
    #fig.colorbar(i2,ax=ax[1,i])
    ax[0,i].set_title('GAN Image')
    ax[1,i].set_title('GAN Label')
219/297:
from skimage.io import imread
num_images=5
fig, ax = plt.subplots(2,num_images, figsize=(5*num_images,10))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[0,i].imshow(xx)
    i2=ax[1,i].imshow(yy)
    #fig.colorbar(i1,ax=ax[0,i])
    #fig.colorbar(i2,ax=ax[1,i])
    ax[0,i].set_title('GAN Image')
    ax[1,i].set_title('GAN Label')
219/298:
from skimage.io import imread
num_images=5
fig, ax = plt.subplots(2,num_images, figsize=(5*num_images,10))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[0,i].imshow(xx)
    i2=ax[1,i].imshow(yy)
    #fig.colorbar(i1,ax=ax[0,i])
    #fig.colorbar(i2,ax=ax[1,i])
    ax[0,i].set_title('GAN Image')
    ax[1,i].set_title('GAN Label')
219/299:
from skimage.io import imread
num_images=5
fig, ax = plt.subplots(2,num_images, figsize=(5*num_images,10))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[0,i].imshow(xx)
    i2=ax[1,i].imshow(yy)
    #fig.colorbar(i1,ax=ax[0,i])
    #fig.colorbar(i2,ax=ax[1,i])
    ax[0,i].set_title('GAN Image')
    ax[1,i].set_title('GAN Label')
219/300:
from skimage.io import imread
num_images=5
fig, ax = plt.subplots(2,num_images, figsize=(5*num_images,10))
plt.gray()
for i in range(num_images):
    jj = np.random.randint(19999)+1
    xx = imread(data_path+'scans/gan_{:05d}.jpg'.format(jj))
    yy = imread(data_path+'labels/gan_{:05d}.jpg'.format(jj))
    i1=ax[0,i].imshow(xx)
    i2=ax[1,i].imshow(yy)
    #fig.colorbar(i1,ax=ax[0,i])
    #fig.colorbar(i2,ax=ax[1,i])
    ax[0,i].set_title('GAN Image')
    ax[1,i].set_title('GAN Label')
243/45:
validation_dataset = SegmentationDataSet(dataset='validation',transform=transform_image)

validation_dataloader = data.DataLoader(dataset=validation_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(validation_dataloader))

print(f'There are {len(validation_dataset)} images in the validation dataset')
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')
243/46:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'There are {len(training_dataset)} images in the validation dataset')
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
243/47:
training_dataset = SegmentationDataSet(dataset='training',transform=transform_image)

training_dataloader = data.DataLoader(dataset=training_dataset,
                                      batch_size=32,
                                      shuffle=True)
x, y = next(iter(training_dataloader))

num_images=5
print(f'x = shape: {x.shape}; type: {x.dtype}')
print(f'x = min: {x.min()}; max: {x.max()}')
print(f'y = min: {y.min()}; max: {y.max()}')
print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')

print(x.shape)
fig, ax = plt.subplots(2,num_images, figsize=(18,7))
plt.gray()
for i in range(num_images):
    ax[0,i].imshow(x[i,0].cpu())
    ax[1,i].imshow(y[i].cpu())
    ax[0,i].set_title('Image')
    ax[1,i].set_title('Label')
244/1: %run evaluate.py
245/1: %run evaluate.py
245/2: %run evaluate.py
245/3: %run evaluate.py
245/4: %run evaluate.py
245/5: %run evaluate.py
245/6: %run evaluate.py
245/7: %run evaluate.py
245/8: %run evaluate.py
245/9: %run evaluate.py
245/10: %run evaluate.py
245/11: %run evaluate.py
246/1: %run evaluate.py
246/2: %run evaluate.py
246/3: %run evaluate.py
246/4: %run evaluate.py
246/5: %run evaluate.py
246/6: %run evaluate.py
246/7: %run evaluate.py
246/8: min(3,4,5)
246/9: np.min(3,4,5)
246/10: np.min(None)
246/11: min(np.min(None),3)
246/12: np.min([np.min(None),3])
246/13: np.nanmin([np.min(None),3])
246/14: np.nanmin([np.min(None),3,4])
246/15: np.min([np.min(None),3,4])
246/16: a=np.min(None)
246/17: %run evaluate.py
246/18: %run evaluate.py
246/19: %run evaluate.py
246/20: %run evaluate.py
246/21: %run evaluate.py
246/22: %run evaluate.py
246/23: %run evaluate.py
246/24: plt.plot(np.arange(3))
246/25: plt.show()
246/26: f=plt.figure()
246/27: f.close()
246/28: f.clear()
246/29: %run evaluate.py
246/30: %run evaluate.py
246/31: %run evaluate.py
246/32: %run evaluate.py
246/33: %run evaluate.py
246/34: %run evaluate.py
246/35: %run evaluate.py
246/36: %run evaluate.py
246/37: %run evaluate.py
246/38: f.get_size_inches()
246/39: plt.tight_layout()
246/40: %run evaluate.py
246/41: %run evaluate.py
246/42: %run evaluate.py
246/43: %run evaluate.py
246/44: %run evaluate.py
246/45: %run evaluate.py
246/46: %run evaluate.py
246/47: %run evaluate.py
246/48: %run evaluate.py
246/49: %run evaluate.py
246/50: %run evaluate.py
246/51: %run evaluate.py
246/52: %run evaluate.py
247/1: %run evaluate.py
247/2: %run evaluate.py
247/3: ipdb.pm()
247/4: %run evaluate.py
247/5: %run evaluate.py
247/6: %run evaluate.py
247/7: %run evaluate.py
247/8: %run evaluate.py
247/9: %run evaluate.py
247/10: %run evaluate.py
247/11: %run evaluate.py
247/12: %run evaluate.py
247/13: ipdb.pm()
248/1: %run evaluate.py
248/2: %run evaluate.py
248/3: %run evaluate.py
248/4: %run evaluate.py
248/5: a=1
248/6: a
248/7: a
248/8: a
248/9: from data_loader import BasicDataset
248/10: from torch.utils.data import DataLoader
248/11:     trainset = BasicDataset(data_dir = './data/', fold='train')
248/12: trainloader = DataLoader(trainset, batch_size=32, shuffle=True)
248/13: x,y=next(iter(trainloader))
248/14: x.shape
248/15: plt.imshow(x[0,0])
248/16: plt.plot(x[0,0,:,0])
248/17: plt.plot(y[0,0,:,0])
248/18: plt.imshow(x[0,0], aspect='auto', origin='lower')
248/19: plt.imshow(y[0,0], aspect='auto', origin='lower')
248/20: plt.imshow(x[0,0]-y[0,0], aspect='auto', origin='lower')
248/21: plt.imshow(x[0,0]-y[0,0], aspect='auto', origin='lower', vmax=10, vmin=10); plt.colorbar()
248/22: plt.imshow(x[0,0]-y[0,0], aspect='auto', origin='lower', cmap='jet', vmax=10, vmin=-10); plt.colorbar()
248/23: i=np.random.randint(32); plt.imshow(x[i,0]-y[i,0], aspect='auto', origin='lower', cmap='jet', vmax=10, vmin=-10); plt.colorbar()
248/24: i=np.random.randint(32); plt.imshow(x[i,0]-y[i,0], aspect='auto', origin='lower', cmap='jet', vmax=10, vmin=-10); plt.colorbar()
248/25: i=np.random.randint(32); plt.clf(); plt.imshow(x[i,0]-y[i,0], aspect='auto', origin='lower', cmap='jet', vmax=10, vmin=-10); plt.colorbar()
248/26: i=np.random.randint(32); plt.clf(); plt.imshow(x[i,0]-y[i,0], aspect='auto', origin='lower', cmap='jet', vmax=10, vmin=-10); plt.colorbar()
248/27: i=np.random.randint(32); plt.clf(); plt.imshow(x[i,0]-y[i,0], aspect='auto', origin='lower', cmap='jet', vmax=10, vmin=-10); plt.colorbar()
248/28: i=np.random.randint(32); plt.clf(); plt.imshow(x[i,0]-y[i,0], aspect='auto', origin='lower', cmap='jet', vmax=10); plt.colorbar()
248/29: i=np.random.randint(32); plt.clf(); plt.imshow(x[i,0]-y[i,0], aspect='auto', origin='lower', cmap='jet', vmax=10); plt.colorbar()
248/30: i=np.random.randint(32); plt.clf(); plt.imshow(x[i,0]-y[i,0], aspect='auto', origin='lower', cmap='jet', vmax=10); plt.colorbar()
248/31: i=np.random.randint(32); plt.clf(); plt.imshow(x[i,0]-y[i,0], aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
248/32: i=np.random.randint(32); plt.clf(); plt.imshow(x[i,0]-y[i,0], aspect='auto', origin='lower', cmap='jet', vmax=10, vmin=-100); plt.colorbar()
248/33: i=np.random.randint(32); plt.clf(); plt.imshow(x[i,0]-y[i,0], aspect='auto', origin='lower', cmap='jet', vmax=10, vmin=-100); plt.colorbar()
248/34: i=np.random.randint(32); plt.clf(); plt.plot(x[i,0]-y[i,0])
248/35: import os
248/36: import glob
248/37: amo = glob.glob('./data/train/*')
248/38: len(amo)
248/39: data=amo[0]
248/40: data=np.load(amo,allow_pickle=True).item()
248/41: amo[0]
248/42: data=np.load(amo[0],allow_pickle=True).item()
248/43: data.keys()
248/44: imc=data['image_clean']
248/45: imo=data['image_ori']
248/46: ims=data['image_stars']
248/47: ims.shape
248/48: plt.imshow(ims-imo, aspect='auto', origin='lower', cmap='jet', vmax=10, vmin=-10); plt.colorbar()
248/49: plt.imshow(ims-imo, aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
248/50: plt.imshow(ims-imo, aspect='auto', origin='lower', cmap='jet', vmax=10); plt.colorbar()
248/51: plt.imshow(ims-imo, aspect='auto', origin='lower', cmap='jet', vmax=10); plt.colorbar()
248/52: plt.imshow(ims-imc, aspect='auto', origin='lower', cmap='jet', vmax=10); plt.colorbar()
248/53: plt.imshow(ims-imo, aspect='auto', origin='lower', cmap='jet', vmax=10); plt.colorbar()
248/54: plt.imshow(imo-imc, aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
250/1: %run train.py
250/2: a=
250/3: %run evaluate.py
250/4: %run evaluate.py
250/5: net
250/6: net2 = net.copy()
250/7: net2 = net
250/8: a={c:'x'}
250/9: a={'c':'x'}
250/10: a['c']
250/11: a={'c':'x','d':'v'}
250/12: a['d']
250/13: a['c']
250/14: a={'c':'x','d':13}
250/15: a['d']
250/16: %run evaluate.py
250/17: f'{12}'
250/18: f'{a['c']}'
250/19: '{}'.format(a['c'])
250/20: %run evaluate.py
250/21: %run evaluate.py
250/22: %run evaluate.py
250/23: %run evaluate.py
250/24: %run train.py
250/25: %run evaluate.py
250/26: %run evaluate.py
250/27: import netCDF4
250/28: date = '2020-07-28'
250/29: files = glob.glob(path_dir+f'{nc_prefix}_{date}_v0*')
250/30: files.sort()
250/31: file = files[-1]
250/32: nc_prefix
250/33: path_dir
250/34: files = glob.glob(path_dir+f'*/{nc_prefix}_{date}_v0*')
250/35: files.sort()
250/36: file = files[-1]
250/37: file
250/38: l1 = netCDF4.Dataset(file, 'r')
250/39: brs, brsc,_,_,_,_ = get_br_nights(l1, target_mode=target_mode)
250/40: l1.close()
250/41: brs = np.concatenate(brs, axis=1)
250/42: brsc = np.concatenate(brsc, axis=1)
250/43: brs[250].shape
250/44: brs.shape
250/45: plt.imshow(brs[:,250].T, origin='lower', aspect='auto', cmap='jet')
250/46: plt.show()
250/47: plt.close('all')
250/48: plt.imshow(brs[:,250].T, origin='lower', aspect='auto', cmap='jet')
250/49: plt.imshow(np.mean(brs, axis=1).T, origin='lower', aspect='auto', cmap='jet')
250/50: plt.colorbar()
250/51: plt.imshow(np.mean(brs, axis=1).T, origin='lower', aspect='auto', cmap='jet')
250/52: x,y = next(iter(trainloader))
250/53: x.shape
250/54: plt.imshow(np.mean(x, axis=(0,1)).T, origin='lower', aspect='auto', cmap='jet')
250/55: plt.imshow(np.mean(x.cpu().numpy(), axis=(0,1)).T, origin='lower', aspect='auto', cmap='jet')
250/56: plt.imshow(np.mean(x.cpu().numpy(), axis=(0,1)), origin='lower', aspect='auto', cmap='jet')
250/57: plt.imshow(np.mean(y.cpu().numpy(), axis=(0,1)), origin='lower', aspect='auto', cmap='jet')
250/58: brs, brsc,_,_,_,_ = get_br_nights(l1, target_mode=target_mode)
250/59: l1 = netCDF4.Dataset(file, 'r')
250/60: brs, brsc,_,_,_,_ = get_br_nights(l1, target_mode=target_mode)
250/61: plt.imshow(np.mean(brs, axis=1).T, origin='lower', aspect='auto', cmap='jet')
250/62: brs.shape
250/63: brs = np.concatenate(brs, axis=1)
250/64: plt.imshow(np.mean(brs, axis=1).T, origin='lower', aspect='auto', cmap='jet')
250/65: brs, brsc,_,_,_,_ = get_br_nights(l1, target_mode=target_mode)
250/66: from iconfuv.misc import get_br_nights
250/67: brs, brsc,_,_,_,_ = get_br_nights(l1, target_mode=target_mode)
250/68: brs, brsc,_,_,_,_ = get_br_nights(l1, target_mode=target_mode)
250/69: brs, brsc,_,_,_,_ = get_br_nights(l1, target_mode=target_mode)
250/70: brs, brsc,_,_,_,_ = get_br_nights(l1, target_mode=target_mode)
250/71: brs, brsc,_,_,_,_ = get_br_nights(l1, target_mode=target_mode)
250/72: brs, brsc,_,_,_,_ = get_br_nights(l1, target_mode=target_mode)
250/73: brs, brsc,_,_,_,_ = get_br_nights(l1, target_mode=target_mode)
250/74: brs, brsc,_,_,_,_ = get_br_nights(l1, target_mode=target_mode)
250/75: type(brs[4])
250/76: type(brs[1])
250/77: type(brs[0])
250/78: a
250/79: brs, brsc,_,_,n,_ = get_br_nights(l1, target_mode=target_mode)
250/80: n.shape
250/81: np.unique(n)
250/82: l1 = netCDF4.Dataset(file, 'r')
250/83: brs, brsc,_,_,n,_ = get_br_nights(l1, target_mode=target_mode)
250/84: np.unique(n)
250/85: brs[0].shape
250/86: brs = np.concatenate(brs, axis=1)
250/87: plt.imshow(np.mean(brs, axis=1).T, origin='lower', aspect='auto', cmap='jet')
250/88: %run evaluate.py
250/89: %run evaluate.py
250/90: %run evaluate.py
250/91: %run evaluate.py
250/92: %run evaluate.py
252/1: %run evaluate.py
252/2: np.random.uniform()
252/3: np.random.uniform()
252/4: np.random.uniform()
252/5: np.random.uniform()
252/6: np.random.uniform()
252/7: np.random.uniform()<0.5
252/8: np.random.uniform()<0.5
252/9: np.random.uniform()<0.5
252/10: np.random.uniform()<0.5
252/11: np.random.uniform()<0.5
252/12: np.random.uniform()<0.5
252/13: np.random.uniform()<0.5
252/14: np.random.uniform()<0.5
252/15: np.random.uniform()<0.5
252/16: np.random.uniform()<0.5
252/17: np.random.uniform()<0.5
252/18: np.random.uniform()<0.5
252/19: np.random.uniform()<0.5
252/20: np.random.uniform()<0.5
252/21: np.random.uniform()<0.5
252/22: np.random.uniform()<0.5
252/23: a=[]
252/24: a=np.sum([np.random.uniform()<0.5 for i in range(10000)])
252/25: a/10000.
252/26: a=np.sum([np.random.uniform()<0.2 for i in range(10000)])
252/27: a/10000.
252/28: %run train.py
252/29: x,y = next(iter(trainloader))
252/30: x.shape
252/31: plt.imshow(x[0,0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/32: plt.imshow(x[10,0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/33: plt.imshow(x[20,0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/34: plt.imshow(y[20,0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/35: fuck you
252/36: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/37: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/38: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/39: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/40:     trainset = BasicDataset(data_dir = './data/', fold='train')
252/41:     trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)
252/42: x,y = next(iter(trainloader))
252/43: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/44: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/45: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/46: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/47: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/48: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/49:     trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)
252/50:     trainset = BasicDataset(data_dir = './data/', fold='train')
252/51:     trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)
252/52: x,y = next(iter(trainloader))
252/53: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/54: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/55: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/56: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/57: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/58: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/59: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/60: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/61: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/62: plt.imshow(x[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/63: plt.imshow(x[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/64: plt.imshow(x[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/65: plt.imshow(x[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/66: plt.imshow(x[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/67: plt.imshow(x[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/68: plt.imshow(x[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/69: i=np.random.randint(64); plt.imshow((x[i,0]-y[i,0]).cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/70: i=np.random.randint(64); plt.imshow((x[i,0]-y[i,0]).cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/71: i=np.random.randint(64); plt.imshow((x[i,0]-y[i,0]).cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/72:     trainset = BasicDataset(data_dir = './data/', fold='train')
252/73:     trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)
252/74: x,y = next(iter(trainloader))
252/75: i=np.random.randint(64); plt.imshow((x[i,0]-y[i,0]).cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/76: i=np.random.randint(64); plt.imshow((x[i,0]-y[i,0]).cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/77: i=np.random.randint(64); plt.imshow((x[i,0]-y[i,0]).cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/78: plt.imshow(x[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/79: plt.imshow(x[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/80: plt.imshow(x[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/81: plt.imshow(x[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/82: plt.imshow(x[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/83: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/84: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/85: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/86: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/87: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/88: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/89: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/90: plt.imshow(y[np.random.randint(64),0].cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
252/91: %run train.py
252/92: valloader
252/93: criterion
252/94:
    model_torch_new = '/home/kamo/resources/icon-fuv/python3/star_removal/saved\
/2021_12_22__15_43_43_NF_32_LR_0.0005_EP_30_L1_LOSS/best_model.pth'
252/95:
    net_new = UNet(in_channels=1,
                 out_channels=1,
                 start_filters=32,
                 bilinear=True,
                 residual=True).to(device)
252/96:     net_new.load_state_dict(torch.load(model_torch_new))
252/97: from evaluate import calculate_valloss
252/98: calculate_valloss(net_new, valloader, criterion)
252/99: %run evaluate.py
252/100: %run evaluate.py
253/1: %run evaluate.py
253/2: %run evaluate.py
254/1: %run train.py
255/1: %run train.py
255/2: %run train.py
255/3: %run train.py
258/1: np.arange(5) % 3
258/2: from data_loader import BasicDataset
258/3: from torch.utils.data import DataLoader
258/4:     trainset = BasicDataset(data_dir = './data/', fold='train')
258/5:     trainloader = DataLoader(trainset, batch_size=64, shuffle=True)
258/6: i=np.random.randint(64); plt.imshow((x[i,0]-y[i,0]).cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/7: x,y = next(iter(trainloader))
258/8: i=np.random.randint(64); plt.imshow((x[i,0]-y[i,0]).cpu(), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/9: i=np.random.randint(64); plt.imshow((x[i,0]-y[i,0]).cpu()>0, aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/10: i=np.random.randint(64); plt.imshow((x[i,0]-y[i,0]).cpu()>1, aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/11: i=np.random.randint(64); plt.imshow((x[i,0]-y[i,0]).cpu(), aspect='auto', origin='lower', cmap='jet', vmax=10); plt.colorbar()
258/12: i=np.random.randint(64); plt.imshow((x[i,0]-y[i,0]).cpu(), aspect='auto', origin='lower', cmap='jet', vmax=10); plt.colorbar()
258/13: i=np.random.randint(64); plt.clf(); plt.imshow((x[i,0]-y[i,0]).cpu(), aspect='auto', origin='lower', cmap='jet', vmax=10); plt.colorbar()
258/14: i=np.random.randint(64); plt.clf(); plt.imshow((x[i,0]-y[i,0]).cpu(), aspect='auto', origin='lower', cmap='jet', vmax=10); plt.colorbar()
258/15: i=np.random.randint(64); plt.clf(); plt.imshow((x[i,0]-y[i,0]).cpu(), aspect='auto', origin='lower', cmap='jet', vmax=10); plt.colorbar()
258/16: i=np.random.randint(64); plt.clf(); plt.imshow(np.log((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/17: i=np.random.randint(64); plt.clf(); plt.imshow(np.log((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/18: i=np.random.randint(64); plt.clf(); plt.imshow(np.log((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/19: i=np.random.randint(64); plt.clf(); plt.imshow(np.log((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/20: i=np.random.randint(64); plt.clf(); plt.imshow(np.log((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/21: i=np.random.randint(64); plt.clf(); plt.imshow(np.log((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/22: i=np.random.randint(64); plt.clf(); plt.imshow(np.log10((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/23: i=np.random.randint(64); plt.clf(); plt.imshow(np.log10((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/24: i=np.random.randint(64); plt.clf(); plt.imshow(np.log10((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/25: i=np.random.randint(64); plt.clf(); plt.imshow(np.log10((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/26: i=np.random.randint(64); plt.clf(); plt.imshow(np.log10((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/27: i=np.random.randint(64); plt.clf(); plt.imshow(np.log10((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/28: i=np.random.randint(64); plt.clf(); plt.imshow(np.log10((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/29: i=np.random.randint(64); plt.clf(); plt.imshow(np.log10((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/30: i=np.random.randint(64); plt.clf(); plt.imshow(np.log10((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/31:     trainloader = DataLoader(trainset, batch_size=512, shuffle=True)
258/32: x,y = next(iter(trainloader))
258/33: i=np.random.randint(512); plt.clf(); plt.imshow(np.log10((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/34: i=np.random.randint(512); plt.clf(); plt.imshow(np.log10((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/35: i=np.random.randint(512); plt.clf(); plt.imshow(np.log10((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/36: i=np.random.randint(512); plt.clf(); plt.imshow(np.log10((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/37: i=np.random.randint(512); plt.clf(); plt.imshow(np.log10((x[i,0]-y[i,0]).cpu()+10), aspect='auto', origin='lower', cmap='jet'); plt.colorbar()
258/38: from evaluate import plot_dataset_diff
258/39: plot_dataset_diff(x,y)
258/40: plot_dataset_diff(x,y)
258/41: plot_dataset_diff(x,y)
258/42: plot_dataset_diff(x,y)
258/43: plot_dataset_diff(x,y)
258/44: plot_dataset_diff(x,y)
258/45: plot_dataset_diff(x,y)
258/46: plot_dataset_diff(x,y)
258/47: plot_dataset_diff(x,y)
258/48: plot_dataset_diff(x,y, th1=20)
258/49: plot_dataset_diff(x,y, th1=20)
259/1: a=0
259/2: a=a+np.arange(3)
259/3: a
260/1: from FUV_instrument import synthetize_star_in_raw_pixels, from_raw_to_science
260/2: a=synthetize_star_in_raw_pixels(127,127,1e3, wavelength='LW')
260/3: a.shape
260/4: plt.imshow(a)
260/5: plt.imshow(a); plt.colorbar()
260/6: np.histogram(a)
260/7: plt.imshow(np.log10(a+1)); plt.colorbar()
260/8: plt.imshow(a, vmax=2); plt.colorbar()
260/9: a=synthetize_star_in_raw_pixels(127.5,127.3,1e3, wavelength='LW')
260/10: plt.imshow(a, vmax=2); plt.colorbar()
260/11: aa=from_raw_to_science(a,fill_nans=True,period='old')
260/12: aa=from_raw_to_science(a,fill_nans=True,period='new')
260/13: plt.imshow(aa, vmax=2); plt.colorbar()
260/14: plt.imshow(aa, origin='lower', aspect='auto', cmap='jets'); plt.colorbar()
260/15: plt.imshow(aa, origin='lower', aspect='auto', cmap='jet'); plt.colorbar()
260/16: from model improt _synthetize_stars
260/17: from model import _synthetize_stars
260/18: im_stars, x0s, y0s, amps = _synthetize_stars(np.random.randint(10,26),max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='new')
260/19: im_stars.shape
260/20: plt.imshow(im_stars, origin='lower', aspect='auto', cmap='jet'); plt.colorbar()
260/21: np.random.randint(0)
260/22: np.random.randint(1)
260/23: np.random.randint(1)
260/24: np.random.randint(1)
260/25: np.random.randint(1)
260/26: np.random.randint(1)
260/27: np.random.randint(1)
260/28: import torch
260/29: a=torch.rand(5)
260/30: a
260/31: type(a)
260/32: b=np.arange(4)
260/33: type(b)
260/34: type(a)==torch.Tensor
260/35: type(a)==torch.Tensora
260/36: type(a)==np.ndarray
260/37: type(b)==np.ndarray
260/38: from star_removal.evaluate import plot_dataset_diff
260/39: from star_removal.evaluate import plot_dataset_diff
260/40: from star_removal.evaluate import plot_dataset_diff
260/41: from star_removal.evaluate import plot_dataset_diff
260/42: a=im_stars[None,None,:,:]
260/43: a.shape
260/44: a[0,0].shape
260/45: a=im_stars[None,None]
260/46: a.shape
260/47: plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th=20,bs=1)
260/48: plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/49: plt.close()
260/50: plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/51: im_stars, x0s, y0s, amps = _synthetize_stars(np.random.randint(10,26),max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='new')
260/52: plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/53: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='new')
260/54: plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/55: plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/56: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='new'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/57: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='new'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/58: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='new'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/59: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='new'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/60: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='new'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/61: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='new'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/62: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='new'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/63: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='new'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/64: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='new'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/65: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='new'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/66: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='new'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/67: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='new'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/68: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='new'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/69: x0s
260/70: y0s
260/71: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='new'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/72: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/73: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/74: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/75: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/76: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/77: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/78: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/79: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/80: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/81: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=0,min_x0=0,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/82: a=1
260/83: a
260/84: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/85: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/86: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/87: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/88: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/89: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/90: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/91: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/92: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/93: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/94: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/95: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/96: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/97: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/98: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/99: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/100: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/101: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_amplitude=3e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/102: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=1e5,min_amplitude=1e5,min_y0=100,min_x0=100,max_y0=100,max_x0=100,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
260/103: im_stars, x0s, y0s, amps = _synthetize_stars(1,max_amplitude=3e5,min_amplitude=3e5,min_y0=10,min_x0=10,max_y0=10,max_x0=10,add_noise=False,version=4.3,wavelength='LW',period='old'); plot_dataset_diff(im_stars[None,None],np.zeros((1,1,256,6)),th1=20,bs=1)
261/1: %run forward.py
261/2: plt.imshow(true_intensity)
261/3: plt.imshow(meas)
261/4: plt.imshow(meas[1])
261/5: plt.imshow(meas[0])
261/6: plt.imshow(meas[2])
261/7: plt.imshow(true_intensity)
261/8: plt.imshow(true_doppler)
261/9: plt.imshow(true_linewidth)
261/10: %run forward.py
261/11: %run forward.py
261/12: plt.imshow(true_linewidth)
261/13: plt.imshow(meas[2])
261/14: plt.imshow(meas[1])
261/15: plt.imshow(meas[0])
261/16: plt.imshow(true_intensity)
261/17: plt.imshow(meas[1])
261/18: plt.imshow(true_linewidth)
261/19: plt.imshow(meas[1])
261/20: a=1
261/21: %run forward.py
261/22: plt.imshow(true_linewidth)
261/23: meas.shape
261/24: plt.imshow(meas[1])
261/25: plt.imshow(meas[0])
261/26: plt.imshow(meas[2])
261/27: plt.imshow(meas[1])
261/28: plt.imshow(meas[2])
261/29: plt.imshow(meas[1])
261/30: plt.imshow(meas[0])
261/31: plt.imshow(meas[1])
261/32: %run forward.py
261/33: plt.imshow(meas[1])
261/34: plt.imshow(meas[2])
261/35: plt.imshow(meas[1])
261/36: plt.imshow(meas[2])
261/37: plt.imshow(meas[0])
261/38: plt.imshow(meas[1])
261/39: plt.imshow(true_doppler)
261/40: plt.imshow(true_linewidth)
261/41: plt.imshow(meas[1])
262/1: %run forward.py
262/2: plt.imshow(meas[1])
262/3: plt.imshow(meas[2])
262/4: plt.imshow(meas[1])
262/5: plt.figure(); plt.imshow(meas[2])
263/1: a=np.zeros((3,4,5))
263/2: a=a.transpose(1,2,0)
263/3: a.shape
265/1: from platform import python_version
265/2: python_version()
266/1: from platform import python_version
266/2: python_version()
267/1: from slitless.forward import forward_op
268/1: cd ../scripts/
268/2: %run ../slitless/forward.py
268/3: %run ../slitless/forward.py
268/4: meas.shape
268/5: plt.imshow(meas[0])
268/6: plt.imshow(meas[1])
268/7: plt.imshow(meas[2])
268/8: %load_file forward_experiments.py
268/9: %cell_run cell1
268/10: %cell_run cell2
268/11: %cell_run impulse
268/12: %cell_run impulse
268/13: %cell_run impulse
268/14: meas.shape
268/15: %cell_run impulse
268/16: %cell_run impulse
268/17: %cell_run impulse
268/18: %cell_run impulse
268/19: %cell_run impulse
268/20: %cell_run impulse
268/21: fig.get_size_inches()
268/22: %cell_run impulse
268/23: %cell_run impulse
268/24: %cell_run impulse
268/25: %cell_run impulse
269/1: %load_file forward_experiments.py
269/2: %cell_run ^impulse
269/3: a=np.zeros((5,1))
269/4: a[[3]]=1
269/5: a
269/6: a[[3,4]]=1
269/7: a
269/8: a[[3,4]]=[2,3]
269/9: a[[3,4]]=[[2,3]]
269/10: a[[3,4]]=[[2],[3]]
269/11: a
269/12: a[[3,4]]=[[2,3]].T
269/13: a[[3,4]]=np.array([[2,3]])
269/14: a[[3,4]]=np.array([[2,3]]).T
269/15: np.where(a>0)
269/16: a.shape
269/17: np.where(a>0)[0]
269/18: a>0
269/19: (a>0).astype(int)
269/20: %cell_run impulse
269/21: %cell_run impulse
269/22: true_doppler
269/23: true_intensity
269/24: true_intensity
269/25: true_doppler = (true_intensity>0).astype(int)
269/26: true_doppler
269/27: true_doppler[k] = np.array([[0.5,-0.5]]).T
269/28: true_doppler
269/29: k
269/30: true_linewidth
269/31: %cell_run impulse
269/32: %cell_run impulse
269/33: %cell_run impulse
269/34: %cell_run impulse
269/35: %cell_run impulse
269/36: %cell_run impulse
269/37: %run ../slitless/forward.py
269/38: plt.imshow(meas[2])
269/39: plt.imshow(meas[2]+meas[1])
269/40: plt.figure(); plt.imshow(meas[0])
269/41: plt.figure(); plt.imshow(meas[1]+meas[2])
269/42: plt.figure(); plt.imshow(meas[0])
269/43: %run ../slitless/forward.py
269/44: plt.figure(); plt.imshow(meas[0])
269/45: plt.figure(); plt.imshow(meas[1]+meas[2])
269/46: %run ../slitless/forward.py
269/47: plt.figure(); plt.imshow(meas[0])
269/48: plt.figure(); plt.imshow(meas[1]+meas[2])
269/49: plt.figure(); plt.imshow(true_doppler)
269/50: plt.colorbar()
269/51: plt.figure(); plt.imshow(true_intensity); plt.colorbar()
269/52: plt.figure(); plt.imshow(true_linewidth); plt.colorbar()
269/53: plt.figure(); plt.imshow(meas[1]+meas[2])
269/54: plt.figure(); plt.imshow(meas[0])
269/55: %cell_run impulse
269/56: %cell_run impulse
269/57: %cell_run impulse
269/58: plt.figure(); plt.imshow(meas[0])
269/59: %cell_run impulse
269/60: %cell_run impulse
269/61: %cell_run impulse
269/62: %cell_run impulse
269/63: %cell_run impulse
270/1: %load_file forward_experiments.py
270/2: %cell_run ^impulse
271/1: %load_file forward_experiments.py
271/2: %cell_run ^impulse
272/1: ls
272/2: import os
272/3: ls data
272/4: ls saved
272/5: amo=os.path.join('./','2021_12_06__12_16_16_NF_4_LR_0.001_EP_2')
272/6: amo
272/7: amo
273/1:
def foo(x):
    x = x.transpose(0,2,1)
273/2: a=np.zeros((3,2,1))
273/3: foo(a)
273/4: a.shape
274/1: import os
274/2: os.path.join('asd\asd','amo')
274/3: import glob
274/4: glob.glob('*')
274/5: from iconfuv.artifact_removal2 import foo
274/6: from iconfuv.artifact_removal2 import foo
274/7: from iconfuv.artifact_removal2 import foo
274/8: from iconfuv.artifact_removal2 import foo
274/9: foo()
274/10: foo()
274/11: pwd
274/12: cd resources/icon-fuv/python3/scripts/
274/13: %run artifact_removal_tester.py
274/14: %run artifact_removal_tester.py
274/15: %run artifact_removal_tester.py
274/16: %run artifact_removal_tester.py
274/17: ipdb.pm()
274/18: ipdb.pm()
274/19: %run artifact_removal_tester.py
274/20: %run artifact_removal_tester.py
274/21: %run artifact_removal_tester.py
274/22: %run artifact_removal_tester.py
274/23: %run artifact_removal_tester.py
274/24: %run artifact_removal_tester.py
274/25: %run artifact_removal_tester.py
274/26: %run artifact_removal_tester.py
274/27: ipdb.pm()
274/28: %run artifact_removal_tester.py
275/1: %run artifact_removal_tester.py
275/2: %run artifact_removal_tester.py
275/3: %run artifact_removal_tester.py
275/4: %run artifact_removal_tester.py
275/5: %run artifact_removal_tester.py
275/6: %run artifact_removal_tester.py
275/7: %run artifact_removal_tester.py
275/8: %run artifact_removal_tester.py
275/9: %run artifact_removal_tester.py
275/10: %run artifact_removal_tester.py
276/1: %run artifact_removal_tester.py
276/2: %run artifact_removal_tester.py
276/3: %run artifact_removal_tester.py
276/4: %run artifact_removal_tester.pyi
276/5: %run artifact_removal_tester.py
276/6: %run artifact_removal_tester.py
276/7: %run artifact_removal_tester.py
276/8: %run artifact_removal_tester.py
276/9: %run artifact_removal_tester.py
276/10: %run artifact_removal_tester.py
276/11: %run artifact_removal_tester.py
277/1: %run artifact_removal_tester.py
278/1: %run artifact_removal_tester.py
278/2: %run artifact_removal_tester.py
278/3: %run artifact_removal_tester.py
278/4: profiles.shape
278/5: plt.imshow(profiles[3,:,1000:2000], origin='lower', aspect='auto')
278/6: plt.imshow(profiles[3], origin='lower', aspect='auto')
278/7: plt.imshow(profiles[0], origin='lower', aspect='auto')
278/8: plt.imshow(br00[0], origin='lower', aspect='auto')
278/9: plt.imshow(br00, origin='lower', aspect='auto')
278/10: plt.imshow(br00[:,:,0].T, origin='lower', aspect='auto')
278/11: plt.imshow(br2[:,:,0].T, origin='lower', aspect='auto')
278/12: plt.imshow(br1[:,:,0].T, origin='lower', aspect='auto')
278/13: plt.imshow(br00[:,:,0].T, origin='lower', aspect='auto')
278/14: plt.imshow(br1[:,:,0].T, origin='lower', aspect='auto')
278/15: type(br00)
278/16: br00.mask.shape
278/17: plt.imshow(br00.mask[:,:,0].T, origin='lower', aspect='auto')
278/18: np.ma.is_masked(br00)
278/19: %run artifact_removal_tester.py
278/20: %run artifact_removal_tester.py
278/21: %run artifact_removal_tester.py
278/22: %run artifact_removal_tester.py
278/23: %run artifact_removal_tester.py
278/24: %run artifact_removal_tester.py
278/25: %run artifact_removal_tester.py
278/26: %run artifact_removal_tester.py
279/1: %run artifact_removal_tester.py
279/2: %run artifact_removal_tester.py
279/3: %run artifact_removal_tester.py
279/4: %run artifact_removal_tester.py
279/5: %run artifact_removal_tester.py
279/6: %run artifact_removal_tester.py
279/7: %run artifact_removal_tester.py
279/8: %run artifact_removal_tester.py
279/9: %run artifact_removal_tester.py
279/10: %run artifact_removal_tester.py
279/11: %run artifact_removal_tester.py
279/12: %run artifact_removal_tester.py
279/13: %load_file artifact_removal_tester.py
279/14: %cell_run plot
279/15: %cell_run plot
279/16: %cell_run plot
279/17: %cell_run plot
279/18: %cell_run plot
279/19: %run artifact_removal_tester.py
279/20: %cell_run plot
279/21: %cell_run plot
279/22: %cell_run plot
279/23: %run artifact_removal_tester.py
279/24: import keras
279/25: keras.__version__
279/26: import torch
279/27: torch.__version__
279/28: import torchvision
279/29: torchvision.__version__
285/1: import keras
286/1: import keras
287/1: import keras
288/1: %run artifact_removal_tester.py
288/2: %run artifact_removal_tester.py
288/3: %run artifact_removal_tester.py
288/4: %run artifact_removal_tester.py
288/5: %run artifact_removal_tester.py
289/1: import torch
290/1: import torch
291/1: import torch
291/2: %run artifact_removal_tester.py
291/3: %run artifact_removal_tester.py
291/4: %run artifact_removal_tester.py
291/5: %run artifact_removal_tester.py
292/1: %run artifact_removal_tester.py
293/1: %run artifact_removal_tester.py
293/2: model_keras
293/3: load_model
293/4: model = load_model(model_keras)
294/1: %run artifact_removal_tester.py
295/1: %run artifact_removal_tester.py
296/1: %run artifact_removal_tester.py
297/1: %run artifact_removal_tester.py
297/2: %run artifact_removal_tester.py
298/1: import torch
299/1: %run artifact_removal_tester.py
299/2: br00.shape
299/3:
stripe = 3
epoch = 540
f, ax = plt.subplots(2, 2, figsize=(12.7, 7.3))
plt.suptitle("{} , Channel: {} , Stripe: {}".format(date, channel, stripe))
i1 = ax[0, 0].imshow(
    br00[:, :, stripe].T,
    aspect="auto",
    origin="lower",
    cmap="jet",
    vmax=vmax,
    vmin=vmin,
)
ax[0, 0].set_title("Starry")
i2 = ax[0, 1].imshow(
    br1[:, :, stripe].T, aspect="auto", origin="lower", cmap="jet", vmax=vmax, vmin=vmin
)
ax[0, 1].set_title("Artifact Removed")
ax[0, 1].axvline(epoch, color="m")
i3 = ax[1, 0].imshow(
    -(br00 - br1)[:, :, stripe].T,
    aspect="auto",
    origin="lower",
    cmap="jet",
    vmax=10,
    vmin=-20,
)
ax[1, 0].set_title("Difference: Artifact Removed - Starry")
ax[1, 1].plot(br1[epoch, :, stripe], np.arange(256), label="Artifact Removed")
ax[1, 1].plot(br00[epoch, :, stripe], np.arange(256), label="Starry (Raw)")
ax[1, 1].set_title("1D Profiles for Daytime Epoch: {}".format(epoch))
ax[1, 1].legend()
ax[1, 1].grid(axis="both", which="both")
plt.colorbar(i1, ax=ax[0, 0])
plt.colorbar(i2, ax=ax[0, 1])
plt.colorbar(i3, ax=ax[1, 0])
# f.colorbar(im, ax=ax.ravel().tolist())
plt.tight_layout()
plt.show()
299/4: plt.plot(np.arange(4))
299/5: plt.show()
301/1: %run artifact_removal_tester.py
301/2: torch.cuda.is_available()
301/3: %load_file artifact_removal_tester.py
301/4: %cell_run plot
301/5: %run artifact_removal_tester.py
301/6: %cell_run plot
302/1: %run artifact_removal_tester.py
302/2: device
302/3: %run artifact_removal_tester.py
302/4: %run artifact_removal_tester.py
302/5: %run artifact_removal_tester.py
302/6: %run artifact_removal_tester.py
303/1: %run artifact_removal_tester.py
303/2: brs
303/3: artifact_removal_variables = {}
303/4: artifact_removal_variables['input_profiles'] = profiles
303/5: profiles.shape
303/6: channelnum
303/7: artifact_removal_variables['channel'] = 1
303/8: artifact_removal_variables['fuv_mode'] = mode
303/9: mode.shape
303/10: profiles_clean.shape
303/11: artifact_removal_variables['output_profiles'] = profiles_clean
303/12: artifact_removal_variables
303/13:
with open('artifact_removal_variables.pickle', 'wb') as handle:
    pickle.dump(artifact_removal_variables, handle)
303/14: import pickle
303/15:
with open('artifact_removal_variables.pickle', 'wb') as handle:
    pickle.dump(artifact_removal_variables, handle)
303/16:
with open('artifact_removal_variables.pickle', 'rb') as handle:
    b=pickle.load(handle)
303/17: b==artifact_removal_variables
303/18: type(b)
303/19: print(b==artifact_removal_variables)
303/20: b==artifact_removal_variables
303/21: b.keys()
303/22: artifact_removal_variables.keys()
303/23: b['output_profiles']==artifact_removal_variables['output_profiles']
303/24: b['output_profiles'].shape
303/25: plt.imshow(b['output_profiles'][3][:,:300], aspect='auto')
303/26: plt.imshow(b['input_profiles'][3][:,:300], aspect='auto')
303/27: plt.imshow(b['output_profiles'][3][:,:300], aspect='auto')
303/28: plt.imshow(artifact_removal_variables['output_profiles'][3][:,:300], aspect='auto')
303/29: plt.imshow(artifact_removal_variables['input_profiles'][3][:,:300], aspect='auto')
303/30: plt.imshow(artifact_removal_variables['output_profiles'][3][:,:300], aspect='auto')
303/31: type(artifact_removal_variables['output_profiles'])
303/32: type(artifact_removal_variables['input_profiles'])
303/33: type(b['input_profiles'])
303/34: type(b['output_profiles'])
303/35: np.nan==np.nan
303/36: artifact_removal_variables.keys()
304/1: import pandas
304/2: import pandas as pd
304/3: a=pd.DataFrame('hmF2':[], 'nmF2':[])
304/4: a=pd.DataFrame(columns=['a','b'])
304/5: a
304/6: a['a']=[1,2,3]
304/7: a
304/8: a['b']=[1,2,3]
304/9: a
304/10: pwd
304/11: file = '/home/kamo/resources/icon-fuv/ncfiles/l2/2020/ICON_L2-5_FUV_Night_2020-01-01_v04r000.NC'
304/12: import netCDF4
304/13: l2 = netCDF4.Dataset(file, 'r')
304/14: l2.variables.keys()
304/15: print(list(l2.variables.keys()))
304/16: list(l2.variables.keys())
304/17: l2.variables['ICON_L25_HMF2'][:].shape
304/18: l2.variables['ICON_L25_Magnetic_Latitude'][:].shape
304/19: l2.variables['ICON_L25_Quality'][:].shape
304/20: l2.variables['ICON_L25_UTC_Time'][:].shape
304/21: l2.variables['ICON_L25_Local_Solar_Time'][:].shape
304/22: l2.variables['ICON_L25_Local_Solar_Time'][2,2]
304/23: l2.variables['ICON_L25_Magnetic_Latitude'][2,2]
304/24: l2.variables['ICON_L25_Magnetic_Latitude']
304/25: %run hmf2_variability_plotter.py
304/26: %run hmf2_variability_plotter.py
304/27: file_l2
304/28: file_l2
304/29: %run hmf2_variability_plotter.py
304/30: np.nanmedian(np.array([np.nan,np.nan]))
304/31: hmf2_n.shape
304/32: hmf2.shape
304/33: condition_n.shape
304/34: plt.imshow(condition_n.T, aspect='auto')
304/35: hmf2_n.shape
304/36: hmf2_n[0]
304/37: np.isnan(hmf2_n[0])
304/38: sum(np.isnan(hmf2_n[:]))
304/39: sum(not np.isnan(hmf2_n[:]))
304/40: sum(!np.isnan(hmf2_n[:]))
304/41: sum(1-np.isnan(hmf2_n[:]))
304/42: amo = hmf2_n[1-np.isnan(hmf2_n)]
304/43: amo.shape
304/44: amo = hmf2_n[1-np.isnan(hmf2_n[:])]
304/45: amo.shape
304/46: hmf2_n[0]
304/47: amo = hmf2_n[np.invert(np.isnan(hmf2_n[:]))]
304/48: amo.shape
304/49: amo = hmf2_n[np.invert(np.isnan(hmf2_n))]
304/50: amo.shape
304/51: %run hmf2_variability_plotter.py
304/52: amo = np.where(np.invert(np.isnan(hmf2_n)))[0]
304/53: amo.shape
304/54: %run hmf2_variability_plotter.py
305/1: %run hmf2_variability_plotter.py
305/2: len(times_hn)
305/3: len(times_hn[0])
305/4: len(times_hn[1])
305/5: len(hmf2s_n[0])
305/6: len(hmf2s_n[1])
305/7: len(times_hn[:])
305/8: amo=np.array(hmf2s_n)
305/9: amo.shape
305/10: %run hmf2_variability_plotter.py
305/11: times_hn.shape
305/12: hmf2s_n.shape
305/13: times_hs.shape
305/14: hmf2s_s.shape
305/15: times_ns.shape
305/16: nmf2s_s.shape
305/17: times_nh.shape
305/18: times_nn.shape
305/19: nmf2s_n.shape
305/20: plt.scatter(times_hs, hmf2s_s)
305/21: plt.scatter(times_hn, hmf2s_n)
305/22: plt.scatter(times_hs, hmf2s_s)
305/23: plt.scatter(times_hs)
305/24: plt.scatter(times_hs, np.zeros_like(times_hs))
305/25: plt.scatter(times_hn, np.zeros_like(times_hn))
305/26: plt.grid(axis='both',minor=True)
305/27: plt.grid(axis='both')
305/28: plt.grid(axis='x')
305/29: plt.grid(axis='x', which='minor')
305/30: plt.grid(axis='y', which='minor')
305/31: amo = times_hn
305/32: type(amo)
305/33: amo1=np.diff(amo)
305/34: amo[0:3]
305/35: amo1[0:3]
305/36: import datetime
305/37: amo1[0]>datetime.timedelta(days=1)
305/38: amo1[0]>datetime.timedelta(seconds=1)
305/39: amo1.shape
305/40: amo.shape
305/41: indo = np.where(amo1>datetime.timedelta(days=7))
305/42: indo = np.where(amo1>datetime.timedelta(days=7))[0]
305/43: len(indo)
305/44: indo
305/45: plt.scatter(times_hn, np.zeros_like(times_hn))
305/46:
for i in indo:
    plt.axvline(times_hn[i])
305/47: amos = times_hs
305/48: amos1=np.diff(amos)
305/49: indos = np.where(amos1>datetime.timedelta(days=15))[0]
305/50: len(indo)
305/51: len(indos)
305/52: plt.scatter(times_hs, np.zeros_like(times_hs))
305/53:
for i in indos:
    plt.axvline(times_hs[i])
305/54: np.median(times_hn)
305/55: np.mean(times_hn)
305/56: np.mean(amo1)
305/57: len(amo1)
306/1: %run hmf2_variability_plotter.py
306/2: %run hmf2_variability_plotter.py
306/3: %run hmf2_variability_plotter.py
306/4: np.min(times_n)
306/5: times_n[0]
306/6: diff = np.diff(times_n)
306/7: med = np.median(diff)
306/8: med
306/9: inds = np.where(diff>datetime.timedelta(days=7))[0]
306/10: import datetime
306/11: inds = np.where(diff>datetime.timedelta(days=7))[0]
306/12: len(inds)
306/13: plt.scatter(times_hn, np.zeros_like(times_hn))
306/14: plt.scatter(times_n, np.zeros_like(times_n))
306/15:
for i in inds:
    plt.axvline(times_n[i])
306/16: plt.scatter(times_n, np.zeros_like(times_n))
306/17:
for i in inds:
    plt.axvline(times_n[i+1])
306/18: plt.scatter(times_n, np.zeros_like(times_n))
306/19:
for i in inds:
    plt.axvline(times_n[i+1])
306/20: np.append(0,np.ones(4))
306/21: inds = np.append(0, np.where(diff>datetime.timedelta(days=7))[0]+1)
306/22: plt.scatter(times_n, np.zeros_like(times_n))
306/23:
for i in inds:
    plt.axvline(times_n[i])
306/24: np.append(0,np.ones(4),4)
306/25: np.appen(d(0,np.ones(4),4))
306/26: np.append((0,np.ones(4),4))
306/27: inds = np.append(np.append(0, np.where(diff > dateutil.timedelta(days=7))[0] + 1), len(times))
306/28: inds = np.append(np.append(0, np.where(diff > datetime.timedelta(days=7))[0] + 1), len(times))
306/29: plt.scatter(times_n, np.zeros_like(times_n))
306/30:
for i in inds:
    plt.axvline(times_n[i])
306/31: inds = np.append(np.append(0, np.where(diff > datetime.timedelta(days=7))[0] + 1), len(times_n))
306/32: plt.scatter(times_n, np.zeros_like(times_n))
306/33:
for i in inds:
    plt.axvline(times_n[i])
306/34: np.pad(np.zeros(4), (1,2))
306/35: np.pad(np.zeros(4), (1,1), mode='constant', constant_values=(1,2))
306/36:
def clusterer(vals, times, gap=7):
    diff = np.diff(times)
    inds = np.append(np.append(0, np.where(diff > dateutil.timedelta(days=gap))[0] + 1), len(times))
    medvals = []
    medtimes = []
    for i in range(len(inds)-1):
        medvals.append(np.median(vals[inds[i]:inds[i+1]]))
        medtimes.append(timemedian(times[inds[i]:inds[i+1]]))
    return medvals, medtimes

def timemedian(times):
    return np.min(times) + np.median(times - np.min(times))
306/37: medvals, medtimes = clusterer(hmf2s_n, times_n, gap=7)
306/38:
def clusterer(vals, times, gap=7):
    diff = np.diff(times)
    inds = np.append(np.append(0, np.where(diff > datetime.timedelta(days=gap))[0] + 1), len(times))
    medvals = []
    medtimes = []
    for i in range(len(inds)-1):
        medvals.append(np.median(vals[inds[i]:inds[i+1]]))
        medtimes.append(timemedian(times[inds[i]:inds[i+1]]))
    return medvals, medtimes

def timemedian(times):
    return np.min(times) + np.median(times - np.min(times))
306/39: medvals, medtimes = clusterer(hmf2s_n, times_n, gap=7)
306/40: len(medvals)
306/41: plt.scatter(times_hn, hmf2s_n)
306/42: plt.scatter(times_n, hmf2s_n)
306/43: plt.scatter(medtimes, medvals)
306/44:
med_hmf2s_n, medtimes_n = clusterer(hmf2s_n, times_n, gap=7)
med_hmf2s_s, medtimes_s = clusterer(hmf2s_s, times_s, gap=12)
med_nmf2s_n, _ = clusterer(nmf2s_n, times_n, gap=7)
med_nmf2s_s, _ = clusterer(nmf2s_s, times_s, gap=12)
306/45: plt.scatter(times_n, hmf2s_n)
306/46: plt.scatter(times_n, hmf2s_n, c='r')
306/47: plt.scatter(medtimes_n, med_hmf2s_n, c='k')
306/48: plt.scatter(times_s, hmf2s_s, c='b')
306/49: plt.scatter(medtimes_s, med_hmf2s_s, c='k')
306/50: plt.scatter(times_s, hmf2s_s, c='b', linewidth=0.5)
306/51: plt.scatter(times_s, hmf2s_s, c='b', linewidth=0.1)
306/52: plt.scatter(times_s, hmf2s_s, c='b', s=1)
306/53: plt.scatter(times_s, hmf2s_s, c='b', s=10)
306/54: plt.scatter(medtimes_s, med_hmf2s_s, c='k', s=10)
306/55: plt.scatter(times_n, hmf2s_n, c='r', s=10)
306/56: plt.scatter(medtimes_n, med_hmf2s_n, c='k', s=40)
306/57: plt.scatter(medtimes_s, med_hmf2s_s, c='k', s=40)
307/1: %run hmf2_variability_plotter.py
307/2: %run hmf2_variability_plotter.py
307/3: sumsum
307/4: file = '/home/kamo/resources/icon-fuv/ncfiles/l2/2020/ICON_L2-5_FUV_Night_2020-01-01_v04r000.NC'
307/5: import netCDF4
307/6: l2 = netCDF4.Dataset(file, 'r')
307/7: l2.variables['ICON_L25_O_Plus_Density']
307/8: plt.plot(l2.variables['ICON_L25_O_Plus_Density'][100,:,3])
307/9: plt.plot(l2.variables['ICON_L25_O_Plus_Profile_Altitude'][100,:,3])
307/10: plt.plot(l2.variables['ICON_L25_O_Plus_Profile_Altitude'][100,:,3])
307/11: plt.imshow(l2.variables['ICON_L25_O_Plus_Density'][50:150,:,3], aspect='auto')
307/12: l2.dimensions
307/13: l2.dimensions['Altitude']
307/14: l2.dimensions['Altitude'].size
307/15: np.arange(15)[:-4:]
307/16: np.arange(15)[-4:]
307/17: a = np.arange(24).reshape(4,6)
307/18: a
307/19: np.where(a>16)
307/20: ind=np.where(a>16)
307/21: a[ind]
307/22: amo = a>16
307/23: np.where(amo)
307/24: a%2==0
307/25: inn=(a[amo]%2==0)
307/26: inn
307/27: a[amo[inn]]
307/28: a[amo][inn]
307/29: amo
307/30: np.where(amo)[inn]
307/31: amo2 = [i[inn] for i in amo]
307/32: amo2 = [i[inn] for i in np.where(amo)]
307/33: amo2
307/34: a[amo2)
307/35: a[amo2]
307/36: amo2
307/37: a[tuple(amo2)]
307/38: np.zeros(4)
307/39: amo
307/40: np.invert(amo)
307/41: a = [[],[]]
307/42: a
307/43: np.empty((4,None))
307/44: np.empty((4,2))
307/45: a=np.empty((4,2))
307/46: a
307/47: a[2,1] = np.zeros(4)
307/48: a=[[[]]]
307/49: a=[[[]*2]*2]*2
307/50: len(a)
307/51: np.array(a).shape
307/52: a=np.empty((4,0))
307/53: a[2]=np.zeros(6)
307/54: []*2
307/55: []*5
307/56: [1]*5
307/57: a=[[[]]]
307/58: np.array(a).shape
307/59: a=[[[[]*2]*2]*2]
307/60: np.array(a).shape
307/61: a=[[[[]*2]*2]*2]*2
307/62: np.array(a).shape
307/63: a=[[[[]*2]*2]*2]*5
307/64: np.array(a).shape
307/65: a=[[[[]*6]*2]*2]*2
307/66: np.array(a).shape
307/67: a=[[[[]]*2]*2]*2
307/68: np.array(a).shape
307/69: %run hmf2_variability_plotter.py
307/70: %run hmf2_variability_plotter.py
307/71: a = np.arange(5)
307/72: b = a + 3
307/73: a>b
307/74: %run hmf2_variability_plotter.py
307/75: %run hmf2_variability_plotter.py
307/76: ipd.pm()
307/77: ipdb.pm()
307/78: %run hmf2_variability_plotter.py
307/79: ipdb.pm()
307/80: %run hmf2_variability_plotter.py
307/81: times[1][0][0].shape
307/82: len(times[1][0][0])
307/83: len(times[1][0][1])
307/84: len(times[1][1][0])
307/85: len(hmf2s[1][1][0])
307/86: plt.scatter(times[0,0,0], hmf2s[0,0,0], c='r', s=10)
307/87: plt.scatter(times[0][0][0], hmf2s[0][0][0], c='r', s=10)
307/88: plt.scatter(times[1][0][0], hmf2s[1][0][0], c='b', s=10)
307/89:
for l1 in [0,1]:
    l1==1
307/90:
for l1 in [0,1]:
    print(l1==1)
307/91: condition_n.shape
307/92: cond_n.shape
307/93: np.sum(condition_n)
307/94: np.sum(cond_n)
307/95: np.sum(conditionl1_n)
307/96: hmf2s[0][0][0].shape
307/97: len(hmf2s[0][0][0])
307/98: len(hmf2s[0][1][0])
307/99: len(hmf2s[0][0][0])
307/100: len(hmf2s[0][0][1])
307/101: len(hmf2s[1][0][0])
307/102: np.allclose(hmf2s[1][0][0], hmf2s[0][1][1])
307/103: %run hmf2_variability_plotter.py
308/1: %run hmf2_variability_plotter.py
308/2: hmf2s[0][0][0].shape
308/3: np.allclose(hmf2s[1][0][0], hmf2s[0][1][1])
308/4: plt.scatter(times[1][0][0], hmf2s[1][0][0], c='b', s=10)
308/5: np.sum(conditionl1_n)
308/6: np.sum(condition_n)
308/7: np.sum(cond_n)
308/8: cond_n.shape
308/9: plt.scatter(times[1][0][0], hmf2s[1][0][0], c='b', s=10)
308/10: %run hmf2_variability_plotter.py
308/11: cond_n.shape
308/12: np.sum(cond_n)
308/13: np.sum(condition_n)
308/14: np.sum(conditionl1_n)
308/15: np.sum(condition_s)
308/16: np.sum(conditionl1_s)
308/17: len(hmf2s[1][1][1])
308/18: len(hmf2s[1][0][1])
308/19: len(hmf2s[1][0][0])
308/20: len(hmf2s[0][0][0])
308/21: condition_n
308/22: np.sum(condition_n)
308/23: np.sum(conditionl1_n)
308/24: hmf2[cond_n].shape
308/25: %run hmf2_variability_plotter.py
308/26: a=[[[]]*2]*2
308/27: a
308/28: np.array(a).shape
308/29: a[1,1].expand(np.zeros(4))
308/30: a[1][1].expand(np.zeros(4))
308/31: a[1][1].extend(np.zeros(4))
308/32: len(a[0][1])
308/33: a[0][1]
308/34: a[0][0]
308/35: a= [[[], []], [[], []]]
308/36: a[1][1].extend(np.zeros(4))
308/37: a[0][0]
308/38: a[1][1]
308/39: a=[[[[]]*2]*2]*2
308/40: a
308/41: %run hmf2_variability_plotter.py
308/42: %run hmf2_variability_plotter.py
308/43: len(hmf2s[0][0][0])
308/44: len(hmf2s[1][0][0])
308/45: %run hmf2_variability_plotter.py
308/46: len(hmf2s[1][0][0])
308/47: len(hmf2s[1][1][0])
308/48: len(hmf2s[1][1][1])
308/49: len(hmf2s[1][0][1])
308/50: %run hmf2_variability_plotter.py
308/51: len(hmf2s[0][1][1])
308/52: len(hmf2s[0][0][1])
308/53: len(hmf2s[0][0][0])
308/54: len(hmf2s[0][1][0])
308/55: a,b=clusterer(hmf2s[1][1][1],times[1][1][1], gap=7)
308/56: a,b=clusterer(hmf2s[1][1][1],np.array(times[1][1][1]), gap=7)
308/57: plt.scatter(times[1][1][1], hmf2s[1][1][1], c='r', s=10)
308/58: plt.scatter(b,a, c='r', s=40)
308/59: plt.scatter(b,a, c='k', s=40)
308/60: a=np.array(times)
308/61: a=np.array(times, dtype=object)
308/62: a,b=clusterer(hmf2s[1][1][1],a[1][1][1], gap=7)
308/63: a,b=clusterer(hmf2s[1][1][1],np.array(times[1][1][1]), gap=7)
308/64: plt.scatter(b,a, c='k', s=40)
308/65: from scipy import interpolate
308/66: f = interpolate.interp1d(b,a)
308/67: xx = np.linspace(b[0],b[-1],100)
308/68: plt.plot(b,a)
308/69: plt.scatter(times[1][1][1], hmf2s[1][1][1], c='r', s=10)
308/70: plt.plot(b,a, linewidth=2, c='r')
308/71: plt.scatter(b,a, c='k', s=40)
308/72: plt.plot(b,a, linewidth=3, c='r')
308/73: plt.scatter(b,a, c='k', s=40)
308/74: %load_file hmf2_variability_plotter.py
308/75: %cell_run plot
308/76: %cell_run plot
308/77: %run hmf2_variability_plotter.py
308/78: %run hmf2_variability_plotter.py
308/79: a=0
308/80: a = np.arange(4)>2
308/81: print(a[0])
308/82: a=np.array([0], dtype=bool)
308/83: print(a)
308/84: a=np.array(0, dtype=bool)
308/85: print(a)
308/86: %cell_run plot
308/87: %cell_run plot
308/88: %cell_run plot
308/89: ipdb.pm()
308/90: %cell_run plot
308/91: %cell_run plot
308/92: %cell_run plot
308/93: %cell_run plot
308/94: %cell_run plot
308/95: %cell_run plot
308/96: f, a = plt.figure()
308/97: f, a = plt.subplots()
308/98: %cell_run plot
308/99: %cell_run plot
308/100: plt.close('all')
308/101: %cell_run plot
308/102: plt.close('all')
309/1: import torch
309/2: import keras
310/1: %run train.py
310/2: %run train.py
310/3: %run train.py
310/4: a=3
310/5: print('%d', a)
310/6: %run train.py
310/7: %run train.py
310/8: %run train.py
311/1: %run train.py
313/1: mkdir train2
313/2: mkdir val2
313/3: import glob
313/4: t1 = glob.glob('train/*')
313/5: t1.sort()
313/6: amo = np.load(t1[0])
313/7: amo = np.load(t1[0], allow_pickle=True)
313/8: import pickle
313/9: pickle.dump(amo, open('amo.npy','wb'), protocol=2)
312/1: import pickle
312/2: pwd
312/3: ls
312/4: data = np.load('amo.npy', allow_pickle=True).item()
312/5: data['image_clean'].shape
314/1: import glob
314/2: t1 = glob.glob('train/*')
314/3: t1.sort()
314/4: import pickle
314/5:
for t in t1:
    d
    amo = np.load(t, allow_pickle=True)
    pickle.dump(amo, open(''))
314/6: t1[0]
314/7: t1[0][6:]
314/8:
for t in t1:
    amo = np.load(t, allow_pickle=True)
    pickle.dump(amo, open('train2/{}'.format(t[6:]), 'wb'), protocol=2)
314/9: t1 = glob.glob('val/*')
314/10: t1.sort()
314/11: t1[0][6:]
314/12: t1[0][]
314/13: t1[0]
314/14: t1[0][4:]
314/15:
for t in t1:
    amo = np.load(t, allow_pickle=True)
    pickle.dump(amo, open('val2/{}'.format(t[4:]), 'wb'), protocol=2)
315/1: %run train.py
315/2: cd ..
315/3: %run train.py
315/4: %run train.py
316/1: %run train.py
317/1: %run train.py
317/2: %run train.py
317/3: %run train.py
317/4: %run train.py
317/5: from unet_parts import DoubleConv
317/6: %run train.py
317/7: %run train.py
317/8: from star_removal.unet_parts import Up
317/9: %run train.py
317/10: import star_removal
317/11: star_removal.__path__
318/1: %run train.py
319/1: import torch.nn as nn
319/2: cc = nn.Conv2d(1,1,kernel_size=3, padding=1)
319/3: import torch
319/4: a = torch.random(1,64,64)
319/5: a = torch.rand(1,64,64)
319/6: b=cc(a)
319/7: a = torch.rand(1,1,64,64)
319/8: b=cc(a)
319/9: a.shape
319/10: b.shape
319/11: cc
319/12: %run train.py
319/13: %run train.py
320/1: ls
320/2: pwd
320/3: %run notebook.py
320/4: from tensorflow.keras.optimizers import schedules
320/5: from tensorflow.keras.optimizers import Adam
320/6: from tensorflow import keras
320/7: from tensorflow.keras import optimizers
320/8: from tensorflow.keras.optimizers import schedules
320/9: %run train.py
320/10: %run notebook.py
320/11: import sklearn
321/1: %run notebook.py
321/2: %run notebook.py
321/3: %run notebook.py
321/4: %run notebook.py
321/5: import tensorflow
321/6: tensorflow.version
321/7: tensorflow.__version__
322/1: a=None
322/2: b=None
322/3: a is None
322/4: a==None
322/5: a=3
322/6: assert a>2
322/7: assert a>4
322/8: assert a>4 "amoo"
322/9: assert a>4, "amoo"
322/10: a
322/11: b
322/12: b is None
322/13: b is not None
322/14: (b is not None) or (a is not None)
322/15: a=None
322/16: (b is not None) or (a is not None)
322/17: (b!=None) or (a!=None)
322/18: a=3
322/19: (b!=None) or (a!=None)
322/20: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-01-13_v04r000.NC'
322/21: import netCDF4
322/22: file2 = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-01-13_v04r009.NC'
322/23: cp file file2
322/24: cp '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-01-13_v04r000.NC' '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-01-13_v04r009.NC'
322/25: l1 = netCDF4.Dataset(file2, 'w')
322/26: l1.variables.keys()
322/27: l1 = netCDF4.Dataset(file2, 'r')
322/28: l1.variables.keys()
322/29: l1 = netCDF4.Dataset(file, 'r')
322/30: l1.variables.keys()
322/31: l1.close()
322/32: l1 = netCDF4.Dataset(file2, 'r')
322/33: l1.variables.keys()
322/34: cp '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-01-13_v04r000.NC' '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-01-13_v04r009.NC'
322/35: l1 = netCDF4.Dataset(file2, 'r')
322/36: l1.variables.keys()
322/37: l1.close()
322/38: l1 = netCDF4.Dataset(file2, 'w')
322/39: l1.variables.keys()
322/40: netCDF4.Dataset?
322/41: l1 = netCDF4.Dataset(file2, 'r+')
322/42: l1.variables.keys()
322/43: br = l1.variables['ICON_L1_FUVA_SWP_PROF_M6']
322/44: br2 = l1.createVariable('ICON_deneme', br.datatype, br.dimesions)
322/45: br.datatype
322/46: br.dimensions
322/47: br2 = l1.createVariable('ICON_deneme', br.datatype, br.dimesions)
322/48: l1.variables.items()
322/49: br.ncattrs()
322/50:
for n,v in l1.items()[:5]:
    print(n)
322/51:
for n,v in l1.items():
    print(n)
322/52:
for n,v in l1.variables.items()[:5]:
    print(n)
322/53:
for n,v in l1.variables.items():
    print(n)
322/54: br.dimensions
322/55: br.datatype
322/56: l1.createVariable?
322/57: l1.createVariable('asd', br.datatype, br.dimensions)
322/58: l1.variables.keys()
322/59: l1.variables['asd'][:]=br[:]
322/60: l1.variables['asd'].setncatts(l1.variables['ICON_L1_FUVA_SWP_PROF_M9'].__dict__)
322/61: br.__dict__
323/1: import netCDF4
323/2: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2021-01-13_v04r009.NC'
323/3: l1 = netCDF4.Dataset(file2, 'r+')
323/4: l1 = netCDF4.Dataset(file, 'r+')
323/5: br = l1.variables['ICON_L1_FUVA_SWP_PROF_M6']
323/6: br.fill_value
323/7: br
323/8: br.FILLVAL
323/9: l1.createVariable('asd', br.datatype, br.dimensions, fill_value=br.FILLVAL)
323/10: l1.variables['asd'].setncatts(l1.variables['ICON_L1_FUVA_SWP_PROF_M6'].__dict__)
323/11: l1.variables['asd'][:] = br[:]
325/1: import pyglow
326/1: import pyglow
327/1: from modify_l1 import rewriter
327/2: rewriter('2022-01-14')
327/3: rewriter('2022-01-14')
327/4: import torch
327/5: torch.cuda.is_available()
327/6: rewriter('2022-01-14')
327/7: rewriter('2022-01-15')
328/1: %run compare_l25s.py
328/2: pdb.pm()
328/3: %run compare_l25s.py
328/4: ipdb.pm()
328/5: %run compare_l25s.py
328/6: l2_new.close()
328/7: l2_old.close()
328/8: %run compare_l25s.py
328/9: ipdb.pm()
329/1: %run compare_l25s.py
329/2: ipdb.pm()
329/3: %run compare_l25s.py
329/4: ipdb.pm()
329/5: %run compare_l25s.py
329/6: a=np.arange(4)
329/7: np.repeat(a[:,np.newaxis],6,axis=1)
329/8:
l2_new.close()
l2_old.close()
330/1: %run compare_l25s.py
330/2: ipdb.pm()
330/3: %run compare_l25s.py
330/4: ipdb.pm()
330/5: %run compare_l25s.py
330/6:
l2_new.close()
l2_old.close()
330/7: %run compare_l25s.py
331/1: %run compare_l25s.py
331/2: %run compare_l25s.py
331/3: %run compare_l25s.py
331/4: %run compare_l25s.py
331/5: %run compare_l25s.py
331/6: ipdb.pm()
331/7: ipdb.pm()
332/1: %run compare_l25s.py
332/2: %run compare_l25s.py
332/3: time_new[-1]
332/4: time_new[-100]
332/5: time_new[-1000]
332/6: %run compare_l25s.py
332/7: time_new[0]
332/8: time_new.shape
332/9: time_new[1]
332/10: time_new[1000]
332/11: %run compare_l25s.py
332/12: %run compare_l25s.py
333/1: a=np.arange(4)
333/2: a=np.arange(4).astype(bool)
333/3: a
333/4: a=np.arange(4)
333/5: b=np.arange(6)-3
333/6: c=a[:,np.newaxis]-b[np.newaxis,:]
333/7: c
333/8: -c
333/9: b
333/10: a
333/11: np.argmin(np.abs(c), axis=1)
333/12: %run compare_l25s.py
333/13: %run compare_l25s.py
333/14: %run compare_l25s.py
333/15: time_new.shape
333/16: ref_inds0 = np.sum(time_new, axis=1)>0
333/17: ref_inds0 = np.sum(ind_new, axis=1)>0
333/18: ref_times0 = time_new[ref_inds0]
333/19: ref_times0.shape
333/20: ref_inds0.shape
333/21: diff = np.abs(time_old[np.newaxis,:] - ref_times0[:,np.newaxis])
333/22: diff.shape
333/23: inds0 = np.argmin(diff, axis=1)
333/24: inds0[100]
333/25: inds0[101]
333/26: diff[100,inds[100]]
333/27: diff[100,inds0[100]]
333/28: import datetime
333/29: diff[100,inds0[108]]
333/30: diff[100,inds0[108]]>datetime.timedelta(seconds=6)
333/31: diff[100,inds0[102]]>datetime.timedelta(seconds=6)
333/32: diff[100,inds0[101]]>datetime.timedelta(seconds=6)
333/33: diff[100,inds0[100]]>datetime.timedelta(seconds=6)
334/1: %run compare_l25s.py
334/2: ref_inds0 = np.sum(ind_new, axis=1)>0
334/3: ref_times0 = time_new[ref_inds0]
334/4: diff = np.abs(time_old[np.newaxis,:] - ref_times0[:,np.newaxis])
334/5: inds0 = np.argmin(diff, axis=1)
334/6: import datetime
334/7: inds1 = np.where(diff<datetime.timedelta(seconds=3))
334/8: inds0.shape
334/9: len(inds0)
334/10: len(inds1)
334/11: inds1[0].shape
334/12: inds1[1].shape
334/13: diff.shape
334/14: inds[0][:10]
334/15: inds1[0][:10]
334/16: inds1[1][:10]
334/17: inds1[0][-10:]
334/18: inds1[1][-10:]
335/1: %run compare_l25s.py
335/2: dst_inds = index_finder(ref_times=time_new, ref_inds=ind_new, dst_times=time_old)
335/3: %run compare_l25s.py
335/4: dst_inds = index_finder(ref_times=time_new, ref_inds=ind_new, dst_times=time_old)
335/5: %run compare_l25s.py
335/6: %run compare_l25s.py
335/7: %run compare_l25s.py
335/8: %run compare_l25s.py
336/1: %run compare_l25s.py
336/2: from hmf2_variability_plotter import clusterer
336/3: %run compare_l25s.py
336/4: %run compare_l25s.py
336/5: %run compare_l25s.py
336/6: %load_file compare_l25s.py
336/7: %cell_run plotting
336/8: %cell_run plotting
336/9: %cell_run plotting
336/10: %cell_run plotting
336/11: ind_new.shape
336/12: ind_old.shape
336/13: np.sum(ind_new)
336/14: np.sum(ind_old)
336/15: %run compare_l25s.py
336/16: %run compare_l25s.py
336/17: %run compare_l25s.py
336/18: %run compare_l25s.py
336/19: %run compare_l25s.py
336/20: %run compare_l25s.py
336/21: %run compare_l25s.py
336/22: l1.close()
336/23: l1_new.close()
336/24: %run compare_l25s.py
337/1: %run compare_l25s.py
337/2: %load_file compare_l25s.py
337/3: %cell_run plotting
337/4: %cell_run plotting
337/5: %run compare_l25s.py
337/6: %run compare_l25s.py
337/7: %cell_run plotting
337/8: %load_file compare_l25s.py
337/9: %cell_run plotting
337/10: %cell_run plotting
337/11: import matplotlib.dates as md
337/12: plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H'))
337/13: plt.gca().xaxis.set_major_formatter(md.DateFormatter('%H'))
337/14: %run compare_l25s.py
337/15: %run compare_l25s.py
337/16: np.median(meds_new)
337/17: np.median(meds_old)
337/18: (meds_old-meds_new)/meds_old*100
337/19: meds_old = np.array(meds_old)
337/20: medsnewd = np.array(meds_new)
337/21: meds_new = np.array(meds_new)
337/22: (meds_old-meds_new)/meds_old*100
337/23: np.med((meds_old-meds_new)/meds_old*100)
337/24: np.median((meds_old-meds_new)/meds_old*100)
337/25: %cell_run plotting
337/26: %run compare_l25s.py
337/27: %cell_run plotting
337/28: %cell_run plotting
337/29: %run compare_l25s.py
337/30: %cell_run plotting
337/31: %cell_run plotting
337/32: %cell_run plotting
337/33: %cell_run plotting
337/34: %cell_run plotting
337/35: '{:.2d}'.format(2.234123)
337/36: '{:.02d}'.format(2.234123)
337/37: '{:.02f}'.format(2.234123)
337/38: %cell_run plotting
337/39: %run compare_l25s.py
337/40: diff
337/41: %cell_run plotting
337/42: %cell_run plotting
337/43: %cell_run plotting
337/44: %cell_run plotting
337/45: %run compare_l25s.py
337/46: %run compare_l25s.py
337/47: %run compare_l25s.py
337/48: %cell_run plotting
337/49: %run compare_l25s.py
337/50: %run compare_l25s.py
337/51: %run compare_l25s.py
337/52: %run compare_l25s.py
337/53: %run compare_l25s.py
337/54: '{:.0f}'.format(2.234123)
337/55: %cell_run plotting
337/56: time_new.shape
337/57: (np.med(meds_old)-np.med(meds_new))/np.med(meds_old)*100
337/58: (np.median(meds_old)-np.median(meds_new))/np.median(meds_old)*100
337/59: %cell_run plotting
337/60: (np.median(meds_old)-np.median(meds_new))/np.median(meds_old)*100
337/61: %run compare_l25s.py
337/62: (np.median(meds_old)-np.median(meds_new))/np.median(meds_old)*100
337/63: len(time_new)
338/1: file = '/home/kamo/resources/icon-fuv/ncfiles/l2/ICON_L2-5_FUV_Night_2022-01-14_v04r000.NC'
338/2: import netCDF4
338/3: l2 = netCDF4.Dataset(file, 'r')
338/4: qual = l2.variables['ICON_L25_Quality'][:]
338/5: qual.shape
338/6: plt.imshow(qual[:300].T, aspect='auto')
338/7: plt.imshow(qual.T, aspect='auto')
338/8: flag = l2.variables['ICON_L25_Quality_Flags'][:]
338/9: flag.shape
338/10: qual[600]
338/11: flag[600]
338/12: l2.variables['ICON_L25_Quality_Flags'].Var_Notes
338/13: print(l2.variables['ICON_L25_Quality_Flags'].Var_Notes)
338/14: plt.imshow(flag.T==1, aspect='auto')
339/1: %run runner.py 2022 014
339/2: %run runner.py 2022 014
339/3: ipdb.pm()
339/4: %run runner.py 2022 014
339/5: ipdb.pm()
339/6: %run runner.py 2022 014
340/1: import netCDF4
340/2: file = '/home/kamo/resources/icon-fuv/ncfiles/l2/ICON_L2-5_FUV_Night_2022-01-14_v04r000.NC'
340/3: l2 = netCDF4.Dataset(file, 'r')
340/4: qual = l2.variables['ICON_L25_Quality'][:]
340/5: flag = l2.variables['ICON_L25_Quality_Flags'][:]
340/6: np.sum(flag==1)
340/7: file = '/home/kamo/resources/icon-fuv/ncfiles/l2/ICON_L2-5_FUV_Night_2022-01-14_v02r000.NC'
340/8: l20 = netCDF4.Dataset(file, 'r')
340/9: flag = l20.variables['ICON_L25_Quality_Flags'][:]
340/10: np.sum(flag==1)
340/11: plt.imshow(flag.T==1, aspect='auto')
340/12: %run runner.py 2022 014
341/1: %run runner.py 2022 014
341/2: u
341/3: u
341/4: u
341/5: %run runner.py 2022 014
341/6: ipdb.pm()
342/1: import netCDF4
342/2: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2022-01-14_v04r000.NC'
342/3: l1 = netCDF4.Dataset(file, 'r')
342/4: from iconfuv.misc import profiler
342/5: prof, prof_er = profiler(l1, err=True)
342/6: prof.shape
342/7: prof_er.shape
342/8: np.sum(np.isnan(prof))
342/9: np.sum(prof.mask)
342/10: 6*256*6971
342/11: plt.imshow(prof.mask[0], aspect='auto')
342/12: plt.imshow(prof_er.mask[0], aspect='auto')
342/13: plt.imshow(prof_er.mask[0]-prof.mask[0], aspect='auto')
342/14: plt.imshow(prof_er.mask[0]^prof.mask[0], aspect='auto')
342/15: mode = l1.variables['ICON_L1_FUV_Mode'][:]
342/16: plt.imshow(prof_er.mask[0,:,mode==2]^prof.mask[0,:,mode==2], aspect='auto')
342/17: plt.imshow(prof_er.mask[0,:,mode==2]^prof.mask[0,:,mode==2], aspect='auto')
342/18: plt.imshow(prof_er.mask[0,:,mode==2].T^prof.mask[0,:,mode==2].T, aspect='auto')
342/19: plt.imshow(prof_er.mask[0,:,mode==1].T^prof.mask[0,:,mode==1].T, aspect='auto')
342/20: plt.imshow(prof_er.mask[0,:,mode==2].T^prof.mask[0,:,mode==2].T, aspect='auto')
342/21: prof[0,236,mode==2][468]
342/22: prof[0,236,mode==2][469]
342/23: prof[0,-40:,mode==2][468]
342/24: dif=prof_er.mask[0,:,mode==2]^prof.mask[0,:,mode==2]
342/25: dif=prof_er.mask[0]^prof.mask[0]
342/26: dif.shape
342/27: prof[0][dif].shape
342/28: np.isnan(prof[0][dif])
342/29: np.sum(np.isnan(prof[0][dif]))
342/30: np.median(np.isnan(prof[0][dif]))
342/31: prof[0][dif][:20]
342/32: np.median(np.isnan(prof.data[0][dif]))
342/33: np.median(prof.data[0][dif])
342/34: np.median(prof[0][dif])
342/35: np.sum(prof.mask[0][dif])
342/36: np.mean(prof[0][dif])
342/37: np.std(prof[0][dif])
342/38: np.max(prof[0][dif])
342/39: plt.imshow(prof.mask[0], aspect='auto')
342/40: plt.imshow(prof_er.mask[0], aspect='auto')
342/41: plt.imshow(prof_er.mask[0,:,mode==2].T^prof.mask[0,:,mode==2].T, aspect='auto')
342/42: plt.imshow(prof_er.mask[0]^prof.mask[0], aspect='auto')
342/43: plt.imshow(prof.mask[0], aspect='auto')
342/44: plt.imshow(prof.mask[0], aspect='auto')
342/45: plt.title('Nans in Brightness Profiles, Stripe=0')
342/46: plt.xlabel('Epoch')
342/47: plt.ylabel('Pixel Number')
342/48: plt.savefig('brnan.png', dpi=300)
342/49: plt.imshow(prof_er.mask[0], aspect='auto')
342/50: plt.title('Nans in Uncertainty Profiles, Stripe=0')
342/51: plt.savefig('uncnan.png', dpi=300)
342/52: plt.imshow(prof_er.mask[0]^prof.mask[0], aspect='auto')
342/53: plt.title('Extra Nans, Stripe=0')
342/54: plt.savefig('exnan.png', dpi=300)
342/55: plt.imshow(prof_er.mask[1]^prof.mask[1], aspect='auto')
342/56: plt.imshow(prof_er.mask[2]^prof.mask[2], aspect='auto')
342/57: plt.imshow(prof_er.mask[3]^prof.mask[3], aspect='auto')
342/58: plt.imshow(prof_er.mask[4]^prof.mask[4], aspect='auto')
342/59: plt.imshow(prof_er.mask[5]^prof.mask[5], aspect='auto')
342/60: plt.imshow(prof_er.mask[4]^prof.mask[4], aspect='auto')
342/61: plt.imshow(prof.mask[4], aspect='auto')
342/62: plt.imshow(prof_er.mask[4], aspect='auto')
342/63: plt.imshow(prof_er.mask[5]^prof.mask[5], aspect='auto')
342/64: plt.imshow(prof.mask[4], aspect='auto')
342/65: plt.title('Nans in Brightness Profiles, Stripe=4')
342/66: plt.xlabel('Epoch')
342/67: plt.ylabel('Pixel Number')
342/68: plt.savefig('st_4_brnan.png', dpi=300)
342/69: plt.imshow(prof_er.mask[4], aspect='auto')
342/70: plt.savefig('st_4_uncnan.png', dpi=300)
342/71: plt.imshow(prof_er.mask[4]^prof.mask[4], aspect='auto')
342/72: plt.title('Extra Nans, Stripe=4')
342/73: plt.savefig('st_4_extra.png', dpi=300)
342/74: plt.imshow(prof_er.mask[4], aspect='auto')
342/75: plt.title('Nans in Uncertainty Profiles, Stripe=4')
342/76: plt.xlabel('Epoch')
342/77: plt.ylabel('Pixel Number')
342/78: plt.savefig('st_4_uncnan.png', dpi=300)
342/79: dif=prof_er.mask[0]^prof.mask[0]
342/80: dif.shape
342/81: np.sum(dif)
342/82: dif=prof_er.mask[0,:,mode==2]^prof.mask[0,:,mode==2]
342/83: np.sum(dif)
342/84: dif=prof_er.mask[0,:,mode==1]^prof.mask[0,:,mode==1]
342/85: np.sum(dif)
342/86: np.sum(prof_er.mask[0,:,mode==1]^prof.mask[0,:,mode==1])
342/87: np.sum(prof_er.mask[:,:,mode==1]^prof.mask[:,:,mode==1])
342/88: np.sum(prof_er.mask[1,:,mode==1]^prof.mask[1,:,mode==1])
342/89: np.sum(prof_er.mask[2,:,mode==1]^prof.mask[2,:,mode==1])
342/90: np.sum(prof_er.mask[3,:,mode==1]^prof.mask[3,:,mode==1])
342/91: np.sum(prof_er.mask[4,:,mode==1]^prof.mask[4,:,mode==1])
342/92: np.sum(prof_er.mask[5,:,mode==1]^prof.mask[5,:,mode==1])
342/93: plt.imshow(prof_er.mask[5]^prof.mask[5], aspect='auto')
342/94: plt.imshow(prof_er.mask[4]^prof.mask[4], aspect='auto')
342/95: plt.plot(prof[4,:,2880])
342/96: plt.plot(prof_er[4,:,2880])
343/1: from modify_l1 import rewriter
343/2: rewriter('2021-08-04')
343/3: rewriter('2021-08-05'); rewriter('2021-08-06'); rewriter('2021-08-10'); rewriter('2021-08-11')
344/1: from scipy.io import readsav
344/2: data = readsav('/home/kamo/resources/icon-fuv/ncfiles/l1/input_2022_014_swp.sav')
344/3: data
344/4: %run uncertainty_tester.py
344/5: %run uncertainty_tester.py
344/6: %run uncertainty_tester2.py
344/7: %run uncertainty_tester2.py
344/8: unc.shape
344/9: my_raw.shape
344/10: dtype(unc)
344/11: type(unc)
344/12: np.sum(np.isnan(unc))
344/13: np.sum(np.isnan(my_raw[:,:,5]))
344/14: plt.imsave('amo1.png', np.isnan(unc), aspect='auto')
344/15: plt.plot(np.isnan(unc), aspect='auto')
344/16: np.isnan(unc).shape
344/17: plt.imshow(np.isnan(unc), aspect='auto')
344/18: plt.imshow(np.isnan(unc).T, aspect='auto')
344/19: %run uncertainty_tester2.py
344/20: plt.imshow(np.isnan(unc).T, aspect='auto')
344/21: %run uncertainty_tester2.py
344/22: np.min(unc)
344/23: np.nanmin(unc)
344/24: %run uncertainty_tester2.py
345/1: %run modify_l1.py 2022-02-18
347/1: from adasdasdijijijoij
347/2: from modify_l1 import rewriter
347/3: rewriter('2022-02-18')
348/1: %run gain_variability.py
348/2: l1.close()
348/3: gdays.shape
348/4: plt.plot(gdays)
349/1: import netCDF4
349/2: from iconfuv.misc import get_br_nights
349/3: file = '/home/kamo/resources/icon-fuv/ncfiles/l1/ICON_L1_FUV_SWP_2022-01-14_v05r000.NC'
349/4: brs, brsc, _,_,_,_ = get_br_nights(l1)
349/5: l1 = netCDF4.Dataset(file, 'r')
349/6: brs, brsc, _,_,_,_ = get_br_nights(l1)
349/7: brs, brsc, brs_err,_,_,_ = get_br_nights(l1)
349/8: brs[4].shape
349/9: plt.imshow(brs[4][4].T, aspect='auto', origin='lower')
349/10: plt.colorbar()
349/11: np.median(gain_day)
349/12: np.median(gdays)
349/13: %run gain_variability.py
349/14: np.median(gdays, axis=0)
350/1: from modify_l1 import rewriter
350/2: rewriter('2022-02-19'); rewriter('2022-02-24'); rewriter('2022-02-25')
   1: %history -g -f 'hist.LOG'
